{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Description:\n",
        "This notebook focuses on creating a prompt iteratively which will generate the 2nd scoring criteria. This scoring criteria will then be used by later assignments to give scores to each of the must have skills, where the scores will vary between 0 and 5. The purpose of breaking this scoring criteria into 2 steps (criteria generation and score generation using criteria) is to use the concept of chain-of-thoughts to enhance the performance of the OpenAI GPT-3.5 model which is relatively cheaper than directly using GPT-4 model"
      ],
      "metadata": {
        "id": "dGhk70MUfVqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now install necessary libraries required to execute all functionalities within this notebook."
      ],
      "metadata": {
        "id": "gvSuRd6QK1T0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install PyMuPDF\n",
        "!pip install textract\n",
        "!pip install python-docx"
      ],
      "metadata": {
        "id": "kK5UgrhwAr1A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cc474657-885e-4591-ca4d-d7d7994c5931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n",
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.23.3-cp310-none-manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyMuPDFb==1.23.3 (from PyMuPDF)\n",
            "  Downloading PyMuPDFb-1.23.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDFb, PyMuPDF\n",
            "Successfully installed PyMuPDF-1.23.3 PyMuPDFb-1.23.3\n",
            "Collecting textract\n",
            "  Downloading textract-1.6.5-py3-none-any.whl (23 kB)\n",
            "Collecting argcomplete~=1.10.0 (from textract)\n",
            "  Downloading argcomplete-1.10.3-py2.py3-none-any.whl (36 kB)\n",
            "Collecting beautifulsoup4~=4.8.0 (from textract)\n",
            "  Downloading beautifulsoup4-4.8.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.9/106.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chardet==3.* (from textract)\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docx2txt~=0.8 (from textract)\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting extract-msg<=0.29.* (from textract)\n",
            "  Downloading extract_msg-0.28.7-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.0/69.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20191110 (from textract)\n",
            "  Downloading pdfminer.six-20191110-py2.py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-pptx~=0.6.18 (from textract)\n",
            "  Downloading python_pptx-0.6.22-py3-none-any.whl (471 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.5/471.5 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting six~=1.12.0 (from textract)\n",
            "  Downloading six-1.12.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting SpeechRecognition~=3.8.1 (from textract)\n",
            "  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xlrd~=1.2.0 (from textract)\n",
            "  Downloading xlrd-1.2.0-py2.py3-none-any.whl (103 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodome (from pdfminer.six==20191110->textract)\n",
            "  Downloading pycryptodome-3.18.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20191110->textract) (2.4.0)\n",
            "Requirement already satisfied: soupsieve>=1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4~=4.8.0->textract) (2.5)\n",
            "Collecting imapclient==2.1.0 (from extract-msg<=0.29.*->textract)\n",
            "  Downloading IMAPClient-2.1.0-py2.py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting olefile>=0.46 (from extract-msg<=0.29.*->textract)\n",
            "  Downloading olefile-0.46.zip (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tzlocal>=2.1 in /usr/local/lib/python3.10/dist-packages (from extract-msg<=0.29.*->textract) (5.0.1)\n",
            "Collecting compressed-rtf>=1.0.6 (from extract-msg<=0.29.*->textract)\n",
            "  Downloading compressed_rtf-1.0.6.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ebcdic>=1.1.1 (from extract-msg<=0.29.*->textract)\n",
            "  Downloading ebcdic-1.1.1-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.5/128.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-pptx~=0.6.18->textract) (4.9.3)\n",
            "Requirement already satisfied: Pillow<=9.5.0,>=3.3.2 in /usr/local/lib/python3.10/dist-packages (from python-pptx~=0.6.18->textract) (9.4.0)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx~=0.6.18->textract)\n",
            "  Downloading XlsxWriter-3.1.3-py3-none-any.whl (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.2/153.2 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: docx2txt, compressed-rtf, olefile\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3959 sha256=cb01909989043f0d18b808e982555697b9a5e117ad91dc86083481896153ae5e\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/58/cf/093d0a6c3ecfdfc5f6ddd5524043b88e59a9a199cb02352966\n",
            "  Building wheel for compressed-rtf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for compressed-rtf: filename=compressed_rtf-1.0.6-py3-none-any.whl size=6185 sha256=2a1c5044e4e842cf413504c403202dd9d51c34a021af08252bfee3b6c73941fc\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/3e/48/e7d833ecc516c36f8966d310b1a6386db091a718f1ff3bf85c\n",
            "  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35417 sha256=101d09e861b590ca7f5c72dd821fa0f6c8b0b967caec1c1a39e2aaddc7c983fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/39/c0/9eb1f7a42b4b38f6f333b6314d4ed11c46f12a0f7b78194f0d\n",
            "Successfully built docx2txt compressed-rtf olefile\n",
            "Installing collected packages: SpeechRecognition, ebcdic, docx2txt, compressed-rtf, chardet, argcomplete, XlsxWriter, xlrd, six, pycryptodome, olefile, beautifulsoup4, python-pptx, pdfminer.six, imapclient, extract-msg, textract\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: xlrd\n",
            "    Found existing installation: xlrd 2.0.1\n",
            "    Uninstalling xlrd-2.0.1:\n",
            "      Successfully uninstalled xlrd-2.0.1\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.16.0\n",
            "    Uninstalling six-1.16.0:\n",
            "      Successfully uninstalled six-1.16.0\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.11.2\n",
            "    Uninstalling beautifulsoup4-4.11.2:\n",
            "      Successfully uninstalled beautifulsoup4-4.11.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pydrive2 1.6.3 requires six>=1.13.0, but you have six 1.12.0 which is incompatible.\n",
            "yfinance 0.2.28 requires beautifulsoup4>=4.11.1, but you have beautifulsoup4 4.8.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed SpeechRecognition-3.8.1 XlsxWriter-3.1.3 argcomplete-1.10.3 beautifulsoup4-4.8.2 chardet-3.0.4 compressed-rtf-1.0.6 docx2txt-0.8 ebcdic-1.1.1 extract-msg-0.28.7 imapclient-2.1.0 olefile-0.46 pdfminer.six-20191110 pycryptodome-3.18.0 python-pptx-0.6.22 six-1.12.0 textract-1.6.5 xlrd-1.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.3)\n",
            "Building wheels for collected packages: python-docx\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184487 sha256=9c56fe5f1c6e501ff894089d2ae0f8d320550d748d7e2c4e7b47c043d1c7356a\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/27/06/837436d4c3bd989b957a91679966f207bfd71d358d63a8194d\n",
            "Successfully built python-docx\n",
            "Installing collected packages: python-docx\n",
            "Successfully installed python-docx-0.8.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload the .env file to the directory `/content/` which contains the \"OPENAI_API_KEY\""
      ],
      "metadata": {
        "id": "mDbcQlIeFmX2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The provided code snippet accesses sensitive values like the OpenAI API key\n"
      ],
      "metadata": {
        "id": "kWq0o6d1uk77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Export your API Key to environment variable\n",
        "# Upload the .env file to the directory \"/content/\"\n",
        "!pip install python-dotenv\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n"
      ],
      "metadata": {
        "id": "xQW9h3tAug93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e6f32d2-fb82-4c42-bb8a-baf6cb7db2bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "# Retrieve the API key from environment variable\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Set the API key for OpenAI\n",
        "openai.api_key = openai_api_key"
      ],
      "metadata": {
        "id": "ud0kQH7KFQAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload the json file containing important information about the Job requirements which was generated in Assignment1"
      ],
      "metadata": {
        "id": "vFz5WRwwFuKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "\n",
        "# Upload the second file\n",
        "print(\"Please upload the second file (requirements_output.json):\")\n",
        "uploaded2 = files.upload()\n",
        "\n",
        "# Check to ensure a file was uploaded. If not, prompt again.\n",
        "while len(uploaded2) == 0:\n",
        "    print(\"No file uploaded. Please upload the second file (requirements_output.json) again:\")\n",
        "    uploaded2 = files.upload()\n",
        "\n",
        "# Merge the dictionaries to have all uploaded files in one\n",
        "uploaded = {**uploaded2}\n",
        "\n",
        "# Print details of uploaded files\n",
        "for fn in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "        name=fn, length=len(uploaded[fn])))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "OmMDz9GsFvEz",
        "outputId": "70e8bae2-192d-4501-fc29-14339962b8c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload the second file (requirements_output.json):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e2c64d9e-bddd-4cea-a6f3-1b6da4c3b292\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e2c64d9e-bddd-4cea-a6f3-1b6da4c3b292\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving requirements_output (3).json to requirements_output (3).json\n",
            "User uploaded file \"requirements_output (3).json\" with length 810 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Import Statements`: Essential libraries are imported. These include:\n",
        "1. `openai` for interacting with the OpenAI API.\n",
        "2. Utilities like `json`, `os`, and `re` for handling data and file operations.\n",
        "3. Libraries for reading specific file formats (`docx` for Word documents, `textract` for older Word format, and `fitz` for PDFs).\n",
        "4. `pandas` for reading Excel files.\n",
        "\n",
        "\n",
        "`read_requirements` Function:\n",
        "\n",
        "1. Reads job requirements from a JSON file and returns the data. It includes error handling to manage potential reading errors."
      ],
      "metadata": {
        "id": "S7FIE2c5LKXM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edSLHu2NAd3j"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import json\n",
        "import os\n",
        "from collections import OrderedDict\n",
        "import re\n",
        "from docx import Document\n",
        "import textract\n",
        "import fitz  # PyMuPDF\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "\n",
        "def read_requirements(file_path):\n",
        "    # Reads the job requirements from a JSON file\n",
        "    try:\n",
        "        with open(file_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading requirements JSON: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below initializes two primary components: job requirements and must-have skills. The `read_requirements` function fetches the job requirements from a predefined JSON file."
      ],
      "metadata": {
        "id": "xitRB-6XUxLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job_requirements = read_requirements('/content/requirements_output.json')\n",
        "must_have_skills = job_requirements[\"must_have_skills\"]"
      ],
      "metadata": {
        "id": "N7Uic3SeVesl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Goal*: To generate a criterion that helps calculate scores for each of the must-have skills present inside a resume.\n",
        "\n",
        "### *Reason*: First we start with a basic prompt asking the assistant to generate a criterion to help calculate scores for each of the must have skills present inside the resume. The initial approach aimed to provide the assistant with a basic idea of what is expected in terms of the scoring criterion. The method was to guide the model in a step-by-step manner to think about how to evaluate a resume based on specific must-have skills.\n",
        "# Prompt Version 1:"
      ],
      "metadata": {
        "id": "ycSvrDvgVtXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def criterion_gen(must_have):\n",
        "    model=\"gpt-3.5-turbo-16k\"\n",
        "    max_tokens=4000\n",
        "    prompt_v1 = f'''I have a resume. I want to find a person whose resume has skills in {must_have}. \\\n",
        "    Let's think step by step on how to look into a resume and give score based on each of the skill mentioned in {must_have}. \\\n",
        "    As an example, take the case where the must have skills are \"SKILL1, SKILL2, SKILL3, SKILL4, SKILL5\". \\\n",
        "    Now generate a criterion to score each of the skill between 0 and 5.'''\n",
        "\n",
        "    messages = [\n",
        "            {\"role\": \"system\", \"content\": f\"{prompt_v1}\"},\n",
        "        ]\n",
        "    response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo-16k\",\n",
        "            messages=messages,\n",
        "            temperature=0,\n",
        "            max_tokens=max_tokens\n",
        "        )\n",
        "    generated_texts = [\n",
        "        choice.message[\"content\"].strip() for choice in response[\"choices\"]\n",
        "    ]\n",
        "    return generated_texts[0]\n",
        "\n",
        "\n",
        "\n",
        "criterion_gen_output = criterion_gen(must_have_skills)\n",
        "print(f'''[Criterion Generation Request] ''', criterion_gen_output)\n"
      ],
      "metadata": {
        "id": "qMn2zZ3uBuQ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9d8e2de-3ef0-46e2-f655-cf7776268ac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Criterion Generation Request]  To score each skill between 0 and 5, we can use the following criterion:\n",
            "\n",
            "1. Skill Relevance: Assess the relevance of the skill to the desired skills. Give a score of 5 if the skill is an exact match, 4 if it is closely related, 3 if it is somewhat related, 2 if it is vaguely related, and 1 if it is not related at all.\n",
            "\n",
            "2. Skill Proficiency: Evaluate the proficiency level of the skill mentioned in the resume. Give a score of 5 if the candidate has extensive experience and deep knowledge in the skill, 4 if they have significant experience and good knowledge, 3 if they have some experience and basic knowledge, 2 if they have limited experience and basic understanding, and 1 if they have no experience or knowledge in the skill.\n",
            "\n",
            "3. Skill Application: Consider the practical application of the skill in real-world projects or work experience. Give a score of 5 if the candidate has successfully applied the skill in multiple projects, 4 if they have applied it in a few projects, 3 if they have some experience applying it, 2 if they have limited experience, and 1 if they have no practical application of the skill.\n",
            "\n",
            "By using these criteria, we can assign a score between 0 and 5 for each skill mentioned in the resume.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:**\n",
        "The output generated by the above cell is not properly formatted. Also the output keeps on changing on multiple runs of the above cell."
      ],
      "metadata": {
        "id": "gyQfL62cWhrS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Output:\n",
        "\n",
        "\n",
        "```\n",
        "[Criterion Generation Request]  To score each skill between 0 and 5, we can use the following criterion:\n",
        "\n",
        "1. Skill Relevance: Assess the relevance of the skill to the desired skills. Give a score of 5 if the skill is an exact match, 4 if it is closely related, 3 if it is somewhat related, 2 if it is vaguely related, and 1 if it is not related at all.\n",
        "\n",
        "2. Skill Proficiency: Evaluate the proficiency level of the skill mentioned in the resume. Give a score of 5 if the candidate has extensive experience and deep knowledge in the skill, 4 if they have significant experience and good knowledge, 3 if they have some experience and basic knowledge, 2 if they have limited experience and basic understanding, and 1 if they have no experience or knowledge in the skill.\n",
        "\n",
        "3. Skill Application: Consider the practical application of the skill in real-world projects or work experience. Give a score of 5 if the candidate has successfully applied the skill in multiple projects, 4 if they have applied it in a few projects, 3 if they have some experience applying it, 2 if they have limited experience, and 1 if they have no practical application of the skill.\n",
        "\n",
        "By using these criteria, we can assign a score between 0 and 5 for each skill mentioned in the resume.\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "4eaADSChWNE1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###*Goal*: Enhance the specificity of the criterion by providing an example string (`string_match`) that gives a scoring guide for a dummy skill (`SKILL1`).\n",
        "\n",
        "###*Reason*: Taking inspiration from the above output we pass a `string_match` string containing an example of the scoring criterion for a dummy skill `SKILL1`. The initial output might not be specific enough for the application. By giving a tangible example of the scoring metric, the aim was to align the model's output more closely with the desired format.\n",
        "# Prompt Version 2:"
      ],
      "metadata": {
        "id": "R7GSgoZCoKzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "string_match = \"\"\"\n",
        "skill1:\n",
        "No projects: 0\n",
        "1 project or mention: one or two\n",
        "2 or 3 projects or mentions: three or four\n",
        "more than or equal to five projects or mentions: five\n",
        "\"\"\"\n",
        "def criterion_gen(must_have):\n",
        "    model=\"gpt-3.5-turbo-16k\"\n",
        "    max_tokens=4000\n",
        "    prompt_v2 = f'''I have a resume. I want to find a person whose resume has skills in {must_have}. \\\n",
        "    Let's think step by step on how to look into a resume and give score based on each of the skill mentioned in {must_have}. \\\n",
        "    As an example, take the case where the must have skills are \"SKILL1, SKILL2, SKILL3, SKILL4, SKILL5\". Now score each of the skill between 0 and 5.\\\n",
        "    For example use the criterion given in {string_match}'''\n",
        "\n",
        "    messages = [\n",
        "            {\"role\": \"system\", \"content\": f\"{prompt_v2}\"},\n",
        "        ]\n",
        "    response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo-16k\",\n",
        "            messages=messages,\n",
        "            temperature=0,\n",
        "            max_tokens=max_tokens\n",
        "        )\n",
        "    generated_texts = [\n",
        "        choice.message[\"content\"].strip() for choice in response[\"choices\"]\n",
        "    ]\n",
        "    return generated_texts[0]\n",
        "\n",
        "criterion_gen_output = criterion_gen(must_have_skills)\n",
        "print(f'''[Criterion Generation Request] ''', criterion_gen_output)"
      ],
      "metadata": {
        "id": "aSovffHYVE6z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d2afd38-56b4-42bf-f4cb-fd3876f16a64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Criterion Generation Request]  To find a person whose resume has skills in ['TensorFlow', 'Keras', 'PyTorch', 'Computer Vision'], we can follow these steps:\n",
            "\n",
            "1. Read the resume and extract the relevant information.\n",
            "2. Assign a score to each skill based on the mentioned criterion.\n",
            "3. Calculate the overall score for the resume based on the scores of individual skills.\n",
            "4. Compare the overall scores of different resumes to find the one with the highest score.\n",
            "\n",
            "Here's an example of how we can score each skill based on the mentioned criterion:\n",
            "\n",
            "Skill1 (TensorFlow):\n",
            "- No projects or mentions: 0\n",
            "- 1 project or mention: 1 or 2\n",
            "- 2 or 3 projects or mentions: 3 or 4\n",
            "- More than or equal to five projects or mentions: 5\n",
            "\n",
            "Skill2 (Keras):\n",
            "- No projects or mentions: 0\n",
            "- 1 project or mention: 1 or 2\n",
            "- 2 or 3 projects or mentions: 3 or 4\n",
            "- More than or equal to five projects or mentions: 5\n",
            "\n",
            "Skill3 (PyTorch):\n",
            "- No projects or mentions: 0\n",
            "- 1 project or mention: 1 or 2\n",
            "- 2 or 3 projects or mentions: 3 or 4\n",
            "- More than or equal to five projects or mentions: 5\n",
            "\n",
            "Skill4 (Computer Vision):\n",
            "- No projects or mentions: 0\n",
            "- 1 project or mention: 1 or 2\n",
            "- 2 or 3 projects or mentions: 3 or 4\n",
            "- More than or equal to five projects or mentions: 5\n",
            "\n",
            "By assigning scores to each skill, we can evaluate the proficiency of a person in these skills based on their resume.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:**\n",
        "In the above case the criteria does not focus on the output format. We need to instruct the assistant to give the output in such a format so that it can be used by other applications and for that JSON format is the ideal one"
      ],
      "metadata": {
        "id": "FF6STVOsf9wC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Output:\n",
        "\n",
        "```\n",
        "[Criterion Generation Request]  To score each skill mentioned in the resume, we can follow these steps:\n",
        "\n",
        "1. Read the resume and extract the skills mentioned.\n",
        "2. For each skill, count the number of projects or mentions related to that skill.\n",
        "3. Assign a score based on the count of projects or mentions using the given criterion.\n",
        "4. Repeat the process for each skill mentioned in the resume.\n",
        "5. Calculate the overall score by summing up the scores of all the skills.\n",
        "\n",
        "Let's apply this step-by-step process to the example skills ['Keras', 'TensorFlow', 'PyTorch', 'Computer Vision']:\n",
        "\n",
        "1. Read the resume and extract the skills mentioned.\n",
        "   - Assume the resume mentions the following skills: ['Keras', 'TensorFlow', 'PyTorch', 'Computer Vision', 'Keras', 'PyTorch']\n",
        "\n",
        "2. For each skill, count the number of projects or mentions related to that skill.\n",
        "   - 'Keras': 2 mentions\n",
        "   - 'TensorFlow': 1 mention\n",
        "   - 'PyTorch': 2 mentions\n",
        "   - 'Computer Vision': 1 mention\n",
        "\n",
        "3. Assign a score based on the count of projects or mentions using the given criterion.\n",
        "   - 'Keras': 2 mentions -> Score: one or two\n",
        "   - 'TensorFlow': 1 mention -> Score: one or two\n",
        "   - 'PyTorch': 2 mentions -> Score: one or two\n",
        "   - 'Computer Vision': 1 mention -> Score: one or two\n",
        "\n",
        "4. Repeat the process for each skill mentioned in the resume.\n",
        "   - 'Keras': 2 mentions -> Score: one or two\n",
        "   - 'TensorFlow': 1 mention -> Score: one or two\n",
        "   - 'PyTorch': 2 mentions -> Score: one or two\n",
        "   - 'Computer Vision': 1 mention -> Score: one or two\n",
        "\n",
        "5. Calculate the overall score by summing up the scores of all the skills.\n",
        "   - 'Keras' score: one or two\n",
        "   - 'TensorFlow' score: one or two\n",
        "   - 'PyTorch' score: one or two\n",
        "   - 'Computer Vision' score: one or two\n",
        "\n",
        "The overall score for this resume would be the sum of the scores for each skill, which would be between 0 and 8.\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "dsvFciPyWm4c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Goal*: Adapt the model to produce JSON-like output for scoring justification.\n",
        "\n",
        "### *Reason*: The output from the above isn't satisfactory so we add a json output in `string_match` to force the final output to look like the JSON output. The desired format for the output seemed to be in JSON, which would make it easier to integrate and analyze in other systems. By showing the model an example of this format, the hope was to nudge it into generating similar structured outputs.\n",
        "\n",
        "# Prompt Version 3:"
      ],
      "metadata": {
        "id": "dD4mCBkhozsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "string_match = \"\"\"\n",
        "skill1:\n",
        "No projects: 0\n",
        "1 project or mention: one or two\n",
        "2 or 3 projects or mentions: three or four\n",
        "more than or equal to five projects or mentions: five\n",
        "{\n",
        "\"SKILL1\": {\n",
        "    \"score\": 5,\n",
        "    \"justification\": \"The candidate has significant experience in SKILL1, as mentioned in the resume.\"\n",
        "}\n",
        "}\n",
        "\"\"\"\n",
        "def criterion_gen(must_have):\n",
        "    model=\"gpt-3.5-turbo-16k\"\n",
        "    max_tokens=4000\n",
        "    prompt_v3 = f'''I have a resume. I want to find a person whose resume has skills in {must_have}. \\\n",
        "    Let's think step by step on how to look into a resume and give score based on each of the skill mentioned in {must_have}. \\\n",
        "    As an example, take the case where the must have skills are \"SKILL1, SKILL2, SKILL3, SKILL4, SKILL5\". Now score each of the skill between 0 and 5.\\\n",
        "    For example use the criterion given in {string_match}'''\n",
        "\n",
        "    messages = [\n",
        "            {\"role\": \"system\", \"content\": f\"{prompt_v3}\"},\n",
        "        ]\n",
        "    response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo-16k\",\n",
        "            messages=messages,\n",
        "            temperature=0,\n",
        "            max_tokens=max_tokens\n",
        "        )\n",
        "    generated_texts = [\n",
        "        choice.message[\"content\"].strip() for choice in response[\"choices\"]\n",
        "    ]\n",
        "    return generated_texts[0]\n",
        "\n",
        "\n",
        "criterion_gen_output = criterion_gen(must_have_skills)\n",
        "print(f'''[Criterion Generation Request] ''', criterion_gen_output)"
      ],
      "metadata": {
        "id": "xJVellaCftDV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fa63b46-b00d-469e-9d38-7434a6fc0480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Criterion Generation Request]  To find a person whose resume has skills in ['TensorFlow', 'Keras', 'PyTorch', 'Computer Vision'], we can follow these steps:\n",
            "\n",
            "1. Read the resume and extract the relevant information.\n",
            "2. Look for mentions or projects related to each skill in the resume.\n",
            "3. Assign a score to each skill based on the number of mentions or projects.\n",
            "4. Generate a scorecard for each skill, including the score and a justification.\n",
            "5. Calculate the overall score for the resume based on the scores of individual skills.\n",
            "\n",
            "Here's an example of how to score each skill:\n",
            "\n",
            "Skill: TensorFlow\n",
            "- No projects or mentions: Score 0\n",
            "- 1 project or mention: Score 1 or 2\n",
            "- 2 or 3 projects or mentions: Score 3 or 4\n",
            "- More than or equal to five projects or mentions: Score 5\n",
            "\n",
            "Skill: Keras\n",
            "- No projects or mentions: Score 0\n",
            "- 1 project or mention: Score 1 or 2\n",
            "- 2 or 3 projects or mentions: Score 3 or 4\n",
            "- More than or equal to five projects or mentions: Score 5\n",
            "\n",
            "Skill: PyTorch\n",
            "- No projects or mentions: Score 0\n",
            "- 1 project or mention: Score 1 or 2\n",
            "- 2 or 3 projects or mentions: Score 3 or 4\n",
            "- More than or equal to five projects or mentions: Score 5\n",
            "\n",
            "Skill: Computer Vision\n",
            "- No projects or mentions: Score 0\n",
            "- 1 project or mention: Score 1 or 2\n",
            "- 2 or 3 projects or mentions: Score 3 or 4\n",
            "- More than or equal to five projects or mentions: Score 5\n",
            "\n",
            "Based on these criteria, we can assign scores to each skill mentioned in the resume and generate a scorecard.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Output:\n",
        "\n",
        "\n",
        "```\n",
        "[Criterion Generation Request]  To find a person whose resume has skills in ['Keras', 'TensorFlow', 'PyTorch', 'Computer Vision'], we can follow these steps:\n",
        "\n",
        "1. Read the resume and extract the relevant information.\n",
        "2. Assign a score to each skill based on the criteria provided.\n",
        "3. Calculate the overall score for the resume based on the scores of individual skills.\n",
        "4. Compare the overall score with a threshold to determine if the person has the required skills.\n",
        "\n",
        "Here's an example of how we can score each skill:\n",
        "\n",
        "1. Keras:\n",
        "   - No projects or mentions: 0\n",
        "   - 1 project or mention: 1\n",
        "   - 2 or 3 projects or mentions: 3\n",
        "   - More than or equal to five projects or mentions: 5\n",
        "\n",
        "2. TensorFlow:\n",
        "   - No projects or mentions: 0\n",
        "   - 1 project or mention: 1\n",
        "   - 2 or 3 projects or mentions: 3\n",
        "   - More than or equal to five projects or mentions: 5\n",
        "\n",
        "3. PyTorch:\n",
        "   - No projects or mentions: 0\n",
        "   - 1 project or mention: 1\n",
        "   - 2 or 3 projects or mentions: 3\n",
        "   - More than or equal to five projects or mentions: 5\n",
        "\n",
        "4. Computer Vision:\n",
        "   - No projects or mentions: 0\n",
        "   - 1 project or mention: 1\n",
        "   - 2 or 3 projects or mentions: 3\n",
        "   - More than or equal to five projects or mentions: 5\n",
        "\n",
        "For each skill, we assign a score based on the criteria mentioned above. The maximum score for each skill is 5.\n",
        "\n",
        "Once we have the scores for each skill, we can calculate the overall score for the resume by summing up the scores of individual skills.\n",
        "\n",
        "Finally, we can compare the overall score with a threshold (e.g., 15) to determine if the person has the required skills. If the overall score is equal to or greater than the threshold, we can consider the person as having the required skills.\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "biG8SLTnHW1K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Goal*: Increase the number of dummy skills in `string_match` to guide the model further in scoring multiple skills.\n",
        "\n",
        "### *Reason*: As the model was not generating satisfactory outputs, the strategy was to provide more context by using multiple dummy skills. This would help the model understand the pattern more clearly and reproduce it for the actual must-have skills.\n",
        "# Prompt Version 4:"
      ],
      "metadata": {
        "id": "Bo-p56par4k7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "string_match = \"\"\"\n",
        "SKILL1 assessment:\n",
        "No projects: 0\n",
        "1 project or mention: one or two\n",
        "2 or 3 projects or mentions: three or four\n",
        "more than or equal to five projects or mentions: five\n",
        "\n",
        "SKILL2 assessment:\n",
        "No projects: 0\n",
        "1 project or mention: one or two\n",
        "2 or 3 projects or mentions: three or four\n",
        "more than or equal to five projects or mentions: five\n",
        "\n",
        "SKILL3 assessment:\n",
        "No projects: 0\n",
        "1 project or mention: one or two\n",
        "2 or 3 projects or mentions: three or four\n",
        "more than or equal to five projects or mentions: five\n",
        "\n",
        "SKILL4 assessment:\n",
        "No projects: 0\n",
        "1 project or mention: one or two\n",
        "2 or 3 projects or mentions: three or four\n",
        "more than or equal to five projects or mentions: five\n",
        "{\n",
        "\"SKILL1\": {\n",
        "    \"score\": 5,\n",
        "    \"justification\": \"The candidate has significant experience in SKILL1, as mentioned in the resume.\"\n",
        "}\n",
        "\"SKILL2\": {\n",
        "    \"score\": 0,\n",
        "    \"justification\": \"The candidate has no experience in SKILL2.\"\n",
        "}\n",
        "\"SKILL3\": {\n",
        "    \"score\": 1,\n",
        "    \"justification\": \"The candidate has some experience in SKILL3\"\n",
        "}\n",
        "\"SKILL4\": {\n",
        "    \"score\": 3,\n",
        "    \"justification\": \"The candidate has good experience in SKILL4.\"\n",
        "}\n",
        "}\n",
        "\"\"\"\n",
        "def criterion_gen(must_have):\n",
        "    model=\"gpt-3.5-turbo-16k\"\n",
        "    max_tokens=4000\n",
        "    prompt_v4 = f'''I have a resume. I want to find a person whose resume has skills in {must_have}. \\\n",
        "    Let's think step by step on how to look into a resume and give score based on each of the skill mentioned in {must_have}. \\\n",
        "    As an example, take the case where the must have skills are \"SKILL1, SKILL2, SKILL3, SKILL4, SKILL5\". Now score each of the skill between 0 and 5.\\\n",
        "    For example use the criterion given in {string_match}'''\n",
        "\n",
        "    messages = [\n",
        "            {\"role\": \"system\", \"content\": f\"{prompt_v4}\"},\n",
        "        ]\n",
        "    response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo-16k\",\n",
        "            messages=messages,\n",
        "            temperature=0,\n",
        "            max_tokens=max_tokens\n",
        "\n",
        "        )\n",
        "    generated_texts = [\n",
        "        choice.message[\"content\"].strip() for choice in response[\"choices\"]\n",
        "    ]\n",
        "    return generated_texts[0]\n",
        "\n",
        "\n",
        "criterion_gen_output = criterion_gen(must_have_skills)\n",
        "print(f'''[Criterion Generation Request] ''', criterion_gen_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XUUTR84hRCF",
        "outputId": "7dd8dc54-e5a2-4973-c741-f1f3cbcbb83d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Criterion Generation Request]  To find a person whose resume has skills in ['TensorFlow', 'Keras', 'PyTorch', 'Computer Vision'], we can follow these steps:\n",
            "\n",
            "1. Read the resume and extract the relevant information.\n",
            "2. Check if the resume mentions any of the required skills ('TensorFlow', 'Keras', 'PyTorch', 'Computer Vision').\n",
            "3. For each skill, assess the candidate's experience level based on the mentioned projects or mentions.\n",
            "4. Assign a score between 0 and 5 for each skill based on the assessment criteria.\n",
            "5. Provide a justification for each skill's score based on the candidate's experience mentioned in the resume.\n",
            "\n",
            "Here's an example of how the assessment can be done:\n",
            "\n",
            "Resume:\n",
            "- Skills: ['TensorFlow', 'Keras', 'PyTorch', 'Computer Vision']\n",
            "- Projects/Mentions:\n",
            "  - TensorFlow: 3 projects\n",
            "  - Keras: 1 mention\n",
            "  - PyTorch: 2 projects\n",
            "  - Computer Vision: 0 projects\n",
            "\n",
            "Assessment:\n",
            "\n",
            "SKILL1 (TensorFlow):\n",
            "- Projects: 3\n",
            "- Score: 5\n",
            "- Justification: The candidate has significant experience in TensorFlow, with 3 mentioned projects.\n",
            "\n",
            "SKILL2 (Keras):\n",
            "- Mentions: 1\n",
            "- Score: 1\n",
            "- Justification: The candidate has some experience in Keras, with 1 mention.\n",
            "\n",
            "SKILL3 (PyTorch):\n",
            "- Projects: 2\n",
            "- Score: 3\n",
            "- Justification: The candidate has good experience in PyTorch, with 2 mentioned projects.\n",
            "\n",
            "SKILL4 (Computer Vision):\n",
            "- Projects: 0\n",
            "- Score: 0\n",
            "- Justification: The candidate has no experience in Computer Vision.\n",
            "\n",
            "Based on this assessment, the candidate's scores for each skill are as follows:\n",
            "\n",
            "{\n",
            "  \"TensorFlow\": {\n",
            "    \"score\": 5,\n",
            "    \"justification\": \"The candidate has significant experience in TensorFlow, with 3 mentioned projects.\"\n",
            "  },\n",
            "  \"Keras\": {\n",
            "    \"score\": 1,\n",
            "    \"justification\": \"The candidate has some experience in Keras, with 1 mention.\"\n",
            "  },\n",
            "  \"PyTorch\": {\n",
            "    \"score\": 3,\n",
            "    \"justification\": \"The candidate has good experience in PyTorch, with 2 mentioned projects.\"\n",
            "  },\n",
            "  \"Computer Vision\": {\n",
            "    \"score\": 0,\n",
            "    \"justification\": \"The candidate has no experience in Computer Vision.\"\n",
            "  }\n",
            "}\n",
            "\n",
            "This assessment provides a score and justification for each skill based on the candidate's experience mentioned in the resume.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:**\n",
        "The output generated by the above cell contains a lot of unnecessary information like as shown below,\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "1. Read the resume and extract the relevant information.\n",
        "2. Check if the resume mentions any of the required skills ('TensorFlow', 'Keras', 'PyTorch', 'Computer Vision').\n",
        "3. For each skill, assess the candidate's experience level based on the mentioned projects or mentions.\n",
        "4. Assign a score between 0 and 5 for each skill based on the assessment criteria.\n",
        "5. Provide a justification for each skill's score based on the candidate's experience mentioned in the resume.\n",
        "\n",
        "Here's an example of how the assessment can be done:\n",
        "\n",
        "Resume:\n",
        "- Skills: ['TensorFlow', 'Keras', 'PyTorch', 'Computer Vision']\n",
        "- Projects/Mentions:\n",
        "  - TensorFlow: 3 projects\n",
        "  - Keras: 1 mention\n",
        "  - PyTorch: 2 projects\n",
        "  - Computer Vision: 0 projects\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "which can harm the final output so we need to focus removing these unwanted information."
      ],
      "metadata": {
        "id": "tepQb3NgghbJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Output:\n",
        "\n",
        "\n",
        "```\n",
        "[Criterion Generation Request]  To find a person whose resume has skills in ['TensorFlow', 'Keras', 'PyTorch', 'Computer Vision'], we can follow these steps:\n",
        "\n",
        "1. Read the resume and extract the relevant information.\n",
        "2. Check if the resume mentions any of the required skills ('TensorFlow', 'Keras', 'PyTorch', 'Computer Vision').\n",
        "3. For each skill, assess the candidate's experience level based on the mentioned projects or mentions.\n",
        "4. Assign a score between 0 and 5 for each skill based on the assessment criteria.\n",
        "5. Provide a justification for each skill's score based on the candidate's experience mentioned in the resume.\n",
        "\n",
        "Here's an example of how the assessment can be done:\n",
        "\n",
        "Resume:\n",
        "- Skills: ['TensorFlow', 'Keras', 'PyTorch', 'Computer Vision']\n",
        "- Projects/Mentions:\n",
        "  - TensorFlow: 3 projects\n",
        "  - Keras: 1 mention\n",
        "  - PyTorch: 2 projects\n",
        "  - Computer Vision: 0 projects\n",
        "\n",
        "Assessment:\n",
        "\n",
        "SKILL1 (TensorFlow):\n",
        "- Projects: 3\n",
        "- Score: 5\n",
        "- Justification: The candidate has significant experience in TensorFlow, with 3 mentioned projects.\n",
        "\n",
        "SKILL2 (Keras):\n",
        "- Mentions: 1\n",
        "- Score: 1\n",
        "- Justification: The candidate has some experience in Keras, with 1 mention.\n",
        "\n",
        "SKILL3 (PyTorch):\n",
        "- Projects: 2\n",
        "- Score: 3\n",
        "- Justification: The candidate has good experience in PyTorch, with 2 mentioned projects.\n",
        "\n",
        "SKILL4 (Computer Vision):\n",
        "- Projects: 0\n",
        "- Score: 0\n",
        "- Justification: The candidate has no experience in Computer Vision.\n",
        "\n",
        "Based on this assessment, the candidate's scores for each skill are as follows:\n",
        "\n",
        "{\n",
        "  \"TensorFlow\": {\n",
        "    \"score\": 5,\n",
        "    \"justification\": \"The candidate has significant experience in TensorFlow, with 3 mentioned projects.\"\n",
        "  },\n",
        "  \"Keras\": {\n",
        "    \"score\": 1,\n",
        "    \"justification\": \"The candidate has some experience in Keras, with 1 mention.\"\n",
        "  },\n",
        "  \"PyTorch\": {\n",
        "    \"score\": 3,\n",
        "    \"justification\": \"The candidate has good experience in PyTorch, with 2 mentioned projects.\"\n",
        "  },\n",
        "  \"Computer Vision\": {\n",
        "    \"score\": 0,\n",
        "    \"justification\": \"The candidate has no experience in Computer Vision.\"\n",
        "  }\n",
        "}\n",
        "\n",
        "This assessment provides a score and justification for each skill based on the candidate's experience mentioned in the resume.\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "fVx28xKHZTc9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Goal*: Double the emphasis on the JSON output format and make the prompt more insistent on replicating the structure of `string_match`.\n",
        "\n",
        "### *Reason*: The outputs still weren't aligning with expectations. By emphasizing the desired format more strongly like by mentioning `string_match` twice and guiding the model explicitly, the aim was to force the model to generate responses that closely mirror the example.\n",
        "\n",
        "# Prompt Version 5:"
      ],
      "metadata": {
        "id": "QRA9iQ1Qr_HJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "string_match = \"\"\"\n",
        "SKILL1 assessment:\n",
        "No projects: 0\n",
        "1 project or mention: one or two\n",
        "2 or 3 projects or mentions: three or four\n",
        "more than or equal to five projects or mentions: five\n",
        "\n",
        "SKILL2 assessment:\n",
        "No projects: 0\n",
        "1 project or mention: one or two\n",
        "2 or 3 projects or mentions: three or four\n",
        "more than or equal to five projects or mentions: five\n",
        "\n",
        "SKILL3 assessment:\n",
        "No projects: 0\n",
        "1 project or mention: one or two\n",
        "2 or 3 projects or mentions: three or four\n",
        "more than or equal to five projects or mentions: five\n",
        "\n",
        "SKILL4 assessment:\n",
        "No projects: 0\n",
        "1 project or mention: one or two\n",
        "2 or 3 projects or mentions: three or four\n",
        "more than or equal to five projects or mentions: five\n",
        "\n",
        "Based on the above criteion the scores can be given in JSON format as shown below,\n",
        "{\n",
        "\"SKILL1\": {\n",
        "    \"score\": 5,\n",
        "    \"justification\": \"The candidate has significant experience in SKILL1, as mentioned in the resume.\"\n",
        "}\n",
        "\"SKILL2\": {\n",
        "    \"score\": 0,\n",
        "    \"justification\": \"The candidate has no experience in SKILL2.\"\n",
        "}\n",
        "\"SKILL3\": {\n",
        "    \"score\": 1,\n",
        "    \"justification\": \"The candidate has some experience in SKILL3\"\n",
        "}\n",
        "\"SKILL4\": {\n",
        "    \"score\": 3,\n",
        "    \"justification\": \"The candidate has good experience in SKILL4.\"\n",
        "}\n",
        "}\n",
        "\"\"\"\n",
        "def criterion_gen(must_have):\n",
        "    model=\"gpt-3.5-turbo-16k\"\n",
        "    max_tokens=4000\n",
        "\n",
        "    prompt_v5 = f'''I have a resume. I want to find a person whose resume has skills in {must_have}. \\\n",
        "    Let's think step by step on how to look into a resume and give score based on each of the skill mentioned in {must_have}. \\\n",
        "    As an example, in the case where the must have skills were \"SKILL1, SKILL2, SKILL3, SKILL4, SKILL5\", here the criterion for \\\n",
        "    judging the resume was {string_match}. So based on the given example of {string_match} give the scoring criterion of {must_have}'''\n",
        "\n",
        "    messages = [\n",
        "            {\"role\": \"system\", \"content\": f\"{prompt_v5}\"},\n",
        "        ]\n",
        "    response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo-16k\",\n",
        "            messages=messages,\n",
        "            temperature=0,\n",
        "            max_tokens=max_tokens\n",
        "        )\n",
        "    generated_texts = [\n",
        "        choice.message[\"content\"].strip() for choice in response[\"choices\"]\n",
        "    ]\n",
        "    return generated_texts[0]\n",
        "\n",
        "\n",
        "\n",
        "criterion_gen_output = criterion_gen(must_have_skills)\n",
        "print(f'''[Criterion Generation Request] ''', criterion_gen_output)\n",
        "\n",
        "def save_to_textfile(filename, criterion_text, string_match_text):\n",
        "    with open(filename, 'w') as file:\n",
        "        file.write(\"----Criterion Generated Output----\\n\")\n",
        "        file.write(criterion_text)\n",
        "        file.write(\"\\n\\n----String Match----\\n\")\n",
        "        file.write(string_match_text)\n",
        "# Save to text file\n",
        "save_to_textfile(\"criterion_and_string_match_output.txt\", criterion_gen_output, string_match)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDQf_2Tjh31w",
        "outputId": "a4b48335-bb79-40e7-e469-462aebf99866"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Criterion Generation Request]  The scoring criterion for the skills ['TensorFlow', 'Keras', 'PyTorch', 'Computer Vision'] can be defined as follows:\n",
            "\n",
            "TensorFlow assessment:\n",
            "- No projects: 0\n",
            "- 1 project or mention: 1\n",
            "- 2 or 3 projects or mentions: 2\n",
            "- More than or equal to five projects or mentions: 5\n",
            "\n",
            "Keras assessment:\n",
            "- No projects: 0\n",
            "- 1 project or mention: 1\n",
            "- 2 or 3 projects or mentions: 2\n",
            "- More than or equal to five projects or mentions: 5\n",
            "\n",
            "PyTorch assessment:\n",
            "- No projects: 0\n",
            "- 1 project or mention: 1\n",
            "- 2 or 3 projects or mentions: 2\n",
            "- More than or equal to five projects or mentions: 5\n",
            "\n",
            "Computer Vision assessment:\n",
            "- No projects: 0\n",
            "- 1 project or mention: 1\n",
            "- 2 or 3 projects or mentions: 2\n",
            "- More than or equal to five projects or mentions: 5\n",
            "\n",
            "Based on the above criteria, the scores for each skill can be given in JSON format as shown below:\n",
            "\n",
            "{\n",
            "  \"TensorFlow\": {\n",
            "    \"score\": 0,\n",
            "    \"justification\": \"The candidate has no experience in TensorFlow.\"\n",
            "  },\n",
            "  \"Keras\": {\n",
            "    \"score\": 2,\n",
            "    \"justification\": \"The candidate has some experience in Keras.\"\n",
            "  },\n",
            "  \"PyTorch\": {\n",
            "    \"score\": 5,\n",
            "    \"justification\": \"The candidate has significant experience in PyTorch, as mentioned in the resume.\"\n",
            "  },\n",
            "  \"Computer Vision\": {\n",
            "    \"score\": 3,\n",
            "    \"justification\": \"The candidate has good experience in Computer Vision.\"\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Output:\n",
        "\n",
        "\n",
        "```\n",
        "[Criterion Generation Request]  To give the scoring criterion for the skills ['Keras', 'TensorFlow', 'PyTorch', 'Computer Vision'], we can follow a similar approach as mentioned in the example. Here is the scoring criterion:\n",
        "\n",
        "Keras assessment:\n",
        "No projects or mentions: 0\n",
        "1 project or mention: one or two\n",
        "2 or 3 projects or mentions: three or four\n",
        "more than or equal to five projects or mentions: five\n",
        "\n",
        "TensorFlow assessment:\n",
        "No projects or mentions: 0\n",
        "1 project or mention: one or two\n",
        "2 or 3 projects or mentions: three or four\n",
        "more than or equal to five projects or mentions: five\n",
        "\n",
        "PyTorch assessment:\n",
        "No projects or mentions: 0\n",
        "1 project or mention: one or two\n",
        "2 or 3 projects or mentions: three or four\n",
        "more than or equal to five projects or mentions: five\n",
        "\n",
        "Computer Vision assessment:\n",
        "No projects or mentions: 0\n",
        "1 project or mention: one or two\n",
        "2 or 3 projects or mentions: three or four\n",
        "more than or equal to five projects or mentions: five\n",
        "\n",
        "Based on the above criteria, the scores can be given in JSON format as shown below:\n",
        "\n",
        "{\n",
        "  \"Keras\": {\n",
        "    \"score\": <score>,\n",
        "    \"justification\": \"<justification>\"\n",
        "  },\n",
        "  \"TensorFlow\": {\n",
        "    \"score\": <score>,\n",
        "    \"justification\": \"<justification>\"\n",
        "  },\n",
        "  \"PyTorch\": {\n",
        "    \"score\": <score>,\n",
        "    \"justification\": \"<justification>\"\n",
        "  },\n",
        "  \"Computer Vision\": {\n",
        "    \"score\": <score>,\n",
        "    \"justification\": \"<justification>\"\n",
        "  }\n",
        "}\n",
        "\n",
        "You can replace `<score>` with the respective score based on the number of projects or mentions in the resume for that skill, and `<justification>` with the justification for the score.\n",
        "\n",
        "For example:\n",
        "\n",
        "{\n",
        "  \"Keras\": {\n",
        "    \"score\": 5,\n",
        "    \"justification\": \"The candidate has significant experience in Keras, as mentioned in the resume.\"\n",
        "  },\n",
        "  \"TensorFlow\": {\n",
        "    \"score\": 3,\n",
        "    \"justification\": \"The candidate has good experience in TensorFlow.\"\n",
        "  },\n",
        "  \"PyTorch\": {\n",
        "    \"score\": 2,\n",
        "    \"justification\": \"The candidate has some experience in PyTorch.\"\n",
        "  },\n",
        "  \"Computer Vision\": {\n",
        "    \"score\": 4,\n",
        "    \"justification\": \"The candidate has extensive experience in Computer Vision, as mentioned in the resume.\"\n",
        "  }\n",
        "}\n",
        "\n",
        "You can adjust the scoring criteria and justification based on the specific requirements and expectations for each skill.\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "nTsUrO94aw6I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iterative prompt development is essential when trying to obtain specific outputs from language models like GPT-3.5. By gradually refining the prompt and giving explicit examples, the user can guide the model towards producing results that align closely with the requirements.\n",
        "\n",
        "\n",
        "We save the generated criteria in a text file so that it can be used to calculate score in the next assignment"
      ],
      "metadata": {
        "id": "KKKV9cufsPwU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have to download the textfile **criterion_and_string_match_output.txt** so that we can use the string match text and the criteria generated in the next assignments"
      ],
      "metadata": {
        "id": "IYW5AfaMKO5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# List of file paths that you want to download\n",
        "file_path = \"/content/criterion_and_string_match_output.txt\"\n",
        "\n",
        "# Download each file to your local system\n",
        "files.download(file_path)"
      ],
      "metadata": {
        "id": "XbPP7614oAO4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "527afacc-6252-4808-b7ed-e7797e068c04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c45d70b0-39c6-4f84-b2c5-08a96dc77288\", \"criterion_and_string_match_output.txt\", 2531)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dh12W-_3Kg_I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}