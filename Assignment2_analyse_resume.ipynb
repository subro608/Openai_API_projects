{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eu6seujXuV2a"
      },
      "source": [
        "# Description:\n",
        "\n",
        "This notebook aims to automate parts of the recruitment process by filtering potential job applicants based on specific criteria outlined in a job description.\n",
        "\n",
        "Initially, the notebook sets up the necessary tools and files by installing required packages. The core logic consists of various utility functions to filter candidates based on criteria like CTC (Cost to Company or salary expectations), location, and notice period. Candidates' information is randomly generated, and the resultant shortlisted candidates are saved as a JSON file.\n",
        "\n",
        "# Learning Objectives:\n",
        "Efficiently filter candidate data based on CTC, location, and notice period using Python coupled with OpenAI's GPT 3.5 capabilities.\n",
        "This will show the power of the API to do complex tasks, for which a lot of rules in NLP would have to be written"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload the .env file to the directory `/content/` which contains the \"OPENAI_API_KEY\""
      ],
      "metadata": {
        "id": "pyu1Ye6sdSLy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plnlXJ4D06Wc"
      },
      "outputs": [],
      "source": [
        "# Libraries Installation\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNlDscmRX--1"
      },
      "source": [
        "We set up our environment to use OpenAI's API for extracting information from Job Descriptions (JD). We'll use Python as our primary language and leverage the OpenAI library to interact with OpenAI's services\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the \"OPENAI_API_KEY\" from the .env file"
      ],
      "metadata": {
        "id": "z4044lWbZVAp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7PyU_wIbTXm5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2b9518d-ae74-4ff3-c9c1-7f30fcdbbfe4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Export your API Key to environment variable\n",
        "# Upload the .env file to the directory \"/content/\"\n",
        "!pip install python-dotenv\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "# Retrieve the API key from environment variable\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Set the API key for OpenAI\n",
        "openai.api_key = openai_api_key"
      ],
      "metadata": {
        "id": "r-erbKeTaqVT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload the json file containing important information about the Job requirements which was generated in Assignment1"
      ],
      "metadata": {
        "id": "YJmJl_b_KDiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "VBy6HwXLJq-l",
        "outputId": "cccd47a1-deaa-407a-e860-f07b9ecafda8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-056a03e0-ad93-4dd1-b01e-182d7a63910b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-056a03e0-ad93-4dd1-b01e-182d7a63910b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving requirements_output.json to requirements_output.json\n",
            "User uploaded file \"requirements_output.json\" with length 1191 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the `resume_data.zip` file containing all the resumes from google drive"
      ],
      "metadata": {
        "id": "XXR_a1SZX8_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "# https://drive.google.com/file/d/17V_o0Snt-Lj0FmegENPQ_rXpvWTWlZgQ/view?usp=sharing\n",
        "def download_file_from_google_drive(file_id, destination):\n",
        "    base_url = \"https://drive.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(base_url, params={'id': file_id}, stream=True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = {'id': file_id, 'confirm': token}\n",
        "        response = session.get(base_url, params=params, stream=True)\n",
        "\n",
        "    save_response_content(response, destination)\n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk:\n",
        "                f.write(chunk)\n",
        "# Example Usage\n",
        "# file_id = '1HaM3IeK2-iqyZzeQmCnAzKLcF9NF-mSo'  # Replace with your file's ID\n",
        "# destination = 'resume_data.zip'\n",
        "file_id = '17V_o0Snt-Lj0FmegENPQ_rXpvWTWlZgQ'\n",
        "destination = 'Webinar_resumes.zip'  # Replace with your desired file name and extension\n",
        "download_file_from_google_drive(file_id, destination)"
      ],
      "metadata": {
        "id": "15VPjlbpYHAZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okQD0GPjr-E6"
      },
      "source": [
        "# **Random Data Generation**\n",
        "\n",
        "# `ResumeProcessor` Class Definition\n",
        "#### **__init__** Method:\n",
        "Initializes an instance of the class with a path to a zip file containing resumes.\n",
        "\n",
        "#### **get_ctc_bounds** Method:\n",
        "Uses the GPT-3.5 Turbo model to extract the lower and upper salary bounds from a string given in the format \"XX-YY\". It returns these bounds as floats.\n",
        "\n",
        "```python\n",
        "def get_ctc_bounds(self, ctc_range):\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are an assistant to a recruiter. You will be given a range consisting of lower and upper salary amount in dollars. \\\n",
        "            Return the upper and lower values in dollars in expanded form. No currency should be mentioned. Output should be in JSON like {'lower':lower salary, 'upper': upper salary}\"},\n",
        "            {\"role\": \"user\", \"content\": f\"The salary range is {ctc_range}.\"},\n",
        "        ]\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=messages,\n",
        "            temperature=0,\n",
        "            max_tokens=1000\n",
        "        )\n",
        "        generated_texts = [choice.message[\"content\"].strip() for choice in response[\"choices\"]]\n",
        "        # print(\"iniital output\", generated_texts)\n",
        "\n",
        "        pattern = r'(\\d{1,3}(?:,\\d{3})*)\\s*(dollars)?'\n",
        "\n",
        "        matches = re.findall(pattern, generated_texts[0])\n",
        "        # print(\"matches\", matches)\n",
        "        if matches and len(matches) == 2:\n",
        "\n",
        "\n",
        "            # Extracting lower and upper salary from the matches and removing commas\n",
        "            try:\n",
        "              lower_salary = float(matches[0].replace(',', ''))\n",
        "              upper_salary = float(matches[1].replace(',', ''))\n",
        "            except:\n",
        "              lower_salary = float(matches[0][0].replace(',', ''))\n",
        "              upper_salary = float(matches[1][0].replace(',', ''))\n",
        "\n",
        "            return lower_salary, upper_salary\n",
        "        else:\n",
        "            return None\n",
        "        return generated_texts[0]\n",
        "```\n",
        "\n",
        "#### **convert_notice_period_to_days** Method:\n",
        "Again uses the GPT-3.5 Turbo model to convert the notice period from various formats to an integer value of days.\n",
        "\n",
        "```python\n",
        "def convert_notice_period_to_days(self, jd_notice):\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You're assisting a recruiter. Convert the provided notice period into days. \\\n",
        "            1 month is typically 30 days, and 1 year is 365 days. The final output should be 'Days': Number of days.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Given notice period: {jd_notice}. Return the output in json with the field 'Days'\"}\n",
        "        ]\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=messages,\n",
        "            temperature=0,\n",
        "            max_tokens=1000\n",
        "        )\n",
        "        generated_texts = [choice.message[\"content\"].strip() for choice in response[\"choices\"]]\n",
        "        # print(generated_texts, generated_texts[0])\n",
        "        return int(re.findall(r'\\d+', generated_texts[0])[0])\n",
        "```\n",
        "\n",
        "\n",
        "#### **extract_and_rename** Method:\n",
        "Extracts the contents of the zip file to a specified directory, and renames directories that contain spaces to use underscores. It returns the path where the resumes are located.\n",
        "\n",
        "#### **generate_random_data** Method:\n",
        "This method randomly generates data for a given resume based on the given job requirements. For instance:\n",
        "\n",
        "1. It decides a candidate's current and expected CTC based on a distribution logic.\n",
        "\n",
        "2. It assigns a current location from a predefined list of major cities.\n",
        "\n",
        "3. It determines the notice period (in days) for the candidate.\n",
        "\n",
        "#### **random_data_resumes** Method:\n",
        "This is the main function of the class:\n",
        "\n",
        "1. It first extracts the resumes from the zip file.\n",
        "2. Reads job requirements from an external JSON file.\n",
        "3. Converts notice period requirements into days.\n",
        "4. Loops through each resume file.\n",
        "5. Generates a pseudo email address from the resume's filename.\n",
        "6. Invokes the generate_random_data method to generate random data for the current resume.\n",
        "7. Appends this information to an 'applications' list.\n",
        "Saves the combined resume information for all candidates to a JSON file named \"all_applications.json\".\n",
        "\n",
        "### **Code Execution**\n",
        "Finally, an instance of the ResumeProcessor class is created using the path to a zip file containing resumes. The random_data_resumes method is called on this instance to process the resumes and generate the JSON output.\n",
        "\n",
        "In summary, this code automates the process of extracting resumes from a zip file, generating associated random data based on job requirements, and saving this data in a structured JSON format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ekjDSiiYvzE2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75388768-6eea-4729-ea58-ab3724f9782b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100000.0, 150000.0)\n"
          ]
        }
      ],
      "source": [
        "# Required Libraries\n",
        "import os\n",
        "import openai\n",
        "import json\n",
        "import random\n",
        "import zipfile\n",
        "import re\n",
        "import shutil\n",
        "from collections import OrderedDict\n",
        "\n",
        "class ResumeProcessor:\n",
        "    def __init__(self):\n",
        "        self.resume_counter = 1\n",
        "    # Function to extract the CTC bounds from a given string in the format \"XX-YY\".\n",
        "    def get_ctc_bounds(self, ctc_range):\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are an assistant to a recruiter. You will be given a range consisting of lower and upper salary amount in dollars. \\\n",
        "            Return the upper and lower values in dollars in expanded form. No currency should be mentioned. Output should be in JSON like {'lower':lower salary, 'upper': upper salary}\"},\n",
        "            {\"role\": \"user\", \"content\": f\"The salary range is {ctc_range}.\"},\n",
        "        ]\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=messages,\n",
        "            temperature=0,\n",
        "            max_tokens=1000\n",
        "        )\n",
        "        generated_texts = [choice.message[\"content\"].strip() for choice in response[\"choices\"]]\n",
        "        # print(\"iniital output\", generated_texts)\n",
        "\n",
        "        pattern = r'(\\d{1,3}(?:,\\d{3})*)\\s*(dollars)?'\n",
        "\n",
        "        matches = re.findall(pattern, generated_texts[0])\n",
        "        # print(\"matches\", matches)\n",
        "        if matches and len(matches) == 2:\n",
        "\n",
        "\n",
        "            # Extracting lower and upper salary from the matches and removing commas\n",
        "            try:\n",
        "              lower_salary = float(matches[0].replace(',', ''))\n",
        "              upper_salary = float(matches[1].replace(',', ''))\n",
        "            except:\n",
        "              lower_salary = float(matches[0][0].replace(',', ''))\n",
        "              upper_salary = float(matches[1][0].replace(',', ''))\n",
        "\n",
        "            return lower_salary, upper_salary\n",
        "        else:\n",
        "            return None\n",
        "        return generated_texts[0]\n",
        "\n",
        "    def convert_notice_period_to_days(self, jd_notice):\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You're assisting a recruiter. Convert the provided notice period into days. \\\n",
        "            1 month is typically 30 days, and 1 year is 365 days. The final output should be 'Days': Number of days.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Given notice period: {jd_notice}. Return the output in json with the field 'Days'\"}\n",
        "        ]\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=messages,\n",
        "            temperature=0,\n",
        "            max_tokens=1000\n",
        "        )\n",
        "        generated_texts = [choice.message[\"content\"].strip() for choice in response[\"choices\"]]\n",
        "        # print(generated_texts, generated_texts[0])\n",
        "        return int(re.findall(r'\\d+', generated_texts[0])[0])\n",
        "    def extract_and_rename(self, zip_file_path):\n",
        "        # Specify the directory where the files will be extracted.\n",
        "        extract_path = \"extracted_files\"\n",
        "\n",
        "        # Open the zip file for reading.\n",
        "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "            # Extract all files/directories in the zip to the specified directory.\n",
        "            zip_ref.extractall(extract_path)\n",
        "\n",
        "        # Start by assuming the path for the resumes is the extraction directory.\n",
        "        resume_path = extract_path\n",
        "\n",
        "        # Loop over each item (file or directory) in the extraction directory.\n",
        "        for item in os.listdir(extract_path):\n",
        "            # Construct the full path for the item.\n",
        "            item_path = os.path.join(extract_path, item)\n",
        "\n",
        "            # Check if the current item is a directory and if its name contains spaces.\n",
        "            if os.path.isdir(item_path) and ' ' in item:\n",
        "                # Replace spaces in the directory name with underscores.\n",
        "                new_name = item.replace(' ', '_')\n",
        "                # Construct the new path for the directory after renaming.\n",
        "                new_path = os.path.join(extract_path, new_name)\n",
        "\n",
        "                # If a directory with the new name doesn't already exist, create one.\n",
        "                if not os.path.exists(new_path):\n",
        "                    os.makedirs(new_path)\n",
        "\n",
        "                # Copy each file/sub-item from the old directory (with spaces in the name) to the new directory.\n",
        "                for sub_item in os.listdir(item_path):\n",
        "                    shutil.copy2(os.path.join(item_path, sub_item), new_path)\n",
        "\n",
        "                # Remove the old directory (with spaces in the name).\n",
        "                shutil.rmtree(item_path)\n",
        "                # Update the resume path to point to the new directory.\n",
        "                resume_path = new_path\n",
        "            else:\n",
        "                # If the item is not a directory (i.e., it's a file), update the resume path to point to this file.\n",
        "                resume_path = item_path\n",
        "\n",
        "        # Return the path where the resumes are located (either a directory or a single file).\n",
        "        return resume_path\n",
        "\n",
        "    def generate_random_data(self, upper_bound, lower_bound, total_resumes, max_notice_period_days):\n",
        "        # Define a list of Californian cities.\n",
        "        californian_cities = ['San Francisco', 'San Diego', 'Sacramento', 'Oakland']\n",
        "\n",
        "        # Modify thresholds to skew random generation towards more favorable candidates.\n",
        "        threshold_80_percent = 0.80 * total_resumes  # Increased from 50%\n",
        "        threshold_90_percent = 0.90 * total_resumes\n",
        "        threshold_10_percent = 0.10 * total_resumes  # Increased from 20%\n",
        "\n",
        "        # Skew CTC generation to be within the desired range for 80% of candidates.\n",
        "        if self.resume_counter < threshold_80_percent:\n",
        "            current_ctc = round(random.uniform(lower_bound, upper_bound), 1)\n",
        "            expected_ctc = round(random.uniform(current_ctc + 1, upper_bound), 1)\n",
        "        else:\n",
        "            current_ctc = round(random.uniform(0.5 * lower_bound, lower_bound - 1), 1)\n",
        "            expected_ctc = round(random.uniform(current_ctc + 1, upper_bound), 1)\n",
        "\n",
        "        # 90% candidates are willing to relocate.\n",
        "        if self.resume_counter < threshold_90_percent:\n",
        "            willing_to_relocate = \"yes\"\n",
        "        else:\n",
        "            willing_to_relocate = \"no\"\n",
        "\n",
        "        # Adjust notice period distribution.\n",
        "        if self.resume_counter < threshold_10_percent:\n",
        "            notice_period = f\"{random.randint(max_notice_period_days + 1, max_notice_period_days + 30)} days\"\n",
        "        else:\n",
        "          notice_period = f\"{random.randint(10, max_notice_period_days//2)} days\"\n",
        "\n",
        "        current_location = random.choice(californian_cities)\n",
        "        self.resume_counter += 1\n",
        "\n",
        "        return current_ctc, expected_ctc, willing_to_relocate, current_location, notice_period\n",
        "\n",
        "    def random_data_resumes(self, zip_file_path):\n",
        "        # Extract resumes from the zip file and rename them if necessary.\n",
        "        resume_path = self.extract_and_rename(zip_file_path)\n",
        "\n",
        "        # List out all the resume files present in the extracted path with specific extensions (.pdf, .doc, .docx).\n",
        "        resume_files = [f for f in os.listdir(resume_path) if f.endswith(('.pdf', '.doc', '.docx'))]\n",
        "        applications = []\n",
        "\n",
        "        # Read the job requirements from the \"requirements_output.json\" file.\n",
        "        with open(\"requirements_output.json\", \"r\") as f:\n",
        "            job_req = json.load(f)\n",
        "        # Convert the notice period (from job requirements) to days.\n",
        "        notice_period_criteria = self.convert_notice_period_to_days(job_req.get(\"notice_period\", \"\"))\n",
        "        # Get the lower and upper bounds of the CTC from the job requirements.\n",
        "        print(self.get_ctc_bounds(job_req.get(\"CTC\", \"\")))\n",
        "        lower_bound, upper_bound = self.get_ctc_bounds(job_req.get(\"CTC\", \"\"))\n",
        "\n",
        "        # Iterate over each resume file.\n",
        "        for filename in resume_files:\n",
        "            resume_file_path = os.path.join(resume_path, filename)\n",
        "            # Generate an email ID using the filename (assuming the file name does not contain periods other than the file extension).\n",
        "            email_id = filename.split('.')[0] + \"@example.com\"\n",
        "            # Generate random data for the current resume.\n",
        "            current_ctc, expected_ctc, willing_to_relocate, current_location, notice_period = self.generate_random_data(upper_bound, lower_bound, len(resume_files), notice_period_criteria)\n",
        "\n",
        "            # Append the generated data for the current resume to the applications list.\n",
        "            applications.append({\n",
        "                'current_ctc': current_ctc,\n",
        "                'expected_ctc': expected_ctc,\n",
        "                'willing_to_relocate': willing_to_relocate,\n",
        "                'current_location': current_location,\n",
        "                'notice_period': notice_period,\n",
        "                'email_id': email_id,\n",
        "                'resume_path': filename\n",
        "            })\n",
        "\n",
        "        # Save the entire applications list to a JSON file.\n",
        "        with open(\"all_applications.json\", \"w\") as f:\n",
        "            json.dump(applications, f, indent=4)\n",
        "\n",
        "# Using the class:\n",
        "processor = ResumeProcessor()\n",
        "processor.random_data_resumes(\"/content/Webinar_resumes.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:**\n",
        "In the above cell, the method **get_ctc_bounds** uses OpenAI API because the input CTC range can vary a lot and so, normal heuristics would not have worked on it. For example:\n",
        "1. For Input get_ctc_bounds(\"12k-1.5 milllion\") Output: (12000.0, 1500000.0)\n",
        "2. For Input get_ctc_bounds(\"12k-15k\") Output: (12000.0, 15000.0)\n",
        "3. For Input get_ctc_bounds(\"3-20\") Output: (3.0, 20.0)\n",
        "\n",
        "Another method that uses OpenAI API is **convert_notice_period_to_days**, in order to convert notice periods to days format.\n",
        "For example:\n",
        "1. For Input convert_notice_period_to_days(\"0.5 months\") Output: 15\n",
        "2. For Input convert_notice_period_to_days(\"9.8 months\") Output: 294\n",
        "3. For Input convert_notice_period_to_days(\"months 2\") Output: 60\n",
        "4. For Input convert_notice_period_to_days(\"months_2.5\") Output: 75"
      ],
      "metadata": {
        "id": "A6fFJHr9rJoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing various formats for CTC:\n",
        "result = processor.get_ctc_bounds(\"100k-150k\")\n",
        "print(f\"Input '100k-150k', Output: {result} \\n\")\n",
        "\n",
        "result = processor.get_ctc_bounds(\"100k to 150k\")\n",
        "print(f\"Input '100k to 150k', Output: {result} \\n\")\n",
        "\n",
        "result = processor.get_ctc_bounds(\"100k and 150k\")\n",
        "print(f\"Input '100k and 150k', Output: {result} \\n\")\n",
        "\n",
        "result = processor.get_ctc_bounds(\"min: 100k & max: 150k\")\n",
        "print(f\"Input 'min: 100k & max: 150k', Output: {result} \\n\")\n",
        "\n",
        "result = processor.get_ctc_bounds(\"250,000 to 1M\")\n",
        "print(f\"Input '250,000 to 1M', Output: {result} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIivkadDg3Zi",
        "outputId": "dd812471-da3d-4940-d796-5a8f5b1baf49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input '100k-150k', Output: (100000.0, 150000.0) \n",
            "\n",
            "Input '100k to 150k', Output: (100000.0, 150000.0) \n",
            "\n",
            "Input '100k and 150k', Output: (100000.0, 150000.0) \n",
            "\n",
            "Input 'min: 100k & max: 150k', Output: (100000.0, 150000.0) \n",
            "\n",
            "Input '250,000 to 1M', Output: (250000.0, 1000000.0) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing various formats for Notice period:\n",
        "result = processor.convert_notice_period_to_days(\"1 month\")\n",
        "print(f\"Input '1 month', Output: {result} \\n\")\n",
        "\n",
        "result = processor.convert_notice_period_to_days(\"1 Month\")\n",
        "print(f\"Input '1 Month', Output: {result} \\n\")\n",
        "\n",
        "result = processor.convert_notice_period_to_days(\"33 days\")\n",
        "print(f\"Input '33 days', Output: {result} \\n\")\n",
        "\n",
        "result = processor.convert_notice_period_to_days(\"Immideate\")\n",
        "print(f\"Input 'Immideate', Output: {result} \\n\")\n",
        "\n",
        "result = processor.convert_notice_period_to_days(\"3600 hours\")\n",
        "print(f\"Input '3600 hours', Output: {result} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAA_fZhShvbL",
        "outputId": "e534e701-df9c-40ef-9a5c-16ceeac57aa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input '1 month', Output: 30 \n",
            "\n",
            "Input '1 Month', Output: 30 \n",
            "\n",
            "Input '33 days', Output: 33 \n",
            "\n",
            "Input 'Immideate', Output: 0 \n",
            "\n",
            "Input '3600 hours', Output: 150 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Filtration using CTC\n",
        "\n",
        "The provided code defines a **FilterCTC** class which is intended to filter candidates' resumes based on their Current Total Compensation (CTC) and Expected Total Compensation in comparison to the budget range of a company.\n",
        "# **Key Components of the FilterCTC class:**\n",
        "1. **Initialization**:\n",
        "The __init__ method initializes the class. It creates an instance of the **ResumeProcessor** class and assigns it to the **processor** attribute. This suggests that the **FilterCTC** class is dependent on functionalities provided by the **ResumeProcessor** class mainly on the **get_ctc_bounds** method which takes a range of CTC as input and gives the lower and upper limit.\n",
        "2. **CTC Check**:\n",
        "The **get_ctc_check** method checks whether a candidate's current and expected CTC are within the company's budget range. It uses OpenAI's GPT-3.5 model to make this decision and returns True if both the candidate's current and expected CTC fall within the budget range, otherwise it returns False.\n",
        "```python\n",
        "def get_ctc_check(self, budget_min, budget_max, cr_ctc, exp_ctc):\n",
        "        \"\"\"\n",
        "        Check if the candidate's current and expected CTC are within the company's budget range.\n",
        "\n",
        "        :param budget_min: Minimum budget of the company for CTC\n",
        "        :param budget_max: Maximum budget of the company for CTC\n",
        "        :param cr_ctc: Candidate's current CTC\n",
        "        :param exp_ctc: Candidate's expected CTC\n",
        "\n",
        "        :return: True if candidate's CTC is within budget, else False\n",
        "        \"\"\"\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are an assistant to a recruiter. You will be given the budget of the company (a range), candidate's current total compensation, and expected total compensation. \\\n",
        "            Return 'yes' if the current compensation is greater than the budget minimum and the expected total compensation is less than the maximum budget. Both conditions should be met for a 'yes'. For all other cases, return 'no'.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Company budget minimum: {budget_min}, company budget maximum: {budget_max}, candidate current total compensation: {cr_ctc}, candidate total expected compensation: {exp_ctc}\"},\n",
        "        ]\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=messages,\n",
        "            temperature=0,\n",
        "            max_tokens=1000\n",
        "        )\n",
        "        result = response.choices[0].message[\"content\"].strip().lower()\n",
        "        return result == \"yes\"\n",
        "```\n",
        "3. **Filtering Resumes Based on CTC**:\n",
        "This method is responsible for the primary functionality:\n",
        "It loads a list of applications (resumes) and job requirements from two separate JSON files.\n",
        "It retrieves the CTC bounds (i.e., lower and upper limits) from the job requirements.\n",
        "It then filters the applications based on the current and expected CTC, ensuring they fall within the bounds. Afther that two new JSON files are created, **filtered_applications_ctc.json** containing the applications that meet the CTC criteria and **removed_resume_ctc.json** containing the applications that did not meet the criteria.\n",
        "\n",
        "# **Execution:**\n",
        "The code concludes by creating an instance of the **FilterCTC** class and invoking the **filter_CTC_resumes** method, which triggers the resume filtering process based on the CTC criteria."
      ],
      "metadata": {
        "id": "lEdQskENsgsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import json\n",
        "from collections import OrderedDict\n",
        "import re\n",
        "\n",
        "class FilterCTC:\n",
        "    def __init__(self):\n",
        "        # Create an instance of the resume processor class\n",
        "        self.processor = ResumeProcessor()\n",
        "\n",
        "    def get_ctc_check(self, budget_min, budget_max, cr_ctc, exp_ctc):\n",
        "        \"\"\"\n",
        "        Check if the candidate's current and expected CTC are within the company's budget range.\n",
        "\n",
        "        :param budget_min: Minimum budget of the company for CTC\n",
        "        :param budget_max: Maximum budget of the company for CTC\n",
        "        :param cr_ctc: Candidate's current CTC\n",
        "        :param exp_ctc: Candidate's expected CTC\n",
        "\n",
        "        :return: True if candidate's CTC is within budget, else False\n",
        "        \"\"\"\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are an assistant to a recruiter. You will be given the budget of the company (a range), candidate's current total compensation, and expected total compensation. \\\n",
        "            Return 'yes' if the current compensation is greater than the budget minimum and the expected total compensation is less than the maximum budget. Both conditions should be met for a 'yes'. For all other cases, return 'no'.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Company budget minimum: {budget_min}, company budget maximum: {budget_max}, candidate current total compensation: {cr_ctc}, candidate total expected compensation: {exp_ctc}\"},\n",
        "        ]\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=messages,\n",
        "            temperature=0,\n",
        "            max_tokens=1000\n",
        "        )\n",
        "        result = response.choices[0].message[\"content\"].strip().lower()\n",
        "        return result == \"yes\"\n",
        "\n",
        "    def filter_CTC_resumes(self):\n",
        "        \"\"\"\n",
        "        Load resumes and job requirements, and filter out resumes based on CTC.\n",
        "        The filtered resumes are saved to 'filtered_applications_ctc.json' and the ones which didn't meet criteria to 'removed_resume_ctc.json'.\n",
        "        \"\"\"\n",
        "        # Load all applications from the JSON file\n",
        "        with open(\"all_applications.json\", \"r\") as f:\n",
        "            applications = json.load(f)\n",
        "\n",
        "        # Load job requirements from the JSON file\n",
        "        with open(\"requirements_output.json\", \"r\") as f:\n",
        "            job_req = json.load(f)\n",
        "\n",
        "        # Assume a method exists to get the CTC bounds from the job requirements\n",
        "        lower_bound, upper_bound = self.processor.get_ctc_bounds(job_req.get(\"CTC\", \"\"))\n",
        "\n",
        "        # Filter the applications based on the current and expected CTC criteria\n",
        "        filtered_applications_ctc = [app for app in applications if self.get_ctc_check(lower_bound, upper_bound, app['current_ctc'], app['expected_ctc'])]\n",
        "\n",
        "        # Identify the applications that were removed due to not meeting the CTC criteria\n",
        "        removed_due_to_ctc = [app for app in applications if app not in filtered_applications_ctc]\n",
        "\n",
        "        # Save the filtered applications to a new JSON file\n",
        "        with open(\"filtered_applications_ctc.json\", \"w\") as f:\n",
        "            json.dump(filtered_applications_ctc, f, indent=4)\n",
        "\n",
        "        # Save the applications that didn't meet the criteria to a separate JSON file\n",
        "        with open(\"removed_resume_ctc.json\", \"w\") as f:\n",
        "            json.dump(removed_due_to_ctc, f, indent=4)\n",
        "filterctc = FilterCTC()\n",
        "filterctc.filter_CTC_resumes()"
      ],
      "metadata": {
        "id": "EHoSGysssgEd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**:\n",
        "For **FilterCTC** class we use the method **get_ctc_check**, which uses OpenAI api, as the input values can vary a lot and so normal heuristics would not have worked.\n",
        "For example:\n",
        "1. For Input get_ctc_check(\"15.99k\", \"230.99k\", \"160,000\", \"220k\") Output: True\n",
        "2. For Input get_ctc_check(\"15.99k\", \"220k\", \"160,000\", \"1.1 mil\") Output: False\n",
        "3. For Input get_ctc_check(\"1.99k\", \"230000\", \"2000\", \"220k\") Output: True"
      ],
      "metadata": {
        "id": "pX2CozVbuLpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing various formats for CTC check:\n",
        "budget_min = \"100k\"\n",
        "budget_max = \"150k\"\n",
        "cr_ctc = \"120,000\"\n",
        "exp_ctc = \"140,000\"\n",
        "result = filterctc.get_ctc_check(budget_min, budget_max, cr_ctc, exp_ctc)\n",
        "print(f\"Input '{budget_min, budget_max, cr_ctc, exp_ctc}', Output: {result} \\n\")\n",
        "\n",
        "budget_min = \"100k\"\n",
        "budget_max = \"150000\"\n",
        "cr_ctc = \"120k\"\n",
        "exp_ctc = \"0.14M\"\n",
        "result = filterctc.get_ctc_check(budget_min, budget_max, cr_ctc, exp_ctc)\n",
        "print(f\"Input '{budget_min, budget_max, cr_ctc, exp_ctc}', Output: {result} \\n\")\n",
        "\n",
        "budget_min = \"100k\"\n",
        "budget_max = \"150k\"\n",
        "cr_ctc = \"120,000\"\n",
        "exp_ctc = \"170,000\"\n",
        "result = filterctc.get_ctc_check(budget_min, budget_max, cr_ctc, exp_ctc)\n",
        "print(f\"Input '{budget_min, budget_max, cr_ctc, exp_ctc}', Output: {result} \\n\")\n",
        "\n",
        "budget_min = \"100k\"\n",
        "budget_max = \"150000\"\n",
        "cr_ctc = \"120k\"\n",
        "exp_ctc = \"1.4 Million\"\n",
        "result = filterctc.get_ctc_check(budget_min, budget_max, cr_ctc, exp_ctc)\n",
        "print(f\"Input '{budget_min, budget_max, cr_ctc, exp_ctc}', Output: {result} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJz0preqjMse",
        "outputId": "a4219a95-59f0-4579-8dbc-b49515784311"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input '('100k', '150k', '120,000', '140,000')', Output: True \n",
            "\n",
            "Input '('100k', '150000', '120k', '0.14M')', Output: True \n",
            "\n",
            "Input '('100k', '150k', '120,000', '170,000')', Output: False \n",
            "\n",
            "Input '('100k', '150000', '120k', '1.4 Million')', Output: False \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **FilterCity Class Description**:\n",
        "\n",
        "### **Initialization**:\n",
        "\n",
        "The class is initialized with paths to two JSON files:\n",
        "1. one containing job requirements (job_requirements_path) and another containing previously filtered applications based on CTC (filtered_ctc_applications_path).\n",
        "2. Upon initialization, it reads and loads these JSON files into respective instance variables.\n",
        "\n",
        "### **check_city Method**:\n",
        "\n",
        "1. This method interacts with the OpenAI GPT-3.5-turbo model.\n",
        "2. Given a candidate's current city and the job's city, the method checks if they are the same (even considering minor variations or typos) or if they're within a default 1-hour drive of each other.\n",
        "3. The result is either \"yes\" or \"no\".\n",
        "```python\n",
        "def check_city(self, current_city, job_city, drive_hour = \"1-hour\"):\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": f\"You're assisting a recruiter. Determine if the candidate's current city ({current_city}) and the prospective job city ({job_city})\\\n",
        "            are the same (even if the names vary or there may be spelling mistakes) or whether both the cities are within a {drive_hour} drive by car from each other, in that case you should \\\n",
        "            return 'yes', otherwise return 'no'.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Candidate's current city: {current_city}. Job's city: {job_city}.\"}\n",
        "        ]\n",
        "\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=messages,\n",
        "            temperature=0,\n",
        "            max_tokens=1000\n",
        "        )\n",
        "        generated_texts = [choice.message[\"content\"].strip() for choice in response[\"choices\"]]\n",
        "        return \"Yes\" in generated_texts or \"yes\" in generated_texts\n",
        "```\n",
        "\n",
        "### **filter_by_willing_to_relocate_and_city Method**:\n",
        "\n",
        "1. Filters the candidates based on their current city and their willingness to relocate.\n",
        "2. If a candidate's current city is the same as the job's city or if they are willing to relocate, they are added to the filtered list.\n",
        "3. For candidates not in the same city and not willing to relocate, it checks with the check_city method to determine if the two cities are close enough. If they are, the candidate is added to the filtered list.\n",
        "\n",
        "### **save_filtered_and_removed Method:**\n",
        "\n",
        "This method saves two sets of data:\n",
        "\n",
        "1. The final list of filtered applicants based on city constraints.\n",
        "2. The list of candidates removed due to not meeting the city criteria.\n",
        "Both lists are saved as separate JSON files.\n",
        "\n",
        "### **process_filtering Method**:\n",
        "This is the main execution method for the class. It calls the filtering function and then the saving function to process and store the results.\n",
        "\n",
        "Finally, after defining the class, an instance of the **FilterCity** class is created and the **process_filtering** method is called, which triggers the whole filtering and saving operation."
      ],
      "metadata": {
        "id": "vOCcFjMPsoQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import json\n",
        "\n",
        "class FilterCity:\n",
        "    # Initialize the object with job requirements and filtered ctc applications\n",
        "    def __init__(self, job_requirements_path, filtered_ctc_applications_path):\n",
        "        # Load the job requirements from the given file\n",
        "        with open(job_requirements_path, \"r\") as f:\n",
        "            self.job_req = json.load(f)\n",
        "\n",
        "        # Load the previously filtered applications from the given file\n",
        "        with open(filtered_ctc_applications_path, \"r\") as f:\n",
        "            self.filtered_applications_ctc = json.load(f)\n",
        "\n",
        "    def check_city(self, current_city, job_city, drive_hour = \"1-hour\"):\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": f\"You're assisting a recruiter. \\\n",
        "            Determine if the candidate's current city ({current_city}) and the prospective job city ({job_city})\\\n",
        "            are the same (even if the names vary or there may be spelling mistakes) then return 'yes'.\\\n",
        "            If both the cities {current_city} & {job_city} are within a {drive_hour} drive by car from each other, in that case you should \\\n",
        "            return 'yes', otherwise return 'no'.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Candidate's current city: {current_city}. Job's city: {job_city}.\"}\n",
        "        ]\n",
        "\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=messages,\n",
        "            temperature=0,\n",
        "            max_tokens=100\n",
        "        )\n",
        "        generated_texts = [choice.message[\"content\"].strip() for choice in response[\"choices\"]]\n",
        "        return \"Yes\" in generated_texts or \"yes\" in generated_texts\n",
        "    # Filter applicants based on their willingness to relocate or if they are in the same city\n",
        "    def filter_by_willing_to_relocate_and_city(self):\n",
        "        filtered_applications = []\n",
        "        job_city = self.job_req.get(\"City\", \"\")\n",
        "\n",
        "        # Iterate through each application\n",
        "        for application in self.filtered_applications_ctc:\n",
        "            # If the 'willing_to_relocate' field is 'n.a.', set it to 'yes'\n",
        "            if application['willing_to_relocate'].lower() == \"n.a.\":\n",
        "                application['willing_to_relocate'] = 'yes'\n",
        "\n",
        "            # Check if the applicant's current location matches the job city\n",
        "            same_city = application['current_location'].lower() == job_city.lower()\n",
        "\n",
        "            # Check if the applicant is willing to relocate\n",
        "            willing_to_relocate = application['willing_to_relocate'].lower() == 'yes'\n",
        "\n",
        "            # If applicant is in the same city or willing to relocate, append to the filtered list\n",
        "            if same_city or willing_to_relocate:\n",
        "                filtered_applications.append(application)\n",
        "                continue\n",
        "            # If not in the same city and not willing to relocate, check willingness using the GPT model\n",
        "            if not same_city and not willing_to_relocate:\n",
        "                if self.check_city(application['current_location'], job_city):\n",
        "                    filtered_applications.append(application)\n",
        "\n",
        "        return filtered_applications\n",
        "\n",
        "    # Save the filtered and removed applications to separate files\n",
        "    def save_filtered_and_removed(self, filtered_applications):\n",
        "        # Find the applications that were removed due to city constraints\n",
        "        removed_due_to_city = [app for app in self.filtered_applications_ctc if app not in filtered_applications]\n",
        "\n",
        "        # Save the filtered applications\n",
        "        with open(\"filtered_applications_city.json\", \"w\") as f:\n",
        "            json.dump(filtered_applications, f, indent=4)\n",
        "\n",
        "        # Save the removed applications\n",
        "        with open(\"removed_due_to_city.json\", \"w\") as f:\n",
        "            json.dump(removed_due_to_city, f, indent=4)\n",
        "\n",
        "    # Process the filtering and saving operations\n",
        "    def process_filtering(self):\n",
        "        filtered_applications = self.filter_by_willing_to_relocate_and_city()\n",
        "        self.save_filtered_and_removed(filtered_applications)\n",
        "\n",
        "# Create an instance of the ApplicantFilter and process the applications\n",
        "applicant_filter = FilterCity(\"requirements_output.json\", \"filtered_applications_ctc.json\")\n",
        "applicant_filter.process_filtering()"
      ],
      "metadata": {
        "id": "08sf826zivvg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**:\n",
        "For **FilterCity** class we use the method **check_city**, which uses OpenAI api, as the input values can vary a lot and so normal heuristics would not have worked.\n",
        "For example:\n",
        "1. For Input check_city(\"Oakland\", \"San Francisco\") Output: True\n",
        "2. For Input check_city(\"Bnglre\", \"Bengaluru\") Output: True\n",
        "3. For Input check_city(\"San diego\", \"San Francisco\") Output: False\n",
        "4. For Input check_city(\"Manhattan\", \"New york\") Output: True"
      ],
      "metadata": {
        "id": "CftFYutAv89J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing our code with different variations:\n",
        "current_city = \"San Francisco\"\n",
        "job_city = \"san francisco\"\n",
        "drive_distnace = \"1-hour\"\n",
        "result = applicant_filter.check_city(current_city, job_city, drive_distnace)\n",
        "print(f\"Applicant location: {current_city}, Job locatoion: {job_city}, Drive distnace: {drive_distnace}\")\n",
        "print(f\"Result: {result} \\n\")\n",
        "\n",
        "current_city = \"San Francisco\"\n",
        "job_city = \"Oakland\"\n",
        "drive_distnace = \"1-hour\"\n",
        "result = applicant_filter.check_city(current_city, job_city, drive_distnace)\n",
        "print(f\"Applicant location: {current_city}, Job locatoion: {job_city}, Drive distnace: {drive_distnace}\")\n",
        "print(f\"Result: {result} \\n\")\n",
        "\n",
        "current_city = \"Santa Cruz\"\n",
        "job_city = \"Sacramento\"\n",
        "drive_distnace = \"1 hour\"\n",
        "result = applicant_filter.check_city(current_city, job_city, drive_distnace)\n",
        "print(f\"Applicant location: {current_city}, Job locatoion: {job_city}, Drive distnace: {drive_distnace}\")\n",
        "print(f\"Result: {result} \\n\")\n",
        "\n",
        "current_city = \"Santa Cruz\"\n",
        "job_city = \"Sacramento\"\n",
        "drive_distnace = \"2-hour\"\n",
        "result = applicant_filter.check_city(current_city, job_city, drive_distnace)\n",
        "print(f\"Applicant location: {current_city}, Job locatoion: {job_city}, Drive distnace: {drive_distnace}\")\n",
        "print(f\"Result: {result} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvfE6VoNkFfN",
        "outputId": "81a22e13-f75c-4c8a-d2a9-f382ef0cb128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applicant location: San Francisco, Job locatoion: san francisco, Drive distnace: 1-hour\n",
            "Result: True \n",
            "\n",
            "Applicant location: San Francisco, Job locatoion: Oakland, Drive distnace: 1-hour\n",
            "Result: True \n",
            "\n",
            "Applicant location: Santa Cruz, Job locatoion: Sacramento, Drive distnace: 1 hour\n",
            "Result: False \n",
            "\n",
            "Applicant location: Santa Cruz, Job locatoion: Sacramento, Drive distnace: 2-hour\n",
            "Result: True \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Filtration using notice period**\n",
        "The following code defines a class **FilterNotice** that is utilized to further filter job applications based on the notice period of the candidates in relation to the notice period requirement of the job. Here's a breakdown:\n",
        "\n",
        "# **FilterNotice Class Description**:\n",
        "\n",
        "### **check_notice Method:**\n",
        "\n",
        "This method is designed to compare the notice period of a job (as provided in the job description) and the notice period of a candidate.\n",
        "It utilizes the GPT-3.5-turbo model of OpenAI to convert notice periods given in various formats (months, years, or days) into days.\n",
        "If the candidate's notice period, when converted to days, is less than or equal to the notice period required by the job, it returns 'yes', otherwise 'no'.\n",
        "```python\n",
        "def check_notice(self, jd_notice, can_notice):\n",
        "        \"\"\"\n",
        "        Convert notice periods given in months, years, or days to days, and check if the candidate's\n",
        "        notice period is less than or equal to the job's notice period.\n",
        "\n",
        "        :param jd_notice: Job's notice period\n",
        "        :param can_notice: Candidate's notice period\n",
        "\n",
        "        :return: 'yes' or 'no' indicating if the candidate's notice period is less than or equal to the job's notice period\n",
        "        \"\"\"\n",
        "        jd_notice = self.processor.convert_notice_period_to_days(jd_notice)\n",
        "        can_notice = self.processor.convert_notice_period_to_days(can_notice)\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You're assisting a recruiter. Convert the provided notice periods into days. \\\n",
        "            1 month is typically 30 days, and 1 year is 365 days. If the candidate's notice period in days is less than the job's notice period in days, then return 'yes'. \\\n",
        "            Otherwise, reply 'no'. The output must be 'yes' or 'no'\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Job's notice period: {jd_notice}. Candidate's notice period: {can_notice}.\"}\n",
        "        ]\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=messages,\n",
        "            temperature=0,\n",
        "            max_tokens=1000\n",
        "        )\n",
        "        generated_texts = [choice.message[\"content\"].strip().lower() for choice in response[\"choices\"]]\n",
        "        # print(\"initial output\", generated_texts)\n",
        "        return generated_texts[0]\n",
        "```\n",
        "\n",
        "### **filter_and_save Method:**\n",
        "\n",
        "This method performs the main operations of loading job requirements, extracting the notice period criteria, and then filtering the previously filtered applications based on city constraints.\n",
        "Only the candidates whose notice periods satisfy the job's notice period criteria are kept in the filtered_applications_notice list.\n",
        "It then saves this final filtered list to a new JSON file named \"filtered_applications.json\".\n",
        "The applications that were removed during this notice period filtering step are saved in another file named \"removed_resume_final.json\".\n",
        "\n",
        "# **After the Class Definition:**\n",
        "\n",
        "\n",
        "An instance of the **FilterNotice** class is created and named **filterer**.\n",
        "Finally, the filtering based on notice period is executed by calling the **filter_and_save** method on the filterer instance.\n",
        "In essence, the code's primary goal is to ensure that candidates' notice periods align with the job's requirements. It does this by using the OpenAI model for conversions and then filtering the applications accordingly."
      ],
      "metadata": {
        "id": "Wq78DiuCs5_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import openai\n",
        "\n",
        "class FilterNotice:\n",
        "\n",
        "    def __init__(self):\n",
        "        # Initialize the ResumeFilter class with an instance of ResumeProcessor class\n",
        "        self.processor = ResumeProcessor()\n",
        "\n",
        "    def check_notice(self, jd_notice, can_notice):\n",
        "        \"\"\"\n",
        "        Convert notice periods given in months, years, or days to days, and check if the candidate's\n",
        "        notice period is less than or equal to the job's notice period.\n",
        "\n",
        "        :param jd_notice: Job's notice period\n",
        "        :param can_notice: Candidate's notice period\n",
        "\n",
        "        :return: 'yes' or 'no' indicating if the candidate's notice period is less than or equal to the job's notice period\n",
        "        \"\"\"\n",
        "        jd_notice = self.processor.convert_notice_period_to_days(jd_notice)\n",
        "        can_notice = self.processor.convert_notice_period_to_days(can_notice)\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You're assisting a recruiter. Convert the provided notice periods into days. \\\n",
        "            1 month is typically 30 days, and 1 year is 365 days. If the candidate's notice period in days is less than the job's notice period in days, then return 'yes'. \\\n",
        "            Otherwise, reply 'no'. The output must be 'yes' or 'no'\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Job's notice period: {jd_notice}. Candidate's notice period: {can_notice}.\"}\n",
        "        ]\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=messages,\n",
        "            temperature=0,\n",
        "            max_tokens=100\n",
        "        )\n",
        "        generated_texts = [choice.message[\"content\"].strip().lower() for choice in response[\"choices\"]]\n",
        "        # print(\"initial output\", generated_texts, jd_notice, can_notice, \"jd_notice, can_notice\")\n",
        "        return generated_texts[0]\n",
        "\n",
        "    def filter_and_save(self):\n",
        "        # Load the job requirements\n",
        "        with open(\"requirements_output.json\", \"r\") as f:\n",
        "            job_req = json.load(f)\n",
        "\n",
        "        # Get the job's notice period criteria\n",
        "        notice_period_criteria = job_req.get(\"notice_period\", \"\")\n",
        "\n",
        "        # Load the previously filtered applications based on city\n",
        "        with open(\"filtered_applications_city.json\", \"r\") as f:\n",
        "            filtered_applications_city = json.load(f)\n",
        "\n",
        "        # Filter the previously filtered applications based on the notice period\n",
        "        filtered_applications_notice = [app for app in filtered_applications_city if self.check_notice(notice_period_criteria, app['notice_period']) == 'yes']\n",
        "        removed_due_to_notice = [app for app in filtered_applications_city if app not in filtered_applications_notice]\n",
        "\n",
        "        # Save the final filtered applications to a new JSON file\n",
        "        with open(\"filtered_applications.json\", \"w\") as f:\n",
        "            json.dump(filtered_applications_notice, f, indent=4)\n",
        "\n",
        "        # Save the resumes that were removed in the final filtering to another JSON file\n",
        "        with open(\"removed_resume_final.json\", \"w\") as f:\n",
        "            json.dump(removed_due_to_notice, f, indent=4)\n",
        "\n",
        "# Assuming the ResumeProcessor class is defined elsewhere, we create an instance of it\n",
        "\n",
        "filterer = FilterNotice()\n",
        "filterer.filter_and_save()"
      ],
      "metadata": {
        "id": "vs5hWCKzYA9j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27e96627-3643-4e11-ed29-c720bbb2813d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial output ['no'] 30 34 jd_notice, can_notice\n",
            "initial output ['yes'] 30 11 jd_notice, can_notice\n",
            "initial output ['yes'] 30 12 jd_notice, can_notice\n",
            "initial output ['yes'] 30 12 jd_notice, can_notice\n",
            "initial output ['yes'] 30 13 jd_notice, can_notice\n",
            "initial output ['yes'] 30 13 jd_notice, can_notice\n",
            "initial output ['yes'] 30 14 jd_notice, can_notice\n",
            "initial output ['yes'] 30 14 jd_notice, can_notice\n",
            "initial output ['yes'] 30 12 jd_notice, can_notice\n",
            "initial output ['yes'] 30 13 jd_notice, can_notice\n",
            "initial output ['yes'] 30 11 jd_notice, can_notice\n",
            "initial output ['yes'] 30 14 jd_notice, can_notice\n",
            "initial output ['yes'] 30 11 jd_notice, can_notice\n",
            "initial output ['yes'] 30 14 jd_notice, can_notice\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**:\n",
        "For **FilterNotice** class we use the method **check_notice**, which uses OpenAI api, as the input values can vary a lot and so normal heuristics would not have worked.\n",
        "For example:\n",
        "1. For Input convert_notice_period_to_days(\"1.5 months\", \"46 days\") Output: False\n",
        "2. For Input check_notice(\"months_1.5\", \"50 days\") Output: False\n",
        "3. For Input check_notice(\"months_2\", \"50 days\") Output: True\n",
        "4. For Input check_notice(\"2-months\", \"50 days\") Output: True\n",
        "5. For Input check_notice(\"2_months\", \"50 days\") Output: True"
      ],
      "metadata": {
        "id": "dWygrBzFw_QQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing various cases:\n",
        "notice_period_jd = \"One Month\"\n",
        "notice_period_candidate = \"29 days\"\n",
        "result = filterer.check_notice(notice_period_jd, notice_period_candidate)\n",
        "print(f\"Output for JD Notice period: {notice_period_jd} & Candidate notice period: {notice_period_candidate} is {result} \\n\")\n",
        "\n",
        "notice_period_jd = \"1_Month\"\n",
        "notice_period_candidate = \"2-months\"\n",
        "result = filterer.check_notice(notice_period_jd, notice_period_candidate)\n",
        "print(f\"Output for JD Notice period: {notice_period_jd} & Candidate notice period: {notice_period_candidate} is {result} \\n\")\n",
        "\n",
        "notice_period_jd = \"1 month\"\n",
        "notice_period_candidate = \"1 Month\"\n",
        "result = filterer.check_notice(notice_period_jd, notice_period_candidate)\n",
        "print(f\"Output for JD Notice period: {notice_period_jd} & Candidate notice period: {notice_period_candidate} is {result} \\n\")\n",
        "\n",
        "notice_period_jd = \"720 hours\"\n",
        "notice_period_candidate = \"43,000 minutes\"\n",
        "result = filterer.check_notice(notice_period_jd, notice_period_candidate)\n",
        "print(f\"Output for JD Notice period: {notice_period_jd} & Candidate notice period: {notice_period_candidate} is {result} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-F2DN5oniwq",
        "outputId": "149127b4-9f55-4aca-da9d-4691c01052ab"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial output ['yes'] 30 29 jd_notice, can_notice\n",
            "Output for JD Notice period: One Month & Candidate notice period: 29 days is yes \n",
            "\n",
            "initial output ['no'] 30 60 jd_notice, can_notice\n",
            "Output for JD Notice period: 1_Month & Candidate notice period: 2-months is no \n",
            "\n",
            "initial output ['no'] 30 30 jd_notice, can_notice\n",
            "Output for JD Notice period: 1 month & Candidate notice period: 1 Month is no \n",
            "\n",
            "initial output ['yes'] 30 29 jd_notice, can_notice\n",
            "Output for JD Notice period: 720 hours & Candidate notice period: 43,000 minutes is yes \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Define a function to count and return the number of entries in a given JSON file.\n",
        "def count_entries_in_json(json_filepath):\n",
        "    # Open and read the content of the JSON file.\n",
        "    with open(json_filepath, \"r\") as f:\n",
        "        data = json.load(f)  # Parse and load the JSON content into a variable.\n",
        "        return len(data)  # Return the number of top-level entries in the loaded data.\n",
        "\n",
        "# A list of file paths containing JSON data that we want to process.\n",
        "files = [\n",
        "    \"/content/all_applications.json\",\n",
        "    \"/content/filtered_applications.json\",\n",
        "    \"/content/removed_due_to_city.json\",\n",
        "    \"/content/removed_resume_ctc.json\",\n",
        "    \"/content/removed_resume_final.json\"\n",
        "]\n",
        "\n",
        "# Loop through each file in the list, count its entries, and print the result.\n",
        "for file in files:\n",
        "    count = count_entries_in_json(file)  # Use the function to count entries for the current file.\n",
        "    print(f\"{file}: {count} entries\")  # Display the file path along with its count of entries."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92yLjsoc-BXH",
        "outputId": "af46c70a-93da-4112-fed0-a32025012ae4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/all_applications.json: 16 entries\n",
            "/content/filtered_applications.json: 13 entries\n",
            "/content/removed_due_to_city.json: 1 entries\n",
            "/content/removed_resume_ctc.json: 1 entries\n",
            "/content/removed_resume_final.json: 1 entries\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the final json file containing information about the filtered resumes."
      ],
      "metadata": {
        "id": "SOi96VF-HQO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# List of file paths that you want to download\n",
        "file_paths = [\n",
        "    \"/content/filtered_applications.json\",\n",
        "    \"/content/all_applications.json\"\n",
        "\n",
        "]\n",
        "\n",
        "# Download each file to your local system\n",
        "for path in file_paths:\n",
        "    files.download(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "5FZizVI1_3RD",
        "outputId": "9496621f-257a-4849-91c6-52d080b50d54"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9d71bdf3-4180-414f-bb65-c6572e88cb28\", \"filtered_applications.json\", 4183)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_07d48785-0fdb-461f-9b14-cea9bec688a6\", \"all_applications.json\", 5117)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we leverage the job description requirements crafted in Assignment1 to streamline resume filtering. Our criteria hinge on multiple facets: the candidate's expected and current CTC, their geographic location, their openness to relocation, and their notice period. By integrating all these filters, we efficiently shortlist potential candidates. In the next Assignments we are going to take a look on how to extract meaningful information from these extracted resumes.\n"
      ],
      "metadata": {
        "id": "Hqk5Zam64SaA"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}