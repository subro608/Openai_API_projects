{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Description:\n",
        "The notebook delves into the comparative performance analysis of two iterations of the GPT model, namely GPT-3.5 and GPT-4, for automating the evaluation of candidates' resumes. By feeding these models resumes of varying complexities, the notebook aims to ascertain which version delivers more accurate and relevant evaluations.\n",
        "\n",
        "### Key components include:\n",
        "\n",
        "1. Utilizing GPT-3.5 and GPT-4 to extract pivotal details such as contact information, skills, and work experiences from resumes.\n",
        "2. Integrating libraries that enable the reading of different file formats to ensure no candidate is left out because of the file type.\n",
        "3. Employing a scoring mechanism, hinged on predefined \"must-have\" skills, to grade resumes. The score provides an objective measure to compare the efficacy of both models in recognizing and evaluating these skills."
      ],
      "metadata": {
        "id": "rl0lOJkOyijG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now install necessary libraries required to execute all functionalities within this notebook."
      ],
      "metadata": {
        "id": "RHx15IZ3r2T1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMZV2_a_t8Wu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83d0ec6c-8598-4813-eb51-1de1fd6a8ecb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.10/dist-packages (1.23.3)\n",
            "Requirement already satisfied: PyMuPDFb==1.23.3 in /usr/local/lib/python3.10/dist-packages (from PyMuPDF) (1.23.3)\n",
            "Requirement already satisfied: textract in /usr/local/lib/python3.10/dist-packages (1.6.5)\n",
            "Requirement already satisfied: argcomplete~=1.10.0 in /usr/local/lib/python3.10/dist-packages (from textract) (1.10.3)\n",
            "Requirement already satisfied: beautifulsoup4~=4.8.0 in /usr/local/lib/python3.10/dist-packages (from textract) (4.8.2)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.10/dist-packages (from textract) (3.0.4)\n",
            "Requirement already satisfied: docx2txt~=0.8 in /usr/local/lib/python3.10/dist-packages (from textract) (0.8)\n",
            "Requirement already satisfied: extract-msg<=0.29.* in /usr/local/lib/python3.10/dist-packages (from textract) (0.28.7)\n",
            "Requirement already satisfied: pdfminer.six==20191110 in /usr/local/lib/python3.10/dist-packages (from textract) (20191110)\n",
            "Requirement already satisfied: python-pptx~=0.6.18 in /usr/local/lib/python3.10/dist-packages (from textract) (0.6.22)\n",
            "Requirement already satisfied: six~=1.12.0 in /usr/local/lib/python3.10/dist-packages (from textract) (1.12.0)\n",
            "Requirement already satisfied: SpeechRecognition~=3.8.1 in /usr/local/lib/python3.10/dist-packages (from textract) (3.8.1)\n",
            "Requirement already satisfied: xlrd~=1.2.0 in /usr/local/lib/python3.10/dist-packages (from textract) (1.2.0)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20191110->textract) (3.19.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20191110->textract) (2.4.0)\n",
            "Requirement already satisfied: soupsieve>=1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4~=4.8.0->textract) (2.5)\n",
            "Requirement already satisfied: imapclient==2.1.0 in /usr/local/lib/python3.10/dist-packages (from extract-msg<=0.29.*->textract) (2.1.0)\n",
            "Requirement already satisfied: olefile>=0.46 in /usr/local/lib/python3.10/dist-packages (from extract-msg<=0.29.*->textract) (0.46)\n",
            "Requirement already satisfied: tzlocal>=2.1 in /usr/local/lib/python3.10/dist-packages (from extract-msg<=0.29.*->textract) (5.0.1)\n",
            "Requirement already satisfied: compressed-rtf>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from extract-msg<=0.29.*->textract) (1.0.6)\n",
            "Requirement already satisfied: ebcdic>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from extract-msg<=0.29.*->textract) (1.1.1)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-pptx~=0.6.18->textract) (4.9.3)\n",
            "Requirement already satisfied: Pillow<=9.5.0,>=3.3.2 in /usr/local/lib/python3.10/dist-packages (from python-pptx~=0.6.18->textract) (9.4.0)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from python-pptx~=0.6.18->textract) (3.1.3)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (0.8.11)\n",
            "Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.3)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install PyMuPDF\n",
        "!pip install textract\n",
        "!pip install python-docx\n",
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload the .env file to the directory `/content/` which contains the \"OPENAI_API_KEY\""
      ],
      "metadata": {
        "id": "mDbcQlIeFmX2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The provided code snippet accesses sensitive values like the OpenAI API key\n"
      ],
      "metadata": {
        "id": "kWq0o6d1uk77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Export your API Key to environment variable\n",
        "# Upload the .env file to the directory \"/content/\"\n",
        "!pip install python-dotenv\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ],
      "metadata": {
        "id": "xQW9h3tAug93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b956c41a-b648-4839-8201-60f8aae4812b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "# Retrieve the API key from environment variable\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "# Set the API key for OpenAI\n",
        "openai.api_key = openai_api_key"
      ],
      "metadata": {
        "id": "vWGg7HBfCoAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload the json file containing important information about the Job requirements which was generated in Assignment1 and the file containing information about the filtered resumes along with their summary generated from Assignment3"
      ],
      "metadata": {
        "id": "9wqXEYPQ79Q6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload the first file\n",
        "print(\"Please upload the first file (filtered_applications_summary.json):\")\n",
        "uploaded1 = files.upload()\n",
        "\n",
        "# Check to ensure a file was uploaded. If not, prompt again.\n",
        "while len(uploaded1) == 0:\n",
        "    print(\"No file uploaded. Please upload the first file (filtered_applications_summary.json) again:\")\n",
        "    uploaded1 = files.upload()\n",
        "\n",
        "# Upload the second file\n",
        "print(\"Please upload the second file (requirements_output.json):\")\n",
        "uploaded2 = files.upload()\n",
        "\n",
        "# Check to ensure a file was uploaded. If not, prompt again.\n",
        "while len(uploaded2) == 0:\n",
        "    print(\"No file uploaded. Please upload the second file (requirements_output.json) again:\")\n",
        "    uploaded2 = files.upload()\n",
        "\n",
        "# Merge the dictionaries to have all uploaded files in one\n",
        "uploaded = {**uploaded1, **uploaded2}\n",
        "\n",
        "# Print details of uploaded files\n",
        "for fn in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "        name=fn, length=len(uploaded[fn])))\n"
      ],
      "metadata": {
        "id": "tGFlD7Y076I6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now download the `Webinar_resumes.zip` file which contains all the resumes"
      ],
      "metadata": {
        "id": "-vnzQV337_6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def download_file_from_google_drive(file_id, destination):\n",
        "    base_url = \"https://drive.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(base_url, params={'id': file_id}, stream=True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = {'id': file_id, 'confirm': token}\n",
        "        response = session.get(base_url, params=params, stream=True)\n",
        "\n",
        "    save_response_content(response, destination)\n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk:\n",
        "                f.write(chunk)\n",
        "# # Example Usage\n",
        "# file_id = '1HaM3IeK2-iqyZzeQmCnAzKLcF9NF-mSo'  # Replace with your file's ID\n",
        "# destination = 'resume_data.zip'  # Replace with your desired file name and extension\n",
        "file_id = '1P7PXx5ynhTRGnfXd273Swbph9t1w8tDs'\n",
        "destination = 'Webinar_resumes.zip'  # Replace with your desired file name and extension\n",
        "download_file_from_google_drive(file_id, destination)"
      ],
      "metadata": {
        "id": "-OxOW7Gm8CgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The provided code provides a set of utility functions to process and analyze job resumes. Firstly, it uses OpenAI's GPT-3.5 model to summarize resumes based on a given prompt. It can read job requirements from a JSON file, and extract text from various document formats such as DOCX, DOC, PDF, and Excel sheets. If a resume contains excessive content, the code employs the Natural Language Toolkit (NLTK) to tokenize the text and trim it down to a manageable size, ensuring that only the most relevant information, up to a maximum token limit, is processed."
      ],
      "metadata": {
        "id": "m9IvVBrlvw5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import json\n",
        "import os\n",
        "from collections import OrderedDict\n",
        "import re\n",
        "from docx import Document\n",
        "import textract\n",
        "import fitz  # PyMuPDF\n",
        "import pandas as pd\n",
        "import math\n",
        "import nltk\n",
        "import tiktoken\n",
        "# nltk.download('punkt')\n",
        "\n",
        "def read_requirements(file_path):\n",
        "    # Reads the job requirements from a JSON file\n",
        "    try:\n",
        "        with open(file_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading requirements JSON: {e}\")\n",
        "        return None\n",
        "\n",
        "def read_json(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    return data\n",
        "\n",
        "def read_document(file_path):\n",
        "    file_path = str(file_path)\n",
        "    _, file_extension = os.path.splitext(file_path)\n",
        "    text = \"\"\n",
        "    if file_extension == '.docx':\n",
        "        doc = Document(file_path)\n",
        "        for para in doc.paragraphs:\n",
        "            text = text + para.text + \" \"\n",
        "    elif file_extension == '.doc':\n",
        "        text = textract.process(file_path).decode()\n",
        "    elif file_extension.lower() == '.pdf':\n",
        "        doc = fitz.open(file_path)\n",
        "        for page_number in range(len(doc)):\n",
        "            page = doc[page_number]\n",
        "            text = text + page.get_text() + \" \"\n",
        "    elif file_extension.lower() in ['.xls', '.xlsx']:\n",
        "        data = pd.read_excel(file_path)\n",
        "        text = data.to_string(index=False)\n",
        "\n",
        "    else:\n",
        "        print(f\"Unsupported file type: {file_extension}\")\n",
        "\n",
        "    return text\n",
        "\n",
        "def check_and_trim(resume_text, max_tokens=1500):\n",
        "    # tokens = nltk.word_tokenize(resume_text)\n",
        "    enc = tiktoken.get_encoding(\"cl100k_base\")\n",
        "    tokens = enc.encode(resume_text)\n",
        "    old_len = len(tokens)\n",
        "    if len(tokens) > max_tokens:\n",
        "        tokens = tokens[:max_tokens]\n",
        "        resume_text = enc.decode(tokens)\n",
        "    return resume_text, old_len, len(tokens)\n"
      ],
      "metadata": {
        "id": "8ijxiAC00CTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The provided code allows a user to select a desired number of resumes to process from a total set, with a default of 2 resumes if no input is given. The **user_select_number_of_resumes** function prompts the user for their choice, ensures valid input, and returns the selected number. The main execution block reads the **filtered_applications_summary** data from a JSON file, queries the user for their desired number of resumes using the aforementioned function, and then randomly selects the specified number of resumes from the total set, storing the result in the **selected_applications** variable."
      ],
      "metadata": {
        "id": "KFE1iIiEGR7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import random\n",
        "\n",
        "\n",
        "def user_select_number_of_resumes(total_resumes, default=2):\n",
        "    \"\"\"\n",
        "    Allow the user to input a number of resumes to process.\n",
        "    If no input is given, the default value is returned.\n",
        "\n",
        "    Args:\n",
        "    - total_resumes (int): Total number of resumes available.\n",
        "    - default (int): The default number to return if no input.\n",
        "\n",
        "    Returns:\n",
        "    - int: The number of resumes the user wants to process.\n",
        "    \"\"\"\n",
        "    print(f\"Total resumes available: {total_resumes}\")\n",
        "    user_input = input(f\"How many resumes do you want to process? (Default is {default}): \")\n",
        "\n",
        "    # If the user doesn't provide any input, return the default value.\n",
        "    if not user_input:\n",
        "        return default\n",
        "\n",
        "    try:\n",
        "        # Convert user input to an integer and ensure it's within the range.\n",
        "        selected_num = int(user_input)\n",
        "        if 1 <= selected_num <= total_resumes:\n",
        "            return selected_num\n",
        "        else:\n",
        "            print(f\"Please select a number between 1 and {total_resumes}.\")\n",
        "            return user_select_number_of_resumes(total_resumes, default)\n",
        "    except ValueError:\n",
        "        # If the user provides non-numeric input, prompt them again.\n",
        "        print(\"Please enter a valid number.\")\n",
        "        return user_select_number_of_resumes(total_resumes, default)\n",
        "\n",
        "# Read the filtered_applications_summary data from the JSON file\n",
        "json_data = read_json('/content/filtered_applications_summary.json')\n",
        "\n",
        "# Display total resumes and get the user's choice\n",
        "n = user_select_number_of_resumes(len(json_data))\n",
        "\n",
        "# Randomly select n resumes\n",
        "selected_applications = random.sample(json_data, n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAOX3J_NGPlh",
        "outputId": "69fa21e4-ba95-4126-fa19-21fd66f80e3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total resumes available: 2\n",
            "How many resumes do you want to process? (Default is 2): 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below initializes three primary components: job requirements, must-have skills, and filtered application data. The `read_requirements` function fetches the job requirements from a predefined JSON file, and `read_json` retrieves the filtered applications data. Then, a structured `resume_prompt` is defined, instructing the model on specific tasks, this prompt has already been prepared in Assignment3. The prompt asks the model to read a resume and extract various attributes: candidate's name, contact information, experience details, education credentials, technical skills, and a concise summary. The expected model output is a JSON structure, containing the extracted details, with an emphasis on properly rounding off the `years_of_experience` and delivering a concise 100-word summary of the resume."
      ],
      "metadata": {
        "id": "LFxezg_swLAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import shutil\n",
        "job_requirements = read_requirements('/content/requirements_output.json')\n",
        "must_have_skills = job_requirements[\"must_have_skills\"]\n",
        "zip_file_path = \"/content/Webinar_resumes.zip\" # For example give the path to resume_data.zip\n",
        "\n",
        "def extract_and_rename(zip_file_path, extract_path=\"extracted_files\"):\n",
        "    \"\"\"\n",
        "    Extract files from a zip archive to a specified directory.\n",
        "    Rename directories containing spaces to use underscores instead.\n",
        "\n",
        "    Args:\n",
        "    - zip_file_path (str): The path to the zip file to be extracted.\n",
        "    - extract_path (str, optional): The path where the zip file content should be extracted to.\n",
        "                                    Defaults to \"extracted_files\".\n",
        "\n",
        "    Returns:\n",
        "    - str: Path to the resume or directory.\n",
        "    \"\"\"\n",
        "    # Check if extract_path exists, if not, create it\n",
        "    if not os.path.exists(extract_path):\n",
        "        os.makedirs(extract_path)\n",
        "\n",
        "    # If extract_path is not empty, skip extraction\n",
        "    if not os.listdir(extract_path):\n",
        "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_path)\n",
        "\n",
        "    resume_path = extract_path\n",
        "    for item in os.listdir(extract_path):\n",
        "        item_path = os.path.join(extract_path, item)\n",
        "\n",
        "        # Check if the current item is a directory and if it has spaces in its name\n",
        "        if os.path.isdir(item_path) and ' ' in item:\n",
        "            new_name = item.replace(' ', '_')\n",
        "            new_path = os.path.join(extract_path, new_name)\n",
        "\n",
        "            # If the new directory name doesn't already exist, create it\n",
        "            if not os.path.exists(new_path):\n",
        "                os.makedirs(new_path)\n",
        "\n",
        "            # Copying contents from the old directory to the new one\n",
        "            for sub_item in os.listdir(item_path):\n",
        "                shutil.copy2(os.path.join(item_path, sub_item), new_path)\n",
        "\n",
        "            # Removing the old directory\n",
        "            shutil.rmtree(item_path)\n",
        "            resume_path = new_path\n",
        "        else:\n",
        "            resume_path = item_path\n",
        "\n",
        "    return resume_path\n",
        "resume_path = extract_and_rename(zip_file_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "BWrHymx288K5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The provided code evaluates resumes against a set of requisite skills `must_have`. It operates by leveraging the GPT-3.5 model to systematically analyze resumes. The function is designed to prompt the model about assessing a resume based on specified skills and expects the model to return a score and a summary for each skill in a JSON format. The scores range from 0 to 5 based on the candidate's experience with the skills. The main loop iterates through a list of job applications, ensuring each has a valid resume path and email. The resume content is read and trimmed if necessary, and then summarized. Finally, the script calculates a score for the candidate's resume based on the essential skills and prints out the candidate's name and their corresponding score."
      ],
      "metadata": {
        "id": "xuRdtO_GIowJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_Score(text, must_have):\n",
        "    model=\"gpt-3.5-turbo-16k\"\n",
        "    max_tokens=2000\n",
        "\n",
        "    first_prompt = f'''I have a resume. I want to find a person whose resume has skills in {must_have}. \\\n",
        "    Look into a resume and give score based on each of the skill mentioned in {must_have}. \\\n",
        "    Each skill present in {must_have}, should have 2 elements. \"Score\" and \"Summary\", if the score is zero then \"Summary' should be empty, otherwise \\\n",
        "    if score is non-zero then give the summary of the project in \"Summary\". Give json response only. The score should be between 0 and 5. Limited experience \\\n",
        "    the score should be one or two, 2-3 projects then score should be three or four and 4-5 projects or more than score should be four or five.'''\n",
        "\n",
        "    messages = [\n",
        "            {\"role\": \"system\", \"content\": f\"{first_prompt}\"},\n",
        "            {\"role\": \"user\", \"content\": f\"{text}\"},\n",
        "        ]\n",
        "    response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo-16k\",\n",
        "            messages=messages,\n",
        "            temperature=1,\n",
        "            max_tokens=max_tokens\n",
        "        )\n",
        "    generated_texts = [\n",
        "        choice.message[\"content\"].strip() for choice in response[\"choices\"]\n",
        "    ]\n",
        "    # print(\"generated_texts\", generated_texts)\n",
        "    return generated_texts[0]\n",
        "\n",
        "for application in selected_applications:\n",
        "    if 'resume_path' in application and 'email_id' in application:\n",
        "\n",
        "        # Extract resume text\n",
        "        resume_text = read_document(os.path.join(resume_path, application['resume_path']))\n",
        "        resume_text, _, _ = check_and_trim(resume_text)\n",
        "\n",
        "        # Directly assign the resume_summary without json.loads()\n",
        "        resume_summary = application['resume_summary']\n",
        "\n",
        "        score = calculate_Score(resume_text, must_have_skills)\n",
        "        print(f'''[Score Request] for {resume_summary[\"name_of_candidate\"]} ''', score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YJN7VCY7IoC",
        "outputId": "a9c3937b-4fc0-40b2-daaa-6842b0641b70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Score Request] for Soso Sukhitashvili  {\n",
            "  \"Keras\": {\n",
            "    \"Score\": 0,\n",
            "    \"Summary\": \"\"\n",
            "  },\n",
            "  \"TensorFlow\": {\n",
            "    \"Score\": 0,\n",
            "    \"Summary\": \"\"\n",
            "  },\n",
            "  \"PyTorch\": {\n",
            "    \"Score\": 1,\n",
            "    \"Summary\": \"Soso has experience working with PyTorch in deep learning projects such as face recognition, image similarity search, object tracking, object detection, and object segmentation.\"\n",
            "  },\n",
            "  \"Computer Vision\": {\n",
            "    \"Score\": 1,\n",
            "    \"Summary\": \"Soso has worked on computer vision projects including face recognition, image similarity search, object tracking, object detection, and object segmentation.\"\n",
            "  }\n",
            "}\n",
            "[Score Request] for Joseph Adeola  {\n",
            "  \"Score\": 3,\n",
            "  \"Summary\": \"Joseph Adeola has experience and skills in Keras, TensorFlow, and PyTorch. He has worked on the iToBos project, a research initiative focused on developing an intelligent total body scanner for early detection of melanoma using computer vision techniques and deep learning models. He applied computer vision techniques for dataset preprocessing and developed and trained deep learning models. Additionally, he has completed various university projects in computer vision, including feature tracking, stereo visual odometry, camera calibration and pose estimation, facial expression recognition, and underwater image analysis and registration.\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**:\n",
        "The problem with the output from the above code is that the output isn't stable. In some cases it is giving extra information that is not required like as shown below,\n",
        "\n",
        "\n",
        "```\n",
        "[Score Request] for Soso Sukhitashvili  {\n",
        "  \"Keras\": {\n",
        "    \"Score\": 0,\n",
        "    \"Summary\": \"\"\n",
        "  },\n",
        "  \"TensorFlow\": {\n",
        "    \"Score\": 0,\n",
        "    \"Summary\": \"\"\n",
        "  },\n",
        "  \"PyTorch\": {\n",
        "    \"Score\": 2,\n",
        "    \"Summary\": \"Soso has experience working with PyTorch, specifically in the field of deep learning. He has worked on projects involving object detection, object tracking, and image similarity search using PyTorch.\"\n",
        "  },\n",
        "  \"Computer Vision\": {\n",
        "    \"Score\": 3,\n",
        "    \"Summary\": \"Soso has strong skills in computer vision, as demonstrated in his work on projects such as face recognition, image similarity search, object tracking, object detection, object segmentation, and OCR.\"\n",
        "  }\n",
        "}\n",
        "[Score Request] for Joseph Adeola  {\n",
        "  \"score\": 5,\n",
        "  \"summary\": \"The person's resume has expertise in Keras, TensorFlow, PyTorch, and Computer Vision. They have worked on projects such as skin lesion detection and classification using deep learning models, feature tracking using the ICP algorithm for event-based pose estimation, stereo visual odometry, camera calibration and pose estimation with augmented reality, facial expression recognition using transfer learning, and underwater image analysis and registration.\"\n",
        "}\n",
        "```\n",
        "For some cases it works perfectly giving scores between 0-5 along with the summary but the result is not stable on multiple runs, it keeps on changing\n",
        "\n"
      ],
      "metadata": {
        "id": "RyFVVUzCI4W9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### From our observations, it's evident that the output generated by GPT-3.5 lacks the desired structure and contains a considerable amount of extraneous information. And even if it gives desired results, the outputs are not stable. Now keeping everything same we just change the GPT model to GPT-4."
      ],
      "metadata": {
        "id": "zcjqw0NGCynJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_Score(text, must_have):\n",
        "    model=\"gpt-4\"\n",
        "    max_tokens=2000\n",
        "\n",
        "    first_prompt = f'''I have a resume. I want to find a person whose resume has skills in {must_have}. \\\n",
        "    Look into a resume and give score based on each of the skill mentioned in {must_have}. \\\n",
        "    Each skill present in {must_have}, should have 2 elements. \"Score\" and \"Summary\", if the score is zero then \"Summary' should be empty, otherwise \\\n",
        "    if score is non-zero then give the summary of the project in \"Summary\". Give json response only. The score should be between 0 and 5. Limited experience \\\n",
        "    the score should be one or two, 2-3 projects then score should be three or four and 4-5 projects or more than score should be four or five.'''\n",
        "\n",
        "    messages = [\n",
        "            {\"role\": \"system\", \"content\": f\"{first_prompt}\"},\n",
        "            {\"role\": \"user\", \"content\": f\"{text}\"},\n",
        "        ]\n",
        "    response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=messages,\n",
        "            temperature=1,\n",
        "            max_tokens=max_tokens\n",
        "        )\n",
        "    generated_texts = [\n",
        "        choice.message[\"content\"].strip() for choice in response[\"choices\"]\n",
        "    ]\n",
        "    # print(\"generated_texts\", generated_texts)\n",
        "    return generated_texts[0]\n",
        "\n",
        "for application in selected_applications:\n",
        "    if 'resume_path' in application and 'email_id' in application:\n",
        "\n",
        "        # Extract resume text\n",
        "        resume_text = read_document(os.path.join(resume_path, application['resume_path']))\n",
        "        resume_text, _, _ = check_and_trim(resume_text)\n",
        "\n",
        "        # Directly assign the resume_summary without json.loads()\n",
        "        resume_summary = application['resume_summary']\n",
        "\n",
        "        score = calculate_Score(resume_text, must_have_skills)\n",
        "        print(f'''[Score Request] for {resume_summary[\"name_of_candidate\"]} ''', score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXpOlA200FyR",
        "outputId": "f1792211-8fd7-4323-c9e8-e53401fd4925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Score Request] for Soso Sukhitashvili  {\n",
            "    \"Keras\": {\n",
            "        \"Score\": 0,\n",
            "        \"Summary\": \"\"\n",
            "    },\n",
            "    \"TensorFlow\": {\n",
            "        \"Score\": 0,\n",
            "        \"Summary\": \"\"\n",
            "    },\n",
            "    \"PyTorch\": {\n",
            "        \"Score\": 2,\n",
            "        \"Summary\": \"Used PyTorch in variety of projects including face recognition, image similarity search, object detection and tracking, OCR, and classification at MaxinAI and Cortica AI. Despite the challenging tasks like varied shapes and aspect ratios of objects, contributed to increase the AI model's accuracy by 5%.\"\n",
            "    },\n",
            "    \"Computer Vision\": {\n",
            "        \"Score\": 3,\n",
            "        \"Summary\": \"Worked extensively on Computer Vision projects at MaxinAI and Cortica AI. Major projects included object detection and tracking, face recognition, image similarity search, and object segmentation. Utilized computer vision for detecting manufacturing defects on products with high accuracy and low latency. As a result, increased the AI model's accuracy by 5%.\"\n",
            "    }\n",
            "}\n",
            "[Score Request] for Joseph Adeola  {\n",
            "  \"Keras\": {\n",
            "    \"Score\": 4,\n",
            "    \"Summary\": [\n",
            "      \"Worked on the iToBos project, a research initiative focused on developing an intelligent total body scanner for early detection of melanoma using computer vision techniques and deep learning models.\",\n",
            "      \"Development of a Feature Tracker using ICP Algorithm for Event-based Pose Estimation on DAVIS346 Camera Sensor\",\n",
            "      \"Implemented a deep-learning framework for facial expression recognition on the Nvidia Jetson Nano device, utilizing transfer learning techniques with the RESNET-18 architecture.\"\n",
            "    ]\n",
            "  },\n",
            "  \"TensorFlow\": {\n",
            "    \"Score\": 2,\n",
            "    \"Summary\": [\n",
            "      \"Worked on the iToBos project, a research initiative focused on developing an intelligent total body scanner for early detection of melanoma using computer vision techniques and deep learning models.\"\n",
            "    ]\n",
            "  },\n",
            "  \"PyTorch\": {\n",
            "    \"Score\": 4,\n",
            "    \"Summary\": [\n",
            "      \"Graduate student specializing in Intelligent Robotics, university valedictorian, and bronze medalist at the International Youth Mathematics Challenge. Proficient in robotics, machine learning, computer vision, programming, control, and motion planning, with 3 years experience in software development.\",\n",
            "      \"Worked on the iToBos project, a research initiative focused on developing an intelligent total body scanner for early detection of melanoma using computer vision techniques and deep learning models.\",\n",
            "      \"Development of a Feature Tracker using ICP Algorithm for Event-based Pose Estimation on DAVIS346 Camera Sensor\",\n",
            "      \"Implemented a deep-learning framework for facial expression recognition on the Nvidia Jetson Nano device, utilizing transfer learning techniques with the RESNET-18 architecture.\"\n",
            "    ]\n",
            "  },\n",
            "  \"Computer Vision\": {\n",
            "    \"Score\": 5,\n",
            "    \"Summary\": [\n",
            "      \"Graduate student specializing in Intelligent Robotics, university valedictorian, and bronze medalist at the International Youth Mathematics Challenge. Proficient in robotics, machine learning, computer vision, programming, control, and motion planning, with 3 years experience in software development.\",\n",
            "      \"Worked on the iToBos project, a research initiative focused on developing an intelligent total body scanner for early detection of melanoma using computer vision techniques and deep learning models.\",\n",
            "      \"Development of a Feature Tracker using ICP Algorithm for Event-based Pose Estimation on DAVIS346 Camera Sensor\",\n",
            "      \"Stereo Visual Odometry Using UTIAS Dataset\",\n",
            "      \"Camera Calibration, Pose Estimation, and Augmented Reality using Aruco Markers in C++\",\n",
            "      \"Classification on the Nano: Facial Expression Recognition using Transfer Learning with RESNET-18 on Nvidia Jetson Nano\",\n",
            "      \"Underwater Image Analysis and Registration\",\n",
            "      \"Epipolar Geomerty and Stereo\"\n",
            "    ]\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**:\n",
        "In the case of the output generated by the above cell, we are getting perfectly formatted JSON data which contains scores between 0-5 for each of the must have skills along with the summary. The JSON output is very stable and hence proves that gpt-4 is superior in performance to gpt-3.5"
      ],
      "metadata": {
        "id": "TxAQennULEl3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Output:\n",
        "\n",
        "```\n",
        "[Score Request] for Soso Sukhitashvili  {\n",
        "  \"Keras\": {\n",
        "    \"Score\": 0,\n",
        "    \"Summary\": \"\"\n",
        "  },\n",
        "  \"TensorFlow\": {\n",
        "    \"Score\": 0,\n",
        "    \"Summary\": \"\"\n",
        "  },\n",
        "  \"PyTorch\": {\n",
        "    \"Score\": 4,\n",
        "    \"Summary\": \"Worked as a deep learning engineer at MaxinAI and developed advanced ML algorithms for complex computer vision projects. As a senior engineer at Cortica AI, improved AI model accuracy by 5% and decreased processing speed by 15%.\"\n",
        "  },\n",
        "  \"Computer Vision\": {\n",
        "    \"Score\": 5,\n",
        "    \"Summary\": \"Has extensive experience in working on computer vision projects. Developed algorithms for object detection and tracking, face recognition, and image tagging. Also, worked on an Israel based company called Cortica AI, where he developed new models for defect detection on manufacturing products.\"\n",
        "  }\n",
        "}\n",
        "[Score Request] for Joseph Adeola  {\n",
        "  \"Keras\": {\n",
        "    \"Score\": 5,\n",
        "    \"Summary\": [\n",
        "      \"Deep Learning Intern at Computer Vision and Robotics Research Institute where developed and trained deep learning models for skin lesion detection and classification.\",\n",
        "      \"Built a facial expression recognition system on Nvidia Jetson Nano using transfer learning techniques with the RESNET-18 architecture.\"\n",
        "    ]\n",
        "  },\n",
        "  \"TensorFlow\": {\n",
        "    \"Score\": 5,\n",
        "    \"Summary\": [\n",
        "      \"Deep Learning Intern at Computer Vision and Robotics Research Institute where developed and trained deep learning models for skin lesion detection and classification.\",\n",
        "      \"Built a facial expression recognition system on Nvidia Jetson Nano using transfer learning techniques with the RESNET-18 architecture.\"\n",
        "    ]\n",
        "  },\n",
        "  \"PyTorch\": {\n",
        "    \"Score\": 4,\n",
        "    \"Summary\": [\n",
        "      \"Developed various projects using PyTorch, one of them involves detection of facial expressions on Nvidia Jetson Nano.\"\n",
        "    ]\n",
        "  },\n",
        "  \"Computer Vision\": {\n",
        "    \"Score\": 5,\n",
        "    \"Summary\": [\n",
        "      \"Worked on an intelligent total body scanner for early detection of melanoma using computer vision techniques and deep learning models.\",\n",
        "      \"Developed a feature tracker using the iterative closest point (ICP) algorithm for event-based vision.\",\n",
        "      \"Handled a project that involved camera calibration, pose estimation, and augmented reality using Aruco markers.\",\n",
        "      \"Worked on underwater image analysis and registration project. Employed SIFT algorithm for robust feature extraction and image registration.\"\n",
        "    ]\n",
        "  }\n",
        "}\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "jm0_xQdYxcGP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### When employing GPT-4, the output score approaches perfection, highlighting its enhanced performance over GPT-3.5. We can see the output is perfectly structured in JSON format and the output is also stable over multiple runs. Thus, for those seeking a cost-effective solution with GPT-3.5 and aiming for accuracy on par with GPT-4, it's imperative to adopt the chain-of-thoughts methodology. This involves first establishing a scoring criteria and subsequently using that criteria to determine the final score.\n",
        "\n",
        "# `Chain-of-thought prompting`:\n",
        "\n",
        "`Chain-of-thought` prompting is a method that enables models to decompose multi-step problems into intermediate steps, which improves reasoning capabilities in large language models. This method is used to enhance the reasoning ability of large language models in arithmetic, commonsense, and symbolic reasoning tasks. Chain-of-thought prompting involves guiding a language model through a series of intermediate steps to solve a problem. It encourages the LLM to explain its reasoning, and the model-generated chain of thought would resemble an intuitive thought process when working through a multi-step reasoning problem. The chain-of-thought prompting technique is simply solving the problem step-by-step, and each step is based on logical reasoning. It is important to note that the benefits of chain-of-thought prompting only become evident when applied to models with approximately 100 billion parameters. The chain-of-thought prompting method enables models to generate chains of thought if demonstrations of chain-of-thought reasoning are provided in the exemplars for few-shot prompting.\n",
        "\n"
      ],
      "metadata": {
        "id": "4ujFVZr-DGym"
      }
    }
  ]
}