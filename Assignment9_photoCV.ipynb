{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install all the requirements for this notebook"
      ],
      "metadata": {
        "id": "H0P-WR5pHLhp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyMuPDF\n",
        "!pip install textract\n",
        "!pip install python-docx\n",
        "!pip install pdf2image\n",
        "!pip install tiktoken\n",
        "!sudo apt-get install poppler-utils\n",
        "!pip install paddlepaddle\n",
        "!apt-get update\n",
        "!apt-get install -y libssl-dev\n",
        "!wget http://nz2.archive.ubuntu.com/ubuntu/pool/main/o/openssl/libssl1.1_1.1.1f-1ubuntu2.19_amd64.deb\n",
        "!sudo dpkg -i libssl1.1_1.1.1f-1ubuntu2.19_amd64.deb"
      ],
      "metadata": {
        "id": "Scc9YuBX8Be1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from collections import OrderedDict\n",
        "import re\n",
        "from docx import Document\n",
        "import textract\n",
        "import fitz  # PyMuPDF\n",
        "import pandas as pd\n",
        "import math\n",
        "import tiktoken\n",
        "\n",
        "def read_document(file_path):\n",
        "    file_path = str(file_path)\n",
        "    _, file_extension = os.path.splitext(file_path)\n",
        "    text = \"\"\n",
        "    if file_extension == '.docx':\n",
        "        doc = Document(file_path)\n",
        "        for para in doc.paragraphs:\n",
        "            text = text + para.text + \" \"\n",
        "    elif file_extension == '.doc':\n",
        "        text = textract.process(file_path).decode()\n",
        "    elif file_extension.lower() == '.pdf':\n",
        "        doc = fitz.open(file_path)\n",
        "        for page_number in range(len(doc)):\n",
        "            page = doc[page_number]\n",
        "            text = text + page.get_text() + \" \"\n",
        "    elif file_extension.lower() in ['.xls', '.xlsx']:\n",
        "        data = pd.read_excel(file_path)\n",
        "        text = data.to_string(index=False)\n",
        "\n",
        "    else:\n",
        "        print(f\"Unsupported file type: {file_extension}\")\n",
        "\n",
        "    return text\n",
        "resume_path = \"/content/photo_cv2.pdf\"\n",
        "read_document(resume_path)"
      ],
      "metadata": {
        "id": "xbx9YGsx750n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "735b0324-61c2-4ba2-fa29-772e74c2d73f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:**\n",
        "In the above case the text extracted from the pdf is empty which can be due to the fact that it is a photo cv and hence we are not able to read it."
      ],
      "metadata": {
        "id": "zE2k9eLvHVqJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code defines a function **pdf_to_jpg** that converts each page of a given PDF file into separate JPG images. Utilizing the convert_from_path function from the **pdf2image** library, the function reads the PDF, generates images for each page, and saves them to a specified output directory (or the current directory by default). The paths of the created JPG images are then returned as a list. The example at the end calls this function using a variable **resume_path** (not defined in the provided code) to convert a PDF to JPGs and prints the paths of the resultant image files."
      ],
      "metadata": {
        "id": "OOJdXy-AIX9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pdf2image import convert_from_path\n",
        "\n",
        "def pdf_to_jpg(pdf_path, output_folder=\".\"):\n",
        "    \"\"\"\n",
        "    Convert a PDF into JPG images.\n",
        "\n",
        "    Args:\n",
        "    - pdf_path (str): The path to the PDF file.\n",
        "    - output_folder (str, optional): The path where the JPG files should be saved.\n",
        "                                     Defaults to the current directory.\n",
        "\n",
        "    Returns:\n",
        "    - List[str]: List of paths to the created JPG images.\n",
        "    \"\"\"\n",
        "    images = convert_from_path(pdf_path)\n",
        "    image_paths = []\n",
        "\n",
        "    for i, image in enumerate(images):\n",
        "        image_path = f\"{output_folder}/output_page_{i + 1}.jpg\"\n",
        "        image.save(image_path, \"JPEG\")\n",
        "        image_paths.append(image_path)\n",
        "\n",
        "    return image_paths\n",
        "\n",
        "# Convert the given PDF to JPG\n",
        "jpg_paths = pdf_to_jpg(resume_path, \"/content/\")\n",
        "print(jpg_paths)"
      ],
      "metadata": {
        "id": "jWFl5Gbx94F_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f889a4e-96b6-4e05-b379-74154c885d89"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content//output_page_1.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Git clone the PaddleOCR repo to use it in order to extract data from images."
      ],
      "metadata": {
        "id": "TJ1OUhMAIepg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/PaddlePaddle/PaddleOCR.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KfL_HlpsWu4",
        "outputId": "221be0db-091e-401f-920a-d287811d53b1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PaddleOCR'...\n",
            "remote: Enumerating objects: 47218, done.\u001b[K\n",
            "remote: Counting objects: 100% (462/462), done.\u001b[K\n",
            "remote: Compressing objects: 100% (276/276), done.\u001b[K\n",
            "remote: Total 47218 (delta 276), reused 322 (delta 184), pack-reused 46756\u001b[K\n",
            "Receiving objects: 100% (47218/47218), 343.41 MiB | 38.60 MiB/s, done.\n",
            "Resolving deltas: 100% (33126/33126), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd PaddleOCR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTJ-Yp7eIGlr",
        "outputId": "65ba33cb-f825-421d-dbb5-294b7024d135"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/PaddleOCR\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WEgGvWSOtBfz",
        "outputId": "34e1326a-29af-4d5a-eb9f-1309a0c90a30"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.0.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.19.3)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.4.0)\n",
            "Collecting pyclipper (from -r requirements.txt (line 4))\n",
            "  Downloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (908 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lmdb (from -r requirements.txt (line 5))\n",
            "  Downloading lmdb-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.23.5)\n",
            "Collecting visualdl (from -r requirements.txt (line 8))\n",
            "  Downloading visualdl-2.5.3-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz (from -r requirements.txt (line 9))\n",
            "  Downloading rapidfuzz-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencv-python<=4.6.0.66 (from -r requirements.txt (line 10))\n",
            "  Downloading opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencv-contrib-python<=4.6.0.66 (from -r requirements.txt (line 11))\n",
            "  Downloading opencv_contrib_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (3.0.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (4.9.3)\n",
            "Collecting premailer (from -r requirements.txt (line 14))\n",
            "  Downloading premailer-3.10.0-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (3.1.2)\n",
            "Collecting attrdict (from -r requirements.txt (line 16))\n",
            "  Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
            "Collecting PyMuPDF<1.21.0 (from -r requirements.txt (line 17))\n",
            "  Downloading PyMuPDF-1.20.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow>=10.0.0 (from -r requirements.txt (line 18))\n",
            "  Downloading Pillow-10.0.1-cp310-cp310-manylinux_2_28_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m117.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 19)) (6.0.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 2)) (1.11.2)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 2)) (3.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 2)) (2.31.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 2)) (2023.8.30)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 2)) (23.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imgaug->-r requirements.txt (line 3)) (1.12.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from imgaug->-r requirements.txt (line 3)) (3.7.1)\n",
            "Collecting bce-python-sdk (from visualdl->-r requirements.txt (line 8))\n",
            "  Downloading bce_python_sdk-0.8.90-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.3/235.3 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flask>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from visualdl->-r requirements.txt (line 8)) (2.2.5)\n",
            "Collecting Flask-Babel>=3.0.0 (from visualdl->-r requirements.txt (line 8))\n",
            "  Downloading flask_babel-3.1.0-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.10/dist-packages (from visualdl->-r requirements.txt (line 8)) (3.20.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from visualdl->-r requirements.txt (line 8)) (2.31.0)\n",
            "Collecting six (from imgaug->-r requirements.txt (line 3))\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from visualdl->-r requirements.txt (line 8)) (1.5.3)\n",
            "Collecting rarfile (from visualdl->-r requirements.txt (line 8))\n",
            "  Downloading rarfile-4.1-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from visualdl->-r requirements.txt (line 8)) (5.9.5)\n",
            "Collecting cssselect (from premailer->-r requirements.txt (line 14))\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting cssutils (from premailer->-r requirements.txt (line 14))\n",
            "  Downloading cssutils-2.7.1-py3-none-any.whl (399 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.7/399.7 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from premailer->-r requirements.txt (line 14)) (5.3.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl->-r requirements.txt (line 15)) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask>=1.1.1->visualdl->-r requirements.txt (line 8)) (2.3.7)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask>=1.1.1->visualdl->-r requirements.txt (line 8)) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask>=1.1.1->visualdl->-r requirements.txt (line 8)) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask>=1.1.1->visualdl->-r requirements.txt (line 8)) (8.1.7)\n",
            "Requirement already satisfied: Babel>=2.12 in /usr/local/lib/python3.10/dist-packages (from Flask-Babel>=3.0.0->visualdl->-r requirements.txt (line 8)) (2.12.1)\n",
            "Requirement already satisfied: pytz>=2022.7 in /usr/local/lib/python3.10/dist-packages (from Flask-Babel>=3.0.0->visualdl->-r requirements.txt (line 8)) (2023.3.post1)\n",
            "Requirement already satisfied: pycryptodome>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from bce-python-sdk->visualdl->-r requirements.txt (line 8)) (3.19.0)\n",
            "Requirement already satisfied: future>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from bce-python-sdk->visualdl->-r requirements.txt (line 8)) (0.18.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r requirements.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r requirements.txt (line 3)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r requirements.txt (line 3)) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r requirements.txt (line 3)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r requirements.txt (line 3)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->visualdl->-r requirements.txt (line 8)) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->visualdl->-r requirements.txt (line 8)) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->visualdl->-r requirements.txt (line 8)) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->visualdl->-r requirements.txt (line 8)) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask>=1.1.1->visualdl->-r requirements.txt (line 8)) (2.1.3)\n",
            "Installing collected packages: pyclipper, lmdb, six, rarfile, rapidfuzz, PyMuPDF, Pillow, opencv-python, opencv-contrib-python, cssutils, cssselect, premailer, bce-python-sdk, attrdict, Flask-Babel, visualdl\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.12.0\n",
            "    Uninstalling six-1.12.0:\n",
            "      Successfully uninstalled six-1.12.0\n",
            "  Attempting uninstall: PyMuPDF\n",
            "    Found existing installation: PyMuPDF 1.23.3\n",
            "    Uninstalling PyMuPDF-1.23.3:\n",
            "      Successfully uninstalled PyMuPDF-1.23.3\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.8.0.76\n",
            "    Uninstalling opencv-python-4.8.0.76:\n",
            "      Successfully uninstalled opencv-python-4.8.0.76\n",
            "  Attempting uninstall: opencv-contrib-python\n",
            "    Found existing installation: opencv-contrib-python 4.8.0.76\n",
            "    Uninstalling opencv-contrib-python-4.8.0.76:\n",
            "      Successfully uninstalled opencv-contrib-python-4.8.0.76\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "python-pptx 0.6.22 requires Pillow<=9.5.0,>=3.3.2, but you have pillow 10.0.1 which is incompatible.\n",
            "textract 1.6.5 requires six~=1.12.0, but you have six 1.16.0 which is incompatible.\n",
            "yfinance 0.2.28 requires beautifulsoup4>=4.11.1, but you have beautifulsoup4 4.8.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Flask-Babel-3.1.0 Pillow-10.0.1 PyMuPDF-1.20.2 attrdict-2.0.1 bce-python-sdk-0.8.90 cssselect-1.2.0 cssutils-2.7.1 lmdb-1.4.1 opencv-contrib-python-4.6.0.66 opencv-python-4.6.0.66 premailer-3.10.0 pyclipper-1.3.0.post5 rapidfuzz-3.3.0 rarfile-4.1 six-1.16.0 visualdl-2.5.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "fitz",
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all the important libraries\n",
        "import paddleocr\n",
        "from paddleocr import PaddleOCR"
      ],
      "metadata": {
        "id": "Bl7lKSqjzwJo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function **extract_text** processes a list of OCR (Optical Character Recognition) output data, presumably nested in structure. It iterates over the first element of this list (assumed to be another list) and retrieves the text located at the second element of each item, which is itself a tuple. This text is appended to the **extracted_texts** list. While iterating, the function also prints each item for reference. Finally, the function consolidates the extracted texts into a single string, separating them by spaces, and returns this string.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AvsuGzp5I_GZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text(ocr_output):\n",
        "    extracted_texts = []\n",
        "\n",
        "    for item in ocr_output[0]:\n",
        "        # Assuming each item's second element is a tuple containing text as its first item\n",
        "        text = item[1][0]\n",
        "        print(item)\n",
        "        extracted_texts.append(text)\n",
        "    single_string = ' '.join(extracted_texts)\n",
        "    return single_string\n"
      ],
      "metadata": {
        "id": "GCxULFlH2aY7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize PaddleOCR\n",
        "ocr = PaddleOCR(lang=\"en\")\n",
        "\n",
        "# Path to your image\n",
        "combine_text = []\n",
        "for img_path in jpg_paths:\n",
        "  # Extract text\n",
        "  result = ocr.ocr(img_path)\n",
        "  # Get extracted text\n",
        "  text = extract_text(result)\n",
        "\n",
        "  combine_text.append(text)\n",
        "total_string = ' '.join(combine_text)"
      ],
      "metadata": {
        "id": "cHGgKozDv4-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af088913-5a32-4e64-8d1d-62775aba2c7f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download https://paddleocr.bj.bcebos.com/PP-OCRv3/english/en_PP-OCRv3_det_infer.tar to /root/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer/en_PP-OCRv3_det_infer.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.00M/4.00M [00:08<00:00, 494kiB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download https://paddleocr.bj.bcebos.com/PP-OCRv4/english/en_PP-OCRv4_rec_infer.tar to /root/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer/en_PP-OCRv4_rec_infer.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10.2M/10.2M [00:02<00:00, 3.63MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_cls_infer.tar to /root/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer/ch_ppocr_mobile_v2.0_cls_infer.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.19M/2.19M [00:06<00:00, 363kiB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023/09/18 11:53:17] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/root/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/root/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/content/PaddleOCR/ppocr/utils/en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=False, cls_model_dir='/root/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, ocr=True, recovery=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023/09/18 11:53:18] ppocr WARNING: Since the angle classifier is not initialized, it will not be used during the forward process\n",
            "[2023/09/18 11:53:19] ppocr DEBUG: dt_boxes num : 95, elapsed : 0.7822816371917725\n",
            "[2023/09/18 11:53:51] ppocr DEBUG: rec_res num  : 95, elapsed : 32.30969309806824\n",
            "[[[93.0, 6.0], [421.0, 12.0], [419.0, 67.0], [91.0, 60.0]], ('Laveena', 0.9984917044639587)]\n",
            "[[[1212.0, 20.0], [1581.0, 20.0], [1581.0, 47.0], [1212.0, 47.0]], ('laveenasatwani52483@gmail.com', 0.982727587223053)]\n",
            "[[[1093.0, 47.0], [1583.0, 47.0], [1583.0, 73.0], [1093.0, 73.0]], ('linkedin.com/in/laveena-satwani-189970153', 0.9928882718086243)]\n",
            "[[[84.0, 89.0], [416.0, 89.0], [416.0, 152.0], [84.0, 152.0]], ('Satwani', 0.9998189210891724)]\n",
            "[[[838.0, 95.0], [1589.0, 97.0], [1589.0, 126.0], [838.0, 124.0]], ('Worked on annotation tool for images inpython to save annotation', 0.9870398640632629)]\n",
            "[[[853.0, 121.0], [1318.0, 126.0], [1318.0, 152.0], [853.0, 148.0]], ('time along with scriptingfor data handling', 0.9905973076820374)]\n",
            "[[[840.0, 198.0], [991.0, 198.0], [991.0, 233.0], [840.0, 233.0]], ('Projects', 0.9969614148139954)]\n",
            "[[[80.0, 251.0], [506.0, 251.0], [506.0, 279.0], [80.0, 279.0]], ('Professional Experience', 0.973081111907959)]\n",
            "[[[838.0, 251.0], [1098.0, 251.0], [1098.0, 277.0], [838.0, 277.0]], ('JAN2019  March 2019', 0.9391667246818542)]\n",
            "[[[838.0, 286.0], [1561.0, 286.0], [1561.0, 312.0], [838.0, 312.0]], ('Image Captioning(Deep Learning)/IIITDMJabalpur', 0.9646326899528503)]\n",
            "[[[838.0, 324.0], [1518.0, 324.0], [1518.0, 350.0], [838.0, 350.0]], ('Implemented a deep learning model to generate captions for', 0.9745815396308899)]\n",
            "[[[854.0, 346.0], [947.0, 351.0], [946.0, 379.0], [852.0, 374.0]], ('images.', 0.980143129825592)]\n",
            "[[[75.0, 364.0], [296.0, 364.0], [296.0, 391.0], [75.0, 391.0]], ('NOV2020- Present', 0.9805576205253601)]\n",
            "[[[838.0, 375.0], [1520.0, 375.0], [1520.0, 401.0], [838.0, 401.0]], ('Used a LSTM network model that would identify objects from', 0.957728922367096)]\n",
            "[[[75.0, 399.0], [651.0, 399.0], [651.0, 427.0], [75.0, 427.0]], ('Computer Vision Engineer /BigVision LLC,', 0.9617558717727661)]\n",
            "[[[853.0, 401.0], [1357.0, 403.0], [1357.0, 431.0], [853.0, 429.0]], ('theimage and generate a caption accordingly', 0.9931226968765259)]\n",
            "[[[75.0, 431.0], [214.0, 431.0], [214.0, 454.0], [75.0, 454.0]], ('Bangalore', 0.9970964789390564)]\n",
            "[[[75.0, 460.0], [722.0, 460.0], [722.0, 480.0], [75.0, 480.0]], ('.Worked with a real estate firm,f8re,to build an intelligent', 0.9270411133766174)]\n",
            "[[[836.0, 454.0], [1073.0, 454.0], [1073.0, 480.0], [836.0, 480.0]], ('Jan 2018APR2018', 0.9785947799682617)]\n",
            "[[[90.0, 488.0], [777.0, 488.0], [777.0, 514.0], [90.0, 514.0]], ('system for automatic image enhancement.Built an end-to-end', 0.9646490216255188)]\n",
            "[[[838.0, 488.0], [1573.0, 488.0], [1573.0, 516.0], [838.0, 516.0]], ('Witty Feedback(Machine Learning)/ IIITDM Jabalpur', 0.953763484954834)]\n",
            "[[[92.0, 520.0], [794.0, 520.0], [794.0, 547.0], [92.0, 547.0]], ('system which would automatically detect the exposure,contrast', 0.969691276550293)]\n",
            "[[[838.0, 529.0], [1536.0, 529.0], [1536.0, 555.0], [838.0, 555.0]], ('Aimed at categorizing and analyzing the sentiments of student', 0.966517984867096)]\n",
            "[[[92.0, 549.0], [704.0, 549.0], [704.0, 575.0], [92.0, 575.0]], ('and similar information of the image and enhance them.', 0.9564818143844604)]\n",
            "[[[851.0, 551.0], [1189.0, 555.0], [1189.0, 581.0], [851.0, 577.0]], ('feedback on course instructors', 0.9655844569206238)]\n",
            "[[[78.0, 577.0], [759.0, 581.0], [759.0, 608.0], [77.0, 603.0]], ('Worked with an automobile dealer firm, 360Booth,to build a', 0.9461379051208496)]\n",
            "[[[836.0, 579.0], [1526.0, 577.0], [1526.0, 605.0], [836.0, 608.0]], ('Implemented a research paperwhich used a dictionary-based', 0.9778149127960205)]\n",
            "[[[90.0, 610.0], [787.0, 610.0], [787.0, 636.0], [90.0, 636.0]], ('car segmenter and image enhancer. The system takes in picture', 0.9619400501251221)]\n",
            "[[[855.0, 605.0], [1230.0, 605.0], [1230.0, 632.0], [855.0, 632.0]], ('sentiment classification procedure', 0.9768695831298828)]\n",
            "[[[840.0, 630.0], [1548.0, 630.0], [1548.0, 656.0], [840.0, 656.0]], ('The text is used for generating a quantitative representation of', 0.963040828704834)]\n",
            "[[[94.0, 644.0], [777.0, 644.0], [777.0, 664.0], [94.0, 664.0]], ('of a scene,detects the car, enhances the image,drops shadow', 0.941058337688446)]\n",
            "[[[855.0, 656.0], [1565.0, 656.0], [1565.0, 682.0], [855.0, 682.0]], ('feedback.It not only identifies the polarity of a feedback but also', 0.9562804698944092)]\n",
            "[[[92.0, 670.0], [704.0, 670.0], [704.0, 697.0], [92.0, 697.0]], ('identifies the type and make of the model and sends the', 0.9628028273582458)]\n",
            "[[[857.0, 682.0], [1550.0, 682.0], [1550.0, 709.0], [857.0, 709.0]], ('determines the extent of positivity or negativity of the feedback', 0.9587612152099609)]\n",
            "[[[92.0, 701.0], [777.0, 701.0], [777.0, 727.0], [92.0, 727.0]], ('enhanced images back to the server for the customers to view.', 0.9574990272521973)]\n",
            "[[[71.0, 731.0], [790.0, 735.0], [789.0, 761.0], [71.0, 757.0]], ('Working with a retail store smarter,Indyme Solutions,to build a', 0.9516869783401489)]\n",
            "[[[90.0, 761.0], [775.0, 763.0], [775.0, 792.0], [90.0, 790.0]], ('pipeline where inwe willdetect if the customer, while shopping', 0.9869846701622009)]\n",
            "[[[90.0, 792.0], [749.0, 794.0], [749.0, 822.0], [90.0, 820.0]], ('from the vending machine,has picked up a product and also', 0.979156494140625)]\n",
            "[[[90.0, 824.0], [518.0, 824.0], [518.0, 850.0], [90.0, 850.0]], ('which type of product has he picked up', 0.9475746154785156)]\n",
            "[[[75.0, 871.0], [328.0, 871.0], [328.0, 897.0], [75.0, 897.0]], ('SEPT2019OCT2020', 0.9632613658905029)]\n",
            "[[[861.0, 865.0], [1100.0, 865.0], [1100.0, 891.0], [861.0, 891.0]], ('JAN2018APR2018', 0.9974580407142639)]\n",
            "[[[75.0, 903.0], [677.0, 903.0], [677.0, 932.0], [75.0, 932.0]], ('Machine Learning Engineer /Vassar Labs IT', 0.9662720561027527)]\n",
            "[[[869.0, 897.0], [1565.0, 897.0], [1565.0, 923.0], [869.0, 923.0]], ('Automatic extraction of Data-Points from Scientific', 0.9736139178276062)]\n",
            "[[[73.0, 936.0], [365.0, 936.0], [365.0, 962.0], [73.0, 962.0]], ('Solutions, Hyderabad', 0.9689449071884155)]\n",
            "[[[871.0, 934.0], [1567.0, 934.0], [1567.0, 960.0], [871.0, 960.0]], ('Data Charts (Image Processing)/IIITDM Jabalpur', 0.9539481401443481)]\n",
            "[[[73.0, 962.0], [792.0, 962.0], [792.0, 988.0], [73.0, 988.0]], ('Working on Bhubaneswar Land Use Intelligent System(BLUIs),a', 0.9553080797195435)]\n",
            "[[[869.0, 974.0], [1585.0, 974.0], [1585.0, 1000.0], [869.0, 1000.0]], ('It involved development of a software for extracting information', 0.9752370715141296)]\n",
            "[[[90.0, 992.0], [492.0, 992.0], [492.0, 1019.0], [90.0, 1019.0]], ('project with the Odisha government.', 0.9675904512405396)]\n",
            "[[[881.0, 998.0], [1193.0, 998.0], [1193.0, 1025.0], [881.0, 1025.0]], ('from an image of plot/chart', 0.949830174446106)]\n",
            "[[[75.0, 1027.0], [730.0, 1027.0], [730.0, 1047.0], [75.0, 1047.0]], ('.Developing models for detecting encroachments in satellite', 0.9564545750617981)]\n",
            "[[[871.0, 1029.0], [1583.0, 1029.0], [1583.0, 1049.0], [871.0, 1049.0]], ('It involved development of a software for extracting information', 0.9533617496490479)]\n",
            "[[[90.0, 1055.0], [792.0, 1055.0], [792.0, 1081.0], [90.0, 1081.0]], ('images by detecting change in buildings and settlements for two', 0.9667503833770752)]\n",
            "[[[883.0, 1051.0], [1195.0, 1051.0], [1195.0, 1077.0], [883.0, 1077.0]], ('from an image of plot/chart', 0.9590362906455994)]\n",
            "[[[869.0, 1077.0], [1589.0, 1077.0], [1589.0, 1104.0], [869.0, 1104.0]], ('Used Matlab to implement the segmentation task and design the', 0.9583359956741333)]\n",
            "[[[92.0, 1087.0], [226.0, 1087.0], [226.0, 1110.0], [92.0, 1110.0]], ('time periods', 0.9653019905090332)]\n",
            "[[[883.0, 1104.0], [934.0, 1104.0], [934.0, 1128.0], [883.0, 1128.0]], ('GUI', 0.9971973299980164)]\n",
            "[[[73.0, 1118.0], [781.0, 1118.0], [781.0, 1144.0], [73.0, 1144.0]], ('Developed end-to-end workflow between data collection, image', 0.9581782221794128)]\n",
            "[[[90.0, 1150.0], [594.0, 1150.0], [594.0, 1177.0], [90.0, 1177.0]], ('pre-processing,inference and post-processing', 0.9840498566627502)]\n",
            "[[[861.0, 1156.0], [1100.0, 1156.0], [1100.0, 1183.0], [861.0, 1183.0]], ('JAN 2019-APR2019', 0.9578490257263184)]\n",
            "[[[73.0, 1181.0], [792.0, 1181.0], [792.0, 1207.0], [73.0, 1207.0]], ('Working with scikit-learn to enhance the satellite imagery before', 0.9595573544502258)]\n",
            "[[[869.0, 1189.0], [1465.0, 1189.0], [1465.0, 1215.0], [869.0, 1215.0]], ('Gaze Estimation using Convolutional Neural', 0.968915581703186)]\n",
            "[[[90.0, 1209.0], [718.0, 1209.0], [718.0, 1235.0], [90.0, 1235.0]], ('prediction and transforming predictions to return the final', 0.9829018712043762)]\n",
            "[[[869.0, 1217.0], [1387.0, 1219.0], [1387.0, 1247.0], [869.0, 1245.0]], ('Network(Machine Learning)/IIITDM', 0.9498777389526367)]\n",
            "[[[90.0, 1241.0], [261.0, 1241.0], [261.0, 1268.0], [90.0, 1268.0]], ('encroachments', 0.9971483945846558)]\n",
            "[[[870.0, 1245.0], [994.0, 1250.0], [993.0, 1278.0], [869.0, 1273.0]], ('Jabalpur', 0.99736487865448)]\n",
            "[[[869.0, 1286.0], [1520.0, 1286.0], [1520.0, 1312.0], [869.0, 1312.0]], ('It involved implementing a researchpaper on iTracker and', 0.9717936515808105)]\n",
            "[[[73.0, 1298.0], [337.0, 1298.0], [337.0, 1324.0], [73.0, 1324.0]], ('JUNE 2019SEPT 2019', 0.9491028189659119)]\n",
            "[[[883.0, 1314.0], [1122.0, 1314.0], [1122.0, 1341.0], [883.0, 1341.0]], ('improving the results', 0.988355815410614)]\n",
            "[[[73.0, 1339.0], [559.0, 1339.0], [559.0, 1365.0], [73.0, 1365.0]], ('Software Engineer /Vassar Labs IT', 0.9647725224494934)]\n",
            "[[[869.0, 1341.0], [1597.0, 1341.0], [1597.0, 1367.0], [869.0, 1367.0]], ('Modified the proposed algorithm and design of the proposed CNN', 0.9729732871055603)]\n",
            "[[[75.0, 1369.0], [369.0, 1369.0], [369.0, 1395.0], [75.0, 1395.0]], ('Solutions, Hyderabad', 0.9737092852592468)]\n",
            "[[[867.0, 1363.0], [1477.0, 1365.0], [1477.0, 1393.0], [867.0, 1391.0]], ('This resulted in a drop of 0.24 in the overall test error', 0.9599555730819702)]\n",
            "[[[73.0, 1403.0], [818.0, 1403.0], [818.0, 1430.0], [73.0, 1430.0]], ('Worked on apwrims.ap.gov.in on the NDVI and Mitanks application.', 0.9605571031570435)]\n",
            "[[[74.0, 1428.0], [818.0, 1432.0], [818.0, 1458.0], [73.0, 1454.0]], ('The pipeline involved Python scripting for handling satellite images', 0.9643341302871704)]\n",
            "[[[875.0, 1434.0], [1055.0, 1434.0], [1055.0, 1468.0], [875.0, 1468.0]], ('Education', 0.99806809425354)]\n",
            "[[[75.0, 1456.0], [826.0, 1456.0], [826.0, 1482.0], [75.0, 1482.0]], ('and calculating the NDVI, runningcomputations and rest api services', 0.9524034857749939)]\n",
            "[[[78.0, 1486.0], [333.0, 1486.0], [333.0, 1507.0], [78.0, 1507.0]], ('creation on SpringBoot.', 0.9696863293647766)]\n",
            "[[[75.0, 1507.0], [704.0, 1507.0], [704.0, 1533.0], [75.0, 1533.0]], ('The apis are used to fetch data and project on geoportal', 0.9422314763069153)]\n",
            "[[[871.0, 1507.0], [1455.0, 1511.0], [1454.0, 1539.0], [871.0, 1535.0]], ('Indian Institute of Information Technology', 0.9618424773216248)]\n",
            "[[[90.0, 1535.0], [273.0, 1535.0], [273.0, 1561.0], [90.0, 1561.0]], ('usingAngularJS.', 0.9850928783416748)]\n",
            "[[[871.0, 1543.0], [1032.0, 1543.0], [1032.0, 1569.0], [871.0, 1569.0]], ('Jabalpur,India', 0.9813569784164429)]\n",
            "[[[73.0, 1575.0], [324.0, 1575.0], [324.0, 1602.0], [73.0, 1602.0]], ('MAY2018 NOV2018', 0.9579458832740784)]\n",
            "[[[869.0, 1579.0], [1512.0, 1582.0], [1512.0, 1610.0], [869.0, 1608.0]], ('Bachelor of Technology in Computer Science & Engineering', 0.9594674706459045)]\n",
            "[[[75.0, 1612.0], [643.0, 1612.0], [643.0, 1640.0], [75.0, 1640.0]], ('Machine Learning Intern /Vassar Labs IT', 0.9603179693222046)]\n",
            "[[[875.0, 1628.0], [1120.0, 1628.0], [1120.0, 1648.0], [875.0, 1648.0]], ('GPA:7.7/10MAY2019', 0.9667630791664124)]\n",
            "[[[75.0, 1644.0], [367.0, 1644.0], [367.0, 1671.0], [75.0, 1671.0]], ('Solutions, Hyderabad', 0.9786230325698853)]\n",
            "[[[73.0, 1683.0], [781.0, 1683.0], [781.0, 1709.0], [73.0, 1709.0]], ('Worked on water segmentation in satellite imagery.The project', 0.9700456857681274)]\n",
            "[[[873.0, 1683.0], [1146.0, 1683.0], [1146.0, 1709.0], [873.0, 1709.0]], ('D.A.V.Public School', 0.9699033498764038)]\n",
            "[[[92.0, 1711.0], [818.0, 1711.0], [818.0, 1737.0], [92.0, 1737.0]], ('was to estimate the water spread area in the Telangana region and', 0.9659000039100647)]\n",
            "[[[871.0, 1715.0], [996.0, 1715.0], [996.0, 1744.0], [871.0, 1744.0]], ('Kota,India', 0.9825088381767273)]\n",
            "[[[92.0, 1737.0], [475.0, 1737.0], [475.0, 1758.0], [92.0, 1758.0]], ('update the statistics over the cloud', 0.968073308467865)]\n",
            "[[[869.0, 1752.0], [1116.0, 1754.0], [1116.0, 1782.0], [869.0, 1780.0]], ('High School Education', 0.9808358550071716)]\n",
            "[[[73.0, 1762.0], [696.0, 1762.0], [696.0, 1788.0], [73.0, 1788.0]], ('Implemented a deep learning network in TensorFlow for', 0.9675236344337463)]\n",
            "[[[88.0, 1786.0], [571.0, 1788.0], [571.0, 1814.0], [88.0, 1812.0]], ('segmenting water bodies in Satellite images', 0.9605454802513123)]\n",
            "[[[871.0, 1788.0], [1073.0, 1788.0], [1073.0, 1814.0], [871.0, 1814.0]], ('95.4% April 2015', 0.9403105974197388)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we use the **summarize_resume** used in Assignment3 to extract valuable information from the resume"
      ],
      "metadata": {
        "id": "KpqLgdNAJ2wo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_resume(text):\n",
        "    \"\"\"\n",
        "    Summarize the given resume text using the OpenAI API with a specified prompt.\n",
        "\n",
        "    Args:\n",
        "    - text (str): The resume text that needs to be summarized.\n",
        "\n",
        "    Returns:\n",
        "    - str: Summarized text as returned by the OpenAI model.\n",
        "    \"\"\"\n",
        "    prompt=f'''Read the given resume and extract information corresponding to the keys \"name_of_candidate\" \\\n",
        "    which stores the candidate name, \"mobile_number\" contains the mobile number, \"email_id\" records the email id of the candidate, \\\n",
        "    total years of experience is stored in \"years_of_experience\", \"education\" refers to the candidate's most recent or highest academic degree, \\\n",
        "    last university/school/college attended by the candidate is given by \"university\", \"linkedin_profile\" contains the linkedin profile, \\\n",
        "    record all the technical skills in \"technical_skills\" , \"years_of_jobs\" showcases the years spent in different jobs, \\\n",
        "    years spent in the current organization is given by \"year_in_current_position\", \"Present_Organization\" denotes name of the present \\\n",
        "    organization and the \"summay\". For \"technical_skills\", provide a summary of the programming languages, libraries, \\\n",
        "    and frameworks the candidate has experience with, \"years_of_jobs\" is a list of job durations, e.g., [\"2012-current\",\"2010-2012\", (June 22, 2022 - Present)]. \\\n",
        "    \"year_in_current_position\" indicates the duration in their current job role. \"years_of_experience\" is the sum of years spent in all jobs including the current one. \\\n",
        "    Round off the year to the upper ceiling. So, if it is 3 months, round it off to 1 year.Summarize the resume in approximately 100 words for the \"summary\" field. \\\n",
        "    The final output must be in JSON'''\n",
        "\n",
        "    # Create a list of messages to simulate a conversation with the OpenAI model.\n",
        "    # The system starts with a prompt and the user provides the resume text.\n",
        "    messages = [\n",
        "            {\"role\": \"system\", \"content\": f\"{prompt}\"},\n",
        "            {\"role\": \"user\", \"content\": text },\n",
        "        ]\n",
        "\n",
        "    # Make a request to the OpenAI API to get the summary.\n",
        "    # Using the 'gpt-3.5-turbo-16k' model for completion.\n",
        "    response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo-16k\",\n",
        "            messages=messages,\n",
        "            temperature=1,\n",
        "            max_tokens=13000  # Setting a maximum token limit for the model's output\n",
        "        )\n",
        "\n",
        "    # Extract the generated text from the response.\n",
        "    # Since there's only one message in the choices, we're taking the first message's content.\n",
        "    generated_texts = [\n",
        "        choice.message[\"content\"].strip() for choice in response[\"choices\"]\n",
        "    ]\n",
        "\n",
        "    return generated_texts[0]"
      ],
      "metadata": {
        "id": "VqBMZyFA-eaZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload the .env file to the directory `/content/` which contains the \"OPENAI_API_KEY\".\n",
        "\n",
        "The provided code snippet accesses sensitive values like the OpenAI API key"
      ],
      "metadata": {
        "id": "bs8TAdOwKBVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Export your API Key to environment variable\n",
        "# Upload the .env file to the directory \"/content/\"\n",
        "!pip install python-dotenv\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ],
      "metadata": {
        "id": "68pxFW9K_E4v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b68484f5-1904-4669-bcf9-7bae46136a86"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Libraries Installation\n",
        "!pip install openai\n",
        "# Required Libraries\n",
        "import openai\n",
        "import json\n",
        "import os\n",
        "from collections import OrderedDict\n",
        "# Retrieve the API key from environment variable\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Set the API key for OpenAI\n",
        "openai.api_key = openai_api_key"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odlS-uu6_MZH",
        "outputId": "0d897178-0942-4e33-9809-0072f9b2a83b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **check_and_trim** function processes a given **resume_text** to ensure that its token count does not exceed a specified maximum (max_tokens, defaulting to 1500). It utilizes the tiktoken library to encode the text into tokens and count them. If the text's token count exceeds the limit, the function trims the tokens to the defined maximum and decodes it back to a string. The function returns the potentially trimmed text, the original token count, and the final token count."
      ],
      "metadata": {
        "id": "nnMqwiOhJrgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_and_trim(resume_text, max_tokens=1500):\n",
        "    # tokens = nltk.word_tokenize(resume_text)\n",
        "    enc = tiktoken.get_encoding(\"cl100k_base\")\n",
        "    tokens = enc.encode(resume_text)\n",
        "    old_len = len(tokens)\n",
        "    if len(tokens) > max_tokens:\n",
        "        tokens = tokens[:max_tokens]\n",
        "        resume_text = enc.decode(tokens)\n",
        "    return resume_text, old_len, len(tokens)"
      ],
      "metadata": {
        "id": "dYIt_kW5JOzE"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Give the extracted text as input to the summarize_resume function\n",
        "resume_text, _, _ = check_and_trim(total_string)\n",
        "resume_summary = summarize_resume(resume_text)"
      ],
      "metadata": {
        "id": "_xxaJCA5_Q7X"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(resume_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHvev_BC_jWG",
        "outputId": "4b1e42cc-f5ac-4353-efe2-d4e62af953bd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"name_of_candidate\": \"Laveena\",\n",
            "  \"mobile_number\": \"N/A\",\n",
            "  \"email_id\": \"laveenasatwani52483@gmail.com\",\n",
            "  \"years_of_experience\": 5,\n",
            "  \"education\": \"Bachelor of Technology in Computer Science & Engineering\",\n",
            "  \"university\": \"Indian Institute of Information Technology Jabalpur\",\n",
            "  \"linkedin_profile\": \"linkedin.com/in/laveena-satwani-189970153\",\n",
            "  \"technical_skills\": \"Python, Deep Learning, Image Processing, Machine Learning, TensorFlow, Matlab, scikit-learn, SpringBoot, AngularJS\",\n",
            "  \"years_of_jobs\": [\"2019-2019\", \"2020-Present\", \"2018-2018\", \"2018-2018\", \"2019-2020\", \"2019-2019\", \"2019-2019\", \"2019-2020\", \"2019-2019\"],\n",
            "  \"year_in_current_position\": 2,\n",
            "  \"Present_Organization\": \"BigVision LLC\",\n",
            "  \"summary\": \"Laveena is a Computer Science and Engineering graduate with a Bachelor's degree from the Indian Institute of Information Technology Jabalpur. She has a total of 5 years of experience in the field of computer vision and machine learning. Her technical skills include Python, Deep Learning, Image Processing, Machine Learning, TensorFlow, Matlab, scikit-learn, SpringBoot, and AngularJS. Laveena has worked on various projects including image captioning, intelligent image enhancement, sentiment analysis, car segmentation, data extraction from images, and gaze estimation. She is currently working as a Computer Vision Engineer at BigVision LLC.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Output:\n",
        "\n",
        "\n",
        "```\n",
        "{\n",
        "  \"name_of_candidate\": \"Laveena Satwani\",\n",
        "  \"mobile_number\": \"N/A\",\n",
        "  \"email_id\": \"laveenasatwani52483@gmail.com\",\n",
        "  \"years_of_experience\": 5,\n",
        "  \"education\": \"Bachelor of Technology in Computer Science & Engineering\",\n",
        "  \"university\": \"Indian Institute of Information Technology Jabalpur, India\",\n",
        "  \"linkedin_profile\": \"linkedin.com/in/laveena-satwani-189970153\",\n",
        "  \"technical_skills\": \"Python, Deep Learning, Machine Learning, Image Processing, Image Segmentation, Convolutional Neural Networks (CNN), TensorFlow, scikit-learn\",\n",
        "  \"years_of_jobs\": [\"2018-2018\", \"2019-2019\", \"2020-Present\"],\n",
        "  \"year_in_current_position\": 1,\n",
        "  \"Present_Organization\": \"BigVision LLC, Bangalore\",\n",
        "  \"summary\": \"Laveena Satwani is a computer science engineer with 5 years of experience in deep learning, machine learning, and image processing. She has worked on projects involving image annotation, image captioning, intelligent image enhancement, sentiment analysis, data extraction from scientific charts, and gaze estimation. She is proficient in Python and has experience with frameworks such as TensorFlow and scikit-learn. Laveena holds a Bachelor's degree in Computer Science & Engineering from Indian Institute of Information Technology Jabalpur. In her current position at BigVision LLC, she works as a Computer Vision Engineer.\"\n",
        "}\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "HjvG7jKALWBq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c2-Ok2zvGqLv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}