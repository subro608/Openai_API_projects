{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Description:\n",
        "This notebook delves into the realm of automated skill assessment using the OpenAI API. By examining resumes, the objective is to generate scores for each 'must-have' skill detailed in a job description. The scoring is binary: a '0' indicates the absence of the skill, and a '1' signifies its presence. Throughout this exercise, we'll fine-tune and iteratively develop the most effective prompt to ensure optimum results.\n",
        "# Learning Objectives:\n",
        "Engage with the OpenAI API, honing the craft of formulating effective prompts to yield superior outcomes. Alongside, acquire proficiency in extracting salient details from resumes and adeptly representing this data, especially emphasizing formats like standard text and JSON."
      ],
      "metadata": {
        "id": "isNbIAM6TOWF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install necessary libraries required to execute all functionalities within this notebook."
      ],
      "metadata": {
        "id": "e3mCibX2OptT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install PyMuPDF\n",
        "!pip install textract\n",
        "!pip install python-docx\n",
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "qI8IlQc8t_cy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4f241df7-daff-404e-e15a-0bb8cb6296ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n",
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.23.3-cp310-none-manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyMuPDFb==1.23.3 (from PyMuPDF)\n",
            "  Downloading PyMuPDFb-1.23.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDFb, PyMuPDF\n",
            "Successfully installed PyMuPDF-1.23.3 PyMuPDFb-1.23.3\n",
            "Collecting textract\n",
            "  Downloading textract-1.6.5-py3-none-any.whl (23 kB)\n",
            "Collecting argcomplete~=1.10.0 (from textract)\n",
            "  Downloading argcomplete-1.10.3-py2.py3-none-any.whl (36 kB)\n",
            "Collecting beautifulsoup4~=4.8.0 (from textract)\n",
            "  Downloading beautifulsoup4-4.8.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.9/106.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chardet==3.* (from textract)\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docx2txt~=0.8 (from textract)\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting extract-msg<=0.29.* (from textract)\n",
            "  Downloading extract_msg-0.28.7-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.0/69.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20191110 (from textract)\n",
            "  Downloading pdfminer.six-20191110-py2.py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-pptx~=0.6.18 (from textract)\n",
            "  Downloading python_pptx-0.6.22-py3-none-any.whl (471 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.5/471.5 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting six~=1.12.0 (from textract)\n",
            "  Downloading six-1.12.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting SpeechRecognition~=3.8.1 (from textract)\n",
            "  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xlrd~=1.2.0 (from textract)\n",
            "  Downloading xlrd-1.2.0-py2.py3-none-any.whl (103 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodome (from pdfminer.six==20191110->textract)\n",
            "  Downloading pycryptodome-3.19.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20191110->textract) (2.4.0)\n",
            "Requirement already satisfied: soupsieve>=1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4~=4.8.0->textract) (2.5)\n",
            "Collecting imapclient==2.1.0 (from extract-msg<=0.29.*->textract)\n",
            "  Downloading IMAPClient-2.1.0-py2.py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting olefile>=0.46 (from extract-msg<=0.29.*->textract)\n",
            "  Downloading olefile-0.46.zip (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tzlocal>=2.1 in /usr/local/lib/python3.10/dist-packages (from extract-msg<=0.29.*->textract) (5.0.1)\n",
            "Collecting compressed-rtf>=1.0.6 (from extract-msg<=0.29.*->textract)\n",
            "  Downloading compressed_rtf-1.0.6.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ebcdic>=1.1.1 (from extract-msg<=0.29.*->textract)\n",
            "  Downloading ebcdic-1.1.1-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.5/128.5 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-pptx~=0.6.18->textract) (4.9.3)\n",
            "Requirement already satisfied: Pillow<=9.5.0,>=3.3.2 in /usr/local/lib/python3.10/dist-packages (from python-pptx~=0.6.18->textract) (9.4.0)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx~=0.6.18->textract)\n",
            "  Downloading XlsxWriter-3.1.3-py3-none-any.whl (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.2/153.2 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: docx2txt, compressed-rtf, olefile\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3959 sha256=6feefb25c30738ab360570baab7905bd2f1709f6f071ebb0281c66281130332d\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/58/cf/093d0a6c3ecfdfc5f6ddd5524043b88e59a9a199cb02352966\n",
            "  Building wheel for compressed-rtf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for compressed-rtf: filename=compressed_rtf-1.0.6-py3-none-any.whl size=6185 sha256=cb6f7701542a5333aaf1c885ca77fc8bf0109ba254b95e0c3c98894936d8cbca\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/3e/48/e7d833ecc516c36f8966d310b1a6386db091a718f1ff3bf85c\n",
            "  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35417 sha256=c588f479db1dfd4f2d4a898f0b48f78c09b020e6d885d422355487deef2d2bca\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/39/c0/9eb1f7a42b4b38f6f333b6314d4ed11c46f12a0f7b78194f0d\n",
            "Successfully built docx2txt compressed-rtf olefile\n",
            "Installing collected packages: SpeechRecognition, ebcdic, docx2txt, compressed-rtf, chardet, argcomplete, XlsxWriter, xlrd, six, pycryptodome, olefile, beautifulsoup4, python-pptx, pdfminer.six, imapclient, extract-msg, textract\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: xlrd\n",
            "    Found existing installation: xlrd 2.0.1\n",
            "    Uninstalling xlrd-2.0.1:\n",
            "      Successfully uninstalled xlrd-2.0.1\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.16.0\n",
            "    Uninstalling six-1.16.0:\n",
            "      Successfully uninstalled six-1.16.0\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.11.2\n",
            "    Uninstalling beautifulsoup4-4.11.2:\n",
            "      Successfully uninstalled beautifulsoup4-4.11.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pydrive2 1.6.3 requires six>=1.13.0, but you have six 1.12.0 which is incompatible.\n",
            "yfinance 0.2.28 requires beautifulsoup4>=4.11.1, but you have beautifulsoup4 4.8.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed SpeechRecognition-3.8.1 XlsxWriter-3.1.3 argcomplete-1.10.3 beautifulsoup4-4.8.2 chardet-3.0.4 compressed-rtf-1.0.6 docx2txt-0.8 ebcdic-1.1.1 extract-msg-0.28.7 imapclient-2.1.0 olefile-0.46 pdfminer.six-20191110 pycryptodome-3.19.0 python-pptx-0.6.22 six-1.12.0 textract-1.6.5 xlrd-1.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.3)\n",
            "Building wheels for collected packages: python-docx\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184487 sha256=1efb060c8a09f39ae9f05ab1303062ce7a10d34f12e876f0a05980a6927f2c58\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/27/06/837436d4c3bd989b957a91679966f207bfd71d358d63a8194d\n",
            "Successfully built python-docx\n",
            "Installing collected packages: python-docx\n",
            "Successfully installed python-docx-0.8.11\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plnlXJ4D06Wc"
      },
      "outputs": [],
      "source": [
        "# Required Libraries\n",
        "import openai\n",
        "import json\n",
        "import os\n",
        "from collections import OrderedDict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload the .env file to the directory `/content/` which contains the \"OPENAI_API_KEY\""
      ],
      "metadata": {
        "id": "LQDSFrcoDlOI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNlDscmRX--1"
      },
      "source": [
        "We set up our environment to use OpenAI's API for extracting information from Job Descriptions (JD). We'll use Python as our primary language and leverage the OpenAI library to interact with OpenAI's services\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the \"OPENAI_API_KEY\" from the .env file"
      ],
      "metadata": {
        "id": "z4044lWbZVAp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PyU_wIbTXm5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "689f475b-ebb1-4290-bb00-5d71c7574407"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Export your API Key to environment variable\n",
        "# Upload the .env file to the directory \"/content/\"\n",
        "!pip install python-dotenv\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "# Retrieve the API key from environment variable\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "\n",
        "# Set the API key for OpenAI\n",
        "openai.api_key = openai_api_key"
      ],
      "metadata": {
        "id": "qaS8K0EnaxMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload the json file containing important information about the Job requirements which was generated in Assignment1 and the file containing information about the filtered resumes along with their summary generated from Assignment3"
      ],
      "metadata": {
        "id": "WCImAXkb0Q3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload the first file\n",
        "print(\"Please upload the first file (filtered_applications_summary.json):\")\n",
        "uploaded1 = files.upload()\n",
        "\n",
        "# Check to ensure a file was uploaded. If not, prompt again.\n",
        "while len(uploaded1) == 0:\n",
        "    print(\"No file uploaded. Please upload the first file (filtered_applications_summary.json) again:\")\n",
        "    uploaded1 = files.upload()\n",
        "\n",
        "# Upload the second file\n",
        "print(\"Please upload the second file (requirements_output.json):\")\n",
        "uploaded2 = files.upload()\n",
        "\n",
        "# Check to ensure a file was uploaded. If not, prompt again.\n",
        "while len(uploaded2) == 0:\n",
        "    print(\"No file uploaded. Please upload the second file (requirements_output.json) again:\")\n",
        "    uploaded2 = files.upload()\n",
        "\n",
        "# Merge the dictionaries to have all uploaded files in one\n",
        "uploaded = {**uploaded1, **uploaded2}\n",
        "\n",
        "# Print details of uploaded files\n",
        "for fn in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "        name=fn, length=len(uploaded[fn])))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "t4hTRPo_zk2W",
        "outputId": "7de560ae-3aa6-4730-cea9-b28e56e04979"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload the first file (filtered_applications_summary.json):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7a1eb19c-6997-45ee-817c-078f29160b73\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7a1eb19c-6997-45ee-817c-078f29160b73\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving filtered_applications_summary.json to filtered_applications_summary.json\n",
            "Please upload the second file (requirements_output.json):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d3fa891a-5d89-4ef0-84f9-32a89aa80fd3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d3fa891a-5d89-4ef0-84f9-32a89aa80fd3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving requirements_output.json to requirements_output.json\n",
            "User uploaded file \"filtered_applications_summary.json\" with length 26784 bytes\n",
            "User uploaded file \"requirements_output.json\" with length 764 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now download the `Webinar_resumes.zip` file which contains all the resumes"
      ],
      "metadata": {
        "id": "J7gtmiGq3EhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def download_file_from_google_drive(file_id, destination):\n",
        "    base_url = \"https://drive.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(base_url, params={'id': file_id}, stream=True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = {'id': file_id, 'confirm': token}\n",
        "        response = session.get(base_url, params=params, stream=True)\n",
        "\n",
        "    save_response_content(response, destination)\n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk:\n",
        "                f.write(chunk)\n",
        "# Example Usage\n",
        "# file_id = '1HaM3IeK2-iqyZzeQmCnAzKLcF9NF-mSo'  # Replace with your file's ID\n",
        "# destination = 'resume_data.zip'  # Replace with your desired file name and extension\n",
        "file_id = '17V_o0Snt-Lj0FmegENPQ_rXpvWTWlZgQ'\n",
        "destination = 'Webinar_resumes.zip'  # Replace with your desired file name and extension\n",
        "download_file_from_google_drive(file_id, destination)"
      ],
      "metadata": {
        "id": "TIBKLH2I3FdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The following code offers functions to read and process various document types including JSON, .docx, .doc, and .pdf files. Utilizing the python-docx library, it can extract text from .docx files. The textract module allows for text extraction from .doc files, and the PyMuPDF (imported as fitz) caters to .pdf files. There's also a function to trim resume text based on a token limit, ensuring the text doesn't exceed a specified number of tokens, which is important for using OpenAI GPT ChatCompletion. This suite of functions together supports comprehensive document reading and pre-processing capabilities."
      ],
      "metadata": {
        "id": "6UNt3y7uPvQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries and modules\n",
        "from docx import Document\n",
        "import textract\n",
        "import fitz  # PyMuPDF\n",
        "import openai\n",
        "import json\n",
        "import os\n",
        "from collections import OrderedDict\n",
        "import re\n",
        "import pandas as pd\n",
        "import math\n",
        "import tiktoken\n",
        "\n",
        "\n",
        "def read_requirements(file_path):\n",
        "    \"\"\"\n",
        "    Read the job requirements from a given JSON file.\n",
        "\n",
        "    Args:\n",
        "    - file_path (str): Path to the JSON file.\n",
        "\n",
        "    Returns:\n",
        "    - dict: Job requirements if successfully read, otherwise None.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading requirements JSON: {e}\")\n",
        "        return None\n",
        "\n",
        "def read_json(file_path):\n",
        "    \"\"\"\n",
        "    Read data from a given JSON file.\n",
        "\n",
        "    Args:\n",
        "    - file_path (str): Path to the JSON file.\n",
        "\n",
        "    Returns:\n",
        "    - dict: Data from the JSON file.\n",
        "    \"\"\"\n",
        "    with open(file_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    return data\n",
        "\n",
        "def read_document(file_path):\n",
        "    \"\"\"\n",
        "    Read and extract text from various document types (.docx, .doc, .pdf, .xls, .xlsx).\n",
        "\n",
        "    Args:\n",
        "    - file_path (str): Path to the document file.\n",
        "\n",
        "    Returns:\n",
        "    - str: Extracted text from the document.\n",
        "    \"\"\"\n",
        "    file_path = str(file_path)\n",
        "    _, file_extension = os.path.splitext(file_path)\n",
        "    text = \"\"\n",
        "    if file_extension == '.docx':\n",
        "        doc = Document(file_path)\n",
        "        for para in doc.paragraphs:\n",
        "            text = text + para.text + \" \"\n",
        "    elif file_extension == '.doc':\n",
        "        text = textract.process(file_path).decode()\n",
        "    elif file_extension.lower() == '.pdf':\n",
        "        doc = fitz.open(file_path)\n",
        "        for page_number in range(len(doc)):\n",
        "            page = doc[page_number]\n",
        "            text = text + page.get_text() + \" \"\n",
        "    elif file_extension.lower() in ['.xls', '.xlsx']:\n",
        "        data = pd.read_excel(file_path)\n",
        "        text = data.to_string(index=False)\n",
        "    else:\n",
        "        print(f\"Unsupported file type: {file_extension}\")\n",
        "\n",
        "    return text\n",
        "\n",
        "def check_and_trim(resume_text, max_tokens=1500):\n",
        "    \"\"\"\n",
        "    Trim the text to a specified number of tokens if it exceeds the limit.\n",
        "\n",
        "    Args:\n",
        "    - resume_text (str): Text to be trimmed.\n",
        "    - max_tokens (int, optional): Maximum number of tokens allowed. Defaults to 1500.\n",
        "\n",
        "    Returns:\n",
        "    - str: Trimmed text.\n",
        "    - int: Original number of tokens.\n",
        "    - int: Number of tokens after trimming.\n",
        "    \"\"\"\n",
        "    # tokens = nltk.word_tokenize(resume_text)\n",
        "    enc = tiktoken.get_encoding(\"cl100k_base\")\n",
        "    tokens = enc.encode(resume_text)\n",
        "    old_len = len(tokens)\n",
        "    if len(tokens) > max_tokens:\n",
        "        tokens = tokens[:max_tokens]\n",
        "        resume_text = enc.decode(tokens)\n",
        "    return resume_text, old_len, len(tokens)\n"
      ],
      "metadata": {
        "id": "vdPbEF22uERY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code imports necessary libraries and modules for document processing, text extraction, and interaction with OpenAI's API. It defines the main function: `initial_score`. The `initial_score` function similarly takes a prompt and text, but is designed to evaluate and return a score for the provided text. It utilizes the GPT-3.5 model and the chat-based interface to generate the respective outputs"
      ],
      "metadata": {
        "id": "ds4lmpy5RqaH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9vadwnqt1a4"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import json\n",
        "import os\n",
        "from collections import OrderedDict\n",
        "import re\n",
        "from docx import Document\n",
        "import textract\n",
        "import fitz  # PyMuPDF\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "def initial_score(text, prompt):\n",
        "    \"\"\"\n",
        "    Use OpenAI's model to generate a response based on the given prompt and text.\n",
        "\n",
        "    Args:\n",
        "    - text (str): The content to be processed.\n",
        "    - prompt (str): The instruction or question for the model to guide its response.\n",
        "\n",
        "    Returns:\n",
        "    - str: Model-generated text based on the input text and prompt.\n",
        "    \"\"\"\n",
        "\n",
        "    # Specify the model and token limits\n",
        "    model = \"gpt-3.5-turbo-16k\"\n",
        "    max_tokens = 2000\n",
        "\n",
        "    # Create a list of messages to simulate a conversation with the model.\n",
        "    # The system starts with a prompt, and the user provides the input text.\n",
        "    messages = [\n",
        "            {\"role\": \"system\", \"content\": f\"{prompt}\"},\n",
        "            {\"role\": \"user\", \"content\": text},\n",
        "        ]\n",
        "\n",
        "    # Make a request to the OpenAI API for the generated response.\n",
        "    response = openai.ChatCompletion.create(\n",
        "            model=model,\n",
        "            messages=messages,\n",
        "            temperature=1,\n",
        "            max_tokens=max_tokens\n",
        "        )\n",
        "\n",
        "    # Extract the generated text from the model's response\n",
        "    generated_texts = [\n",
        "        choice.message[\"content\"].strip() for choice in response[\"choices\"]\n",
        "    ]\n",
        "\n",
        "    return generated_texts[0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:**\n",
        "Now in the following cells we will focus on creating a prompt iteratively for the function **initial_score()** such that we can use binary classification to classify whether each of the must have skill is present in the resume or not."
      ],
      "metadata": {
        "id": "1OvtuCEGW8iN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The provided code allows a user to select a desired number of resumes to process from a total set, with a default of 2 resumes if no input is given. The **user_select_number_of_resumes** function prompts the user for their choice, ensures valid input, and returns the selected number. The main execution block reads the **filtered_applications_summary** data from a JSON file, queries the user for their desired number of resumes using the aforementioned function, and then randomly selects the specified number of resumes from the total set, storing the result in the **selected_applications** variable.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "paDFuq4E7OFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import random\n",
        "\n",
        "\n",
        "def user_select_number_of_resumes(total_resumes, default=2):\n",
        "    \"\"\"\n",
        "    Allow the user to input a number of resumes to process.\n",
        "    If no input is given, the default value is returned.\n",
        "\n",
        "    Args:\n",
        "    - total_resumes (int): Total number of resumes available.\n",
        "    - default (int): The default number to return if no input.\n",
        "\n",
        "    Returns:\n",
        "    - int: The number of resumes the user wants to process.\n",
        "    \"\"\"\n",
        "    print(f\"Total resumes available: {total_resumes}\")\n",
        "    user_input = input(f\"How many resumes do you want to process? (Default is {default}): \")\n",
        "\n",
        "    # If the user doesn't provide any input, return the default value.\n",
        "    if not user_input:\n",
        "        return default\n",
        "\n",
        "    try:\n",
        "        # Convert user input to an integer and ensure it's within the range.\n",
        "        selected_num = int(user_input)\n",
        "        if 1 <= selected_num <= total_resumes:\n",
        "            return selected_num\n",
        "        else:\n",
        "            print(f\"Please select a number between 1 and {total_resumes}.\")\n",
        "            return user_select_number_of_resumes(total_resumes, default)\n",
        "    except ValueError:\n",
        "        # If the user provides non-numeric input, prompt them again.\n",
        "        print(\"Please enter a valid number.\")\n",
        "        return user_select_number_of_resumes(total_resumes, default)\n",
        "\n",
        "# Read the filtered_applications_summary data from the JSON file\n",
        "json_data = read_json('/content/filtered_applications_summary.json')\n",
        "\n",
        "# Display total resumes and get the user's choice\n",
        "n = user_select_number_of_resumes(len(json_data))\n",
        "\n",
        "# Randomly select n resumes\n",
        "selected_applications = random.sample(json_data, n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGIBArNgx4ve",
        "outputId": "d4723de2-e3b9-4178-9b24-7dda2d0aee56"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total resumes available: 12\n",
            "How many resumes do you want to process? (Default is 2): 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code provides functionality to extract and reorganize files from a given zip archive. After reading job requirements from a JSON file, the **extract_and_rename** function unzips the contents of a specified zip file (like \"**Webinar_resumes.zip**\") into a directory (defaulted as \"**extracted_files**\"). If the directory to extract to doesn't exist, it's created; if it's already populated, extraction is skipped. Post-extraction, the function scans the contents, and if it finds any directories with spaces in their names, it renames them by replacing spaces with underscores. If the directory with the new name already exists, it transfers files from the old directory to the new one and then deletes the old directory. The function finally returns the path of the reorganized or main content directory. The main execution block then calls this function with the given zip file path and stores the result in the **resume_path** variable."
      ],
      "metadata": {
        "id": "xSSThNHJSHMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import shutil\n",
        "job_requirements = read_requirements('/content/requirements_output.json')\n",
        "must_have_skills = job_requirements[\"must_have_skills\"]\n",
        "zip_file_path = \"/content/Webinar_resumes.zip\" # For example give the path to resume_data.zip\n",
        "\n",
        "def extract_and_rename(zip_file_path, extract_path=\"extracted_files\"):\n",
        "    \"\"\"\n",
        "    Extract files from a zip archive to a specified directory.\n",
        "    Rename directories containing spaces to use underscores instead.\n",
        "\n",
        "    Args:\n",
        "    - zip_file_path (str): The path to the zip file to be extracted.\n",
        "    - extract_path (str, optional): The path where the zip file content should be extracted to.\n",
        "                                    Defaults to \"extracted_files\".\n",
        "\n",
        "    Returns:\n",
        "    - str: Path to the resume or directory.\n",
        "    \"\"\"\n",
        "    # Check if extract_path exists, if not, create it\n",
        "    if not os.path.exists(extract_path):\n",
        "        os.makedirs(extract_path)\n",
        "\n",
        "    # If extract_path is not empty, skip extraction\n",
        "    if not os.listdir(extract_path):\n",
        "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_path)\n",
        "\n",
        "    resume_path = extract_path\n",
        "    for item in os.listdir(extract_path):\n",
        "        item_path = os.path.join(extract_path, item)\n",
        "\n",
        "        # Check if the current item is a directory and if it has spaces in its name\n",
        "        if os.path.isdir(item_path) and ' ' in item:\n",
        "            new_name = item.replace(' ', '_')\n",
        "            new_path = os.path.join(extract_path, new_name)\n",
        "\n",
        "            # If the new directory name doesn't already exist, create it\n",
        "            if not os.path.exists(new_path):\n",
        "                os.makedirs(new_path)\n",
        "\n",
        "            # Copying contents from the old directory to the new one\n",
        "            for sub_item in os.listdir(item_path):\n",
        "                shutil.copy2(os.path.join(item_path, sub_item), new_path)\n",
        "\n",
        "            # Removing the old directory\n",
        "            shutil.rmtree(item_path)\n",
        "            resume_path = new_path\n",
        "        else:\n",
        "            resume_path = item_path\n",
        "\n",
        "    return resume_path\n",
        "resume_path = extract_and_rename(zip_file_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "GZ8sek0rvzdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Evaluation of the Resume\n",
        "\n",
        "## *Goal*: Extract projects in which a particular skill has been applied.\n",
        "## *Reason*: It serves as an introductory step to understand the extent of a model's capability in extracting skill-specific projects.\n",
        "# Prompt Version 1 :"
      ],
      "metadata": {
        "id": "IVACTazqkxbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_version_1 = f'''You are an assistant to a recruiter. Your job is to evaluate a resume for a particular skill. The skills for which you need to do\n",
        "evaluation are {must_have_skills}. You need to find the projects in which a particular skill from this list has been applied.'''\n",
        "\n",
        "for application in selected_applications:\n",
        "    if 'resume_path' in application and 'email_id' in application:\n",
        "\n",
        "        # Extract resume text\n",
        "        resume_text = read_document(os.path.join(resume_path, application['resume_path']))\n",
        "        resume_text, _, _ = check_and_trim(resume_text)\n",
        "\n",
        "        # Directly assign the resume_summary without json.loads()\n",
        "        resume_summary = application['resume_summary']\n",
        "\n",
        "        # Score the resume against job requirements\n",
        "        initial_score_output = initial_score(resume_text, prompt_version_1)\n",
        "\n",
        "        print(f'''[Matching Request] for {resume_summary[\"name_of_candidate\"]} ''', initial_score_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7Vtcq1_uol7",
        "outputId": "afb5c725-303f-4085-ec44-ca5ba8e5ec9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Matching Request] for Soso Sukhitashvili  Based on the information provided in the resume, the projects in which the skills have been applied are:\n",
            "\n",
            "- Computer Vision: \n",
            "  - Face recognition\n",
            "  - Image similarity search\n",
            "  - Object tracking\n",
            "  - Object detection\n",
            "  - Object segmentation\n",
            "  - OCR (Optical Character Recognition)\n",
            "\n",
            "- Natural Language Processing:\n",
            "  - Sentiment analysis\n",
            "  - Machine translation\n",
            "  - Text classification\n",
            "  - Named entity recognition\n",
            "  - Speech recognition\n",
            "\n",
            "It is important to note that the resume does not specifically mention the use of TensorFlow, Keras, or PyTorch for these projects, but the skills in Python and deep learning suggest that these frameworks could have been used.\n",
            "[Matching Request] for Derrick I.C. VAN FRAUSUM  Based on the given resume, here are the projects in which the mentioned skills have been applied:\n",
            "\n",
            "1. Computer Vision:\n",
            "   - Estimate pose & predict sport movements; remove background from images\n",
            "   - Automatic detection of intro, video content, and outro in TV shows\n",
            "   - Build 3D model from satellite images\n",
            "\n",
            "2. TensorFlow:\n",
            "   - Computer Vision projects\n",
            "   - Natural Language Processing text summarization\n",
            "\n",
            "3. PyTorch:\n",
            "   - Computer Vision projects\n",
            "\n",
            "4. Keras: Not mentioned in the resume.\n",
            "\n",
            "It seems that the candidate has experience in applying Computer Vision techniques using TensorFlow and PyTorch.\n",
            "[Matching Request] for Naren Sadhwani  Based on the information provided in the resume, the projects in which the skills are applied are as follows:\n",
            "\n",
            "1. Machine Learning Intern, Newwork Softwares GmbH:\n",
            "   - An end-to-end Machine Learning platform for demand forecasting, time-series analysis, classification using regression models.\n",
            "   - Proficiency developed in following technologies: Pycaret (AutoML), Docker (Application Deployment), Streamlit (Front-End Development), Azure (cloud), FastAPI, MySQL, Linux.\n",
            "   - No specific mention of TensorFlow, Keras, PyTorch, or Computer Vision in this project.\n",
            "\n",
            "2. Founder & CTO, IIR Technologies:\n",
            "   - Conceptualized and developed the SMART Electric wheel.\n",
            "   - No specific mention of TensorFlow, Keras, PyTorch, or Computer Vision in this project.\n",
            "\n",
            "3. Advanced Thermofluids Technologist, Rolls Royce(RR) Plc.:\n",
            "   - Designed, analyzed, validated, and verified secondary air flow systems using 1D & 3D fluid simulation software.\n",
            "   - Implemented a FEM methodology in ANSYS to perform fan blade off transient time simulations, reducing simulation time by 25%.\n",
            "   - Revamped the Non-Service Run Damage Technical Variances (NSRDTV) process in Maintenance Repair and Overhaul (MRO) operations, achieving annual savings of $3.3 million.\n",
            "   - Coordination, stakeholder management, vendor negotiations, chairing meetings for designing a generic oil-flushing rig for engine gearbox.\n",
            "   - No specific mention of TensorFlow, Keras, PyTorch, or Computer Vision in this project.\n",
            "\n",
            "4. Deep Learning Specialization, Coursera:\n",
            "   - Implemented various deep learning architectures for images, text, and signal problems.\n",
            "   - No specific mention of TensorFlow, Keras, PyTorch, or Computer Vision projects in this specialization.\n",
            "\n",
            "5. Machine Learning /AI Engineer Path, Codecademy:\n",
            "   - Implemented various ML algorithms, including anomaly detection, clustering using K-Means, regression, classification, time-series analysis, ensemble learning, AdaBoost, and XGBoost.\n",
            "   - No specific mention of TensorFlow, Keras, PyTorch, or Computer Vision projects in this path.\n",
            "\n",
            "6. Computer Vision with Embedded Machine Learning, Edge Impulse:\n",
            "   - Deployed and trained computer vision and machine learning algorithms on edge devices.\n",
            "   - Implemented projects like a smart intruder alarm, keyword activation, object detection, and DNN classifier.\n",
            "   - Model deployment considerations for edge devices.\n",
            "   - This project specifically involves Computer Vision.\n",
            "\n",
            "7. ROS2 Self Driving Car with Deep Learning and Computer Vision, Udemy:\n",
            "   - Gained in-depth understanding of building software solutions in ROS2.\n",
            "   - Implemented algorithms for Traffic Signal Detection and classification, Road Sign classification, lane assist, Cruise control & T-junc navigation, object tracking using optical flow, state estimation using Kalman filters.\n",
            "   - No specific mention of TensorFlow, Keras, or PyTorch, but involves Computer Vision.\n",
            "\n",
            "Therefore, the projects related to the specified skills are:\n",
            "- Computer Vision with Embedded Machine Learning (Edge Impulse)\n",
            "- ROS2 Self Driving Car with Deep Learning and Computer Vision (Udemy)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Output:\n",
        "\n",
        "\n",
        "```\n",
        "[Matching Request] for Ayşin Sancı  Based on the information provided, the projects in which the required skills have been applied are as follows:\n",
        "\n",
        "1. Altinay Robot Technologies – Senior Software Engineer:\n",
        "   - Built a Computer Vision application to communicate with Robotics Systems using Python and Cloud.\n",
        "   - Applied AI, Machine Learning, and Computer Vision on Robotics project using Python, Java, and C++ on Linux.\n",
        "   - Created Connect4 game that humans play vs robot using AI algorithms such as MinMax and Alpha-Beta pruning.\n",
        "   - Created an Augmented Reality application that displays 3D CAD images of the Robots.\n",
        "   \n",
        "2. Event Gates – Software Engineer:\n",
        "   - Created Computer Vision algorithm using Pytorch and AWS Cloud to ensure the reliability of gate security system.\n",
        "   - Built Deep Learning models with Python, Pytorch.\n",
        "   \n",
        "3. Projects:\n",
        "   - Speech Recognition - github.com/Ayshine/AI - Speech Recognition\n",
        "   - Machine Translation - github.io/Ayshine/NLP - Machine Translation\n",
        "[Matching Request] for Abhilash Babu  Projects in which Abhilash Babu has applied the skills 'TensorFlow', 'Keras', 'PyTorch', 'Computer Vision' are:\n",
        "\n",
        "1. Jan 2020 - Feb 2022: Implemented Deep learning model to detect facial attributes like open-closed eye, face occlusion, etc using Tensorflow2. Also, explored model interpretation using GradCAM, GradCAM++. This project involved the use of the TensorFlow framework for computer vision tasks.\n",
        "\n",
        "2. Aug 2016 - Dec 2019: Developed machine learning models for defect classification using Logistic Regression and Naive Bayes model. This project involved the use of machine learning techniques and frameworks such as TensorFlow and Keras for computer vision tasks.\n",
        "\n",
        "3. Jan 2013 - Jul 2016: Implemented machine vision algorithms and workflows to inspect LTCC and HTCC substrates based on the Golden Template method. Also, developed custom inspection scripts using Halcon Machine Vision library. This project involved the use of computer vision techniques and libraries, including TensorFlow and Keras.\n",
        "\n",
        "Overall, Abhilash Babu has experience applying TensorFlow, Keras, and PyTorch for computer vision tasks in different projects throughout their career.\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "DBBNGZLzY45L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction of Structured Output\n",
        "\n",
        "## *Goal*: Return the model's response in a JSON format.\n",
        "## *Reason*: The answers are very descriptive and is written like a short essay with bullet points. So we inform it to give the output in JOSN format. By structuring the response, it becomes easier to programmatically assess and use the output. JSON is a widely-accepted format for structured data.\n",
        "# Prompt Version 2 :"
      ],
      "metadata": {
        "id": "q14P_nRpk1OC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_version_2 = f'''You are an assistant to a recruiter. Your job is to evaluate a resume for a particular skill.  The skills for which you need to do\n",
        "evaluation are {must_have_skills}.  You need to find the projects in which a particular skill from this list has been applied. Return your response as a JSON'''\n",
        "\n",
        "for application in selected_applications:\n",
        "    if 'resume_path' in application and 'email_id' in application:\n",
        "\n",
        "        # Extract resume text\n",
        "        resume_text = read_document(os.path.join(resume_path, application['resume_path']))\n",
        "        resume_text, _, _ = check_and_trim(resume_text)\n",
        "\n",
        "        # Directly assign the resume_summary without json.loads()\n",
        "        resume_summary = application['resume_summary']\n",
        "\n",
        "        # Score the resume against job requirements\n",
        "        initial_score_output = initial_score(resume_text, prompt_version_2)\n",
        "\n",
        "        print(f'''[Matching Request] for {resume_summary[\"name_of_candidate\"]} ''', initial_score_output)\n"
      ],
      "metadata": {
        "id": "FJw4btI8wXMr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97abeb57-0841-46cd-9161-b3bbe3d833b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Matching Request] for Soso Sukhitashvili  {\n",
            "  'TensorFlow': [\n",
            "    'Computer vision',\n",
            "    'Natural language processing'\n",
            "  ],\n",
            "  'Keras': [],\n",
            "  'PyTorch': [\n",
            "    'Computer vision'\n",
            "  ],\n",
            "  'Computer Vision': [\n",
            "    'Face recognition',\n",
            "    'Image similarity search',\n",
            "    'Object tracking',\n",
            "    'Object detection',\n",
            "    'Object segmentation'\n",
            "  ]\n",
            "}\n",
            "[Matching Request] for Derrick I.C. VAN FRAUSUM  {\n",
            "  \"TensorFlow\": \"Computer Vision: estimate pose & predict sport movements; remove background from images\",\n",
            "  \"Keras\": \"\",\n",
            "  \"PyTorch\": \"\",\n",
            "  \"Computer Vision\": \"Computer Vision: estimate pose & predict sport movements; remove background from images\"\n",
            "}\n",
            "[Matching Request] for Naren Sadhwani  {\n",
            "  \"projects\": [\n",
            "    {\n",
            "      \"title\": \"Machine Learning Intern\",\n",
            "      \"skills\": [\n",
            "        \"Tensorflow\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"Deep Learning Specialization\",\n",
            "      \"skills\": [\n",
            "        \"Tensorflow\",\n",
            "        \"Pytorch\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"Machine Learning /AI Engineer Path\",\n",
            "      \"skills\": [\n",
            "        \"Tensorflow\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"Computer Vision with Embedded Machine Learning\",\n",
            "      \"skills\": [\n",
            "        \"Computer Vision\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"ROS2 Self Driving Car with Deep Learning and Computer Vision\",\n",
            "      \"skills\": [\n",
            "        \"Computer Vision\"\n",
            "      ]\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Output:\n",
        "\n",
        "\n",
        "```\n",
        "prompt_version_2 = f'''You are an assistant to a recruiter. Your job is to evaluate a resume for a particular skill.  The skills for which you need to do\n",
        "evaluation are {must_have_skills}.  You need to find the projects in which a particular skill from this list has been applied. Return your response as a JSON'''\n",
        "\n",
        "Output:\n",
        "[Matching Request] for Joseph Adeola  {\n",
        "  \"TensorFlow\": [\"iToBos project\"],\n",
        "  \"Keras\": [\"iToBos project\"],\n",
        "  \"PyTorch\": [],\n",
        "  \"Computer Vision\": [\"iToBos project\", \"Feature Tracker using ICP Algorithm for Event-based Pose Estimation on DAVIS346 Camera Sensor\", \"Stereo Visual Odometry Using UTIAS Dataset\", \"Camera Calibration, Pose Estimation, and Augmented Reality using Aruco Markers\", \"Underwater Image Analysis and Registration\", \"Epipolar Geomerty and Stereo\", \"Facial Expression Recognition using Transfer Learning with RESNET-18 on Nvidia Jetson Nano\"]\n",
        "}\n",
        "[Matching Request] for Soso Sukhitashvili  {\n",
        "  \"TensorFlow\": [\n",
        "    \"None\"\n",
        "  ],\n",
        "  \"Keras\": [\n",
        "    \"None\"\n",
        "  ],\n",
        "  \"PyTorch\": [\n",
        "    \"Deep Learning Engineer / Algorithm Developer - worked with PyTorch in computer vision projects such as object detection, object tracking, and image segmentation\"\n",
        "  ],\n",
        "  \"Computer Vision\": [\n",
        "    \"Deep Learning Engineer / Algorithm Developer - worked on computer vision projects including object detection, object tracking, image similarity search, and OCR\"\n",
        "  ]\n",
        "}\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "YQ2VEolyZt3E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Binary Scoring of Skills\n",
        "\n",
        "## *Goal*: Mark each skill as '1' (present) or '0' (absent) in the resume.\n",
        "## *Reason*: The problem with the above is that the projects selected by the assistant for each of the must have skills varies a lot, each time we run the above cell.OpenAI GPT 3.5 is good for binary classification so for that reason we ask the assistant to give score 1 or 0 based on the fact whether a must have skill is present in the resume or not. Binary classification is straightforward, making it easier for human evaluators to quickly ascertain if a candidate possesses a particular skill\n",
        "\n",
        "# Prompt Version 3 :\n"
      ],
      "metadata": {
        "id": "08Q4pYkik-qp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "prompt_version_3 = f'''You are an assistant to a recruiter. Your job is to evaluate a resume for a particular skill.  The skills for which you need to do\n",
        "evaluation are {must_have_skills}. You need to find the projects in which a particular skill from this list has been applied. For each skill, \\\n",
        "mark it 1 if there are projects related to the skill in the resume otherwise mark it 0. Now do this for all the must have skills. \\\n",
        "Return your response as a JSON'''\n",
        "\n",
        "for application in selected_applications:\n",
        "    if 'resume_path' in application and 'email_id' in application:\n",
        "\n",
        "        # Extract resume text\n",
        "        resume_text = read_document(os.path.join(resume_path, application['resume_path']))\n",
        "        resume_text, _, _ = check_and_trim(resume_text)\n",
        "\n",
        "        # Directly assign the resume_summary without json.loads()\n",
        "        resume_summary = application['resume_summary']\n",
        "\n",
        "        # Score the resume against job requirements\n",
        "        initial_score_output = initial_score(resume_text, prompt_version_3)\n",
        "\n",
        "        print(f'''[Matching Request] for {resume_summary[\"name_of_candidate\"]} ''', initial_score_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iimp4TYy3NPP",
        "outputId": "00a06ea1-e587-4e0f-f13a-3ac038c82acd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Matching Request] for Soso Sukhitashvili  {\n",
            "  \"TensorFlow\": 0,\n",
            "  \"Keras\": 0,\n",
            "  \"PyTorch\": 1,\n",
            "  \"Computer Vision\": 1\n",
            "}\n",
            "[Matching Request] for Derrick I.C. VAN FRAUSUM  {\n",
            "  \"TensorFlow\": 1,\n",
            "  \"Keras\": 0,\n",
            "  \"PyTorch\": 1,\n",
            "  \"Computer Vision\": 1\n",
            "}\n",
            "[Matching Request] for Naren Sadhwani  {\n",
            "  \"TensorFlow\": 1,\n",
            "  \"Keras\": 0,\n",
            "  \"PyTorch\": 1,\n",
            "  \"Computer Vision\": 1\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Output\n",
        "\n",
        "\n",
        "```\n",
        "[Matching Request] for Ayşin Sancı  {\n",
        "  \"TensorFlow\": 0,\n",
        "  \"Keras\": 0,\n",
        "  \"PyTorch\": 1,\n",
        "  \"Computer Vision\": 1\n",
        "}\n",
        "[Matching Request] for Abhilash Babu  {\n",
        "  \"TensorFlow\": 1,\n",
        "  \"Keras\": 1,\n",
        "  \"PyTorch\": 1,\n",
        "  \"Computer Vision\": 1\n",
        "}\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "RVCYmUpraqzF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Justification for Each Skill Score\n",
        "\n",
        "## *Goal*: Provide a summary or justification for each skill's score.\n",
        "## *Reason*: Merely scoring isn't enough. A recruiter or hiring manager would want to know the context or basis on which a score was assigned. Summaries give insights into the candidate's proficiency in a particular skill. Now the above output looks great but we also need justification or a summary about the projects corresponding to each skill based on which the assistant gave the score. So for each skill we ask the assistant to give 2 more information that is \"score\" and \"summary\"\n",
        "\n",
        "# Prompt Version 4 :"
      ],
      "metadata": {
        "id": "6dtrRjahmS4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_version_4 = f'''You are an assistant to a recruiter. Your job is to evaluate a resume for a particular skill.  The skills for which you need to do\n",
        "evaluation are {must_have_skills}. You need to find the projects in which a particular skill from this list has been applied. For each skill, \\\n",
        "use the technical skill as the key and this key will further have 2 more keys \"summary\" and \"score\". \"score\" is 0 if there is no project using this \\\n",
        "particular skill and \"summary\" is empty and \"score\" is 1 if you find a project with the particular technical skill, then use \"summary\" to \\\n",
        "explain the project. Now do this for all the must have skills. \\\n",
        "Return your response as a JSON'''\n",
        "\n",
        "for application in selected_applications:\n",
        "    if 'resume_path' in application and 'email_id' in application:\n",
        "\n",
        "        # Extract resume text\n",
        "        resume_text = read_document(os.path.join(resume_path, application['resume_path']))\n",
        "        resume_text, _, _ = check_and_trim(resume_text)\n",
        "\n",
        "        # Directly assign the resume_summary without json.loads()\n",
        "        resume_summary = application['resume_summary']\n",
        "\n",
        "        # Score the resume against job requirements\n",
        "        initial_score_output = initial_score(resume_text, prompt_version_4)\n",
        "\n",
        "        print(f'''[Matching Request] for {resume_summary[\"name_of_candidate\"]} ''', initial_score_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkiLu-Ja5ciD",
        "outputId": "f1ad949d-617d-47b7-cece-2a01c3c9d176"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Matching Request] for Soso Sukhitashvili  {\n",
            "  \"TensorFlow\": {\n",
            "    \"summary\": \"\",\n",
            "    \"score\": 0\n",
            "  },\n",
            "  \"Keras\": {\n",
            "    \"summary\": \"\",\n",
            "    \"score\": 0\n",
            "  },\n",
            "  \"PyTorch\": {\n",
            "    \"summary\": \"I have experience working with PyTorch in my role as a deep learning engineer. I have used PyTorch for projects such as object detection, image similarity search, and sentiment analysis.\",\n",
            "    \"score\": 1\n",
            "  },\n",
            "  \"Computer Vision\": {\n",
            "    \"summary\": \"I have extensive experience working on computer vision projects, including face recognition, image similarity search, object tracking, object detection, and object segmentation.\",\n",
            "    \"score\": 1\n",
            "  }\n",
            "}\n",
            "[Matching Request] for Derrick I.C. VAN FRAUSUM  {\n",
            "  \"TensorFlow\": {\n",
            "    \"summary\": \"Computer Vision: estimate pose & predict sport movements; remove background from images\",\n",
            "    \"score\": 1\n",
            "  },\n",
            "  \"Keras\": {\n",
            "    \"summary\": \"\",\n",
            "    \"score\": 0\n",
            "  },\n",
            "  \"PyTorch\": {\n",
            "    \"summary\": \"\",\n",
            "    \"score\": 0\n",
            "  },\n",
            "  \"Computer Vision\": {\n",
            "    \"summary\": \"Computer Vision: estimate pose & predict sport movements; remove background from images\",\n",
            "    \"score\": 1\n",
            "  }\n",
            "}\n",
            "[Matching Request] for Naren Sadhwani  {\n",
            "  \"TensorFlow\": {\n",
            "    \"summary\": \"Implemented various deep learning architectures for images, text and signal problems. Sequence to sequence models: LSTMs, GRUs Transformers, autoencoders, GANs. DNN: ImageNet, U-Net, YOLO, Residual Networks, Face Recognition. Hyperparameter tuning, Regularization, Optimization, Transfer Learning\",\n",
            "    \"score\": 1\n",
            "  },\n",
            "  \"Keras\": {\n",
            "    \"summary\": \"\",\n",
            "    \"score\": 0\n",
            "  },\n",
            "  \"PyTorch\": {\n",
            "    \"summary\": \"Deployed and trained computer vision and machine learning algorithms on edge devices. Smart intruder alarm, keyword activation, Object Detection, DNN Classifier. Model deployment considerations for edge devices\",\n",
            "    \"score\": 1\n",
            "  },\n",
            "  \"Computer Vision\": {\n",
            "    \"summary\": \"Gained in-depth understanding of building software solutions in ROS2. Algorithms implemented for Traffic Signal Detection and classification, Road Sign classification, lane assist, Cruise control & T junc navigation, object tracking using optical flow, state estimation using Kalman filters\",\n",
            "    \"score\": 1\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Output:\n",
        "\n",
        "\n",
        "```\n",
        "[Matching Request] for Ayşin Sancı  {\n",
        "  \"TensorFlow\": {\n",
        "    \"summary\": \"\",\n",
        "    \"score\": 0\n",
        "  },\n",
        "  \"Keras\": {\n",
        "    \"summary\": \"\",\n",
        "    \"score\": 0\n",
        "  },\n",
        "  \"PyTorch\": {\n",
        "    \"summary\": \"Created Computer Vision algorithm using Pytorch and AWS Cloud to ensure the reliability of gate security system.\",\n",
        "    \"score\": 1\n",
        "  },\n",
        "  \"Computer Vision\": {\n",
        "    \"summary\": \"Built a Computer Vision application to communicate with Robotics Systems using Python and Cloud.\",\n",
        "    \"score\": 1\n",
        "  }\n",
        "}\n",
        "[Matching Request] for Abhilash Babu  {\n",
        "  \"TensorFlow\": {\n",
        "    \"summary\": \"Implemented Deep learning model to detect facial attributes like open-closed eye, face occlusion etc using Tensorflow2. Exploration of model interpretation using GradCAM, GradCAM++. Implemented Object detection using YOLO family models. Inference of pre-trained models using ONNX runtime.\",\n",
        "    \"score\": 1\n",
        "  },\n",
        "  \"Keras\": {\n",
        "    \"summary\": \"\",\n",
        "    \"score\": 0\n",
        "  },\n",
        "  \"PyTorch\": {\n",
        "    \"summary\": \"Developed and deployed machine learning solutions for a variety of applications, including object detection, image classification, image segmentation. Possesses a deep understanding of classical computer vision techniques as well as the latest advancements in deep learning frameworks such as TensorFlow and PyTorch.\",\n",
        "    \"score\": 1\n",
        "  },\n",
        "  \"Computer Vision\": {\n",
        "    \"summary\": \"Implemented Deep learning model to detect facial attributes like open-closed eye, face occlusion etc using Tensorflow2. Exploration of model interpretation using GradCAM, GradCAM++. Implemented Object detection using YOLO family models. Evaluation of background elimination (video matting) models like Bodypix, MODNet etc. Implemented machine vision algorithms and workflows in C++ to inspect documents like Passport, ID cards etc. Developed machine learning models for defect classification using Logistic Regression and Naive Bayes model. Developed GUI application using Qt framework for creating Machine vision workflows for inspection, measurement and system calibration. Integrated GigE and USB Cameras into the software using corresponding vendor SDKs. Integrated 3D Depth sensors into the software for inspecting seam of the passport. Implemented machine vision algorithms and workflows to inspect LTCC and HTCC substrates based on Golden Template method. Integrated Cameras, Frame grabbers, strobe controllers and motor controllers into the software using vendor SDKs. Developed GUI application using .NET WPF technology to configure and create inspection workflows and to log inspection results in MySQL database. Implemented custom inspection scripts using Halcon Machine Vision library, which could then be used in the inspection software as plugins.\",\n",
        "    \"score\": 1\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "boZ-B-jXdcQm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The primary objective of this notebook is to create a prompt capable of categorizing essential \"must-have\" skills. These skills are scrutinized based on specific criteria to ascertain their inclusion or exclusion within a candidate's resume. To ensure seamless integration with subsequent assignments, the output is meticulously structured in JSON format. Furthermore, we have taken rigorous measures to maintain consistency in the JSON output keys, ensuring that data can be accessed and evaluated efficiently in future processes. This approach not only streamlines the initial assessment of candidates but also sets the stage for advanced analytics and evaluations."
      ],
      "metadata": {
        "id": "gquHYNvpaBrl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To evaluate the compatibility of a resume with the job description (JD), we'll employ a two-tiered scoring system:\n",
        "\n",
        "`Binary Scoring`: This method assesses the presence or absence of `must-have` skills from the JD in the resume. Each skill is given a score of '1' if present or '0' if absent.\n",
        "\n",
        "`Project-based Scoring`: For each of the \"must-have\" skills identified in the resume, candidates will receive a score ranging from 0 to 5, based on the number of projects where they've demonstrated the skill.\n",
        "\n",
        "The final score for each skill is derived by multiplying the scores from these two criteria. The binary score serves as a filter. If a skill is not present in the resume (a binary score of '0'), then even if it has a non-zero score from the project-based evaluation, the multiplication will result in a final score of '0' for that skill. This system ensures that only the truly relevant skills, as indicated by the JD, are taken into account when gauging a candidate's proficiency.\n",
        "We have implemented the `Binary Scoring` system, next we are going to implement it in the later assignments. Also we will compare the performance of GPT-3.5 with GPT-4 for the `Project-based Scoring` system. As using GPT-3.5 is cost effective. In case `Binary Scoring` we have already achieved good results with GPT-3.5 but `Project-based Scoring` is a bit complicated and therefore we need to compare the performance of both the versions of GPT"
      ],
      "metadata": {
        "id": "C92fh6pJd70V"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hB2IyGwK6f6m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}